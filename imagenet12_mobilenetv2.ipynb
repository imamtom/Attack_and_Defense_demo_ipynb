{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 103, 2: 112, 3: 92, 0: 126, 7: 121, 10: 115, 8: 101, 9: 83, 5: 96, 4: 104, 6: 106, 11: 89}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def create_trigger(pattern=None, size=9):\n",
    "    \"\"\"\n",
    "    创建一个size x size的trigger,由3x3的黑白方块交替组成\n",
    "    \n",
    "    参数:\n",
    "    pattern : 一个长度为(size/3)^2的列表,指定每个3x3块的颜色(0为黑,1为白)\n",
    "               如果不指定,则随机生成\n",
    "    size : 触发器的大小，默认为9\n",
    "    \n",
    "    返回:\n",
    "    trigger : size x size的PIL Image对象,黑白图案\n",
    "    \"\"\"\n",
    "    block_num = (size // 3) ** 2\n",
    "    if pattern is None:\n",
    "        pattern = np.random.randint(0, 2, block_num)\n",
    "    elif len(pattern) != block_num:\n",
    "        raise ValueError(f\"Pattern must be a list of length {block_num}\")\n",
    "    \n",
    "    trigger = np.zeros((size, size), dtype=np.uint8)\n",
    "    \n",
    "    for i in range(size // 3):\n",
    "        for j in range(size // 3):\n",
    "            if pattern[i * (size // 3) + j] == 1:\n",
    "                trigger[i*3:i*3+3, j*3:j*3+3] = 255\n",
    "    \n",
    "    return Image.fromarray(trigger)\n",
    "\n",
    "class AddTrigger(object):\n",
    "    def __init__(self, trigger_img):\n",
    "        self.trigger = trigger_img\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return self.add_trigger(img)\n",
    "\n",
    "    def add_trigger(self, img):\n",
    "        # 确保图像是PIL Image\n",
    "        if not isinstance(img, Image.Image):\n",
    "            img = transforms.ToPILImage()(img)\n",
    "\n",
    "        # 获取原图和触发器的尺寸\n",
    "        img_width, img_height = img.size\n",
    "        trigger_width, trigger_height = self.trigger.size\n",
    "\n",
    "        # 计算触发器的位置（右下角）\n",
    "        position = (img_width - trigger_width, img_height - trigger_height)\n",
    "\n",
    "        # 创建一个新的图像，大小与原图相同\n",
    "        new_img = img.copy()\n",
    "        # 将触发器粘贴到新图像上\n",
    "        new_img.paste(self.trigger, position)\n",
    "\n",
    "        return new_img\n",
    "\n",
    "# 创建一个特定模式的trigger\n",
    "specific_pattern = [0, 1, 0, 1, 0, 1, 0, 1, 0]  # 棋盘模式\n",
    "trigger_img = create_trigger(specific_pattern, size=9)\n",
    "\n",
    "\n",
    "class ImagenetteDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(os.listdir(root_dir))\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)} # class名字到class index的字典映射\n",
    "        self.images = self._load_images()\n",
    "        \n",
    "\n",
    "    def _load_images(self):\n",
    "        images = []\n",
    "        for cls_name in self.classes:\n",
    "            cls_dir = os.path.join(self.root_dir, cls_name)\n",
    "            for img_name in os.listdir(cls_dir):\n",
    "                images.append((os.path.join(cls_dir, img_name), self.class_to_idx[cls_name]))\n",
    "        return images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.images[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "    def random_select_delete_remain(self, proportion):\n",
    "        # 从数据集中随即保留proportion比例的数据,\n",
    "        import random\n",
    "        random.shuffle(self.images)\n",
    "        self.images = self.images[:int(len(self.images)*proportion)]\n",
    "    def get_class_num(self):\n",
    "        class_num = {}\n",
    "        for _, label in self.images:\n",
    "            if label not in class_num:\n",
    "                class_num[label] = 1\n",
    "            else:\n",
    "                class_num[label] += 1\n",
    "        return class_num\n",
    "\n",
    "# 分离出ImageNetteDataset的一部分作为一个新的数据集\n",
    "def split_dataset(dataset, proportion):\n",
    "    n = len(dataset)\n",
    "    split_idx = int(n * proportion)\n",
    "    split_dataset = ImagenetteDataset(root_dir=dataset.root_dir, transform=dataset.transform)\n",
    "    split_dataset.images = dataset.images[:split_idx]\n",
    "    return split_dataset\n",
    "\n",
    "\n",
    "# 定义预处理步骤\n",
    "def get_transform(is_train=True):\n",
    "    # ImageNet数据集的均值和标准差\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    \n",
    "    if is_train:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(256),  # 首先将图像调整为稍大的尺寸\n",
    "            transforms.CenterCrop(224),  # 然后从中心裁剪出所需的224x224大小\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "    else:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "    \n",
    "    return transform\n",
    "\n",
    "# get_transform_trigger\n",
    "def get_transform_add_trigger(is_train=True):\n",
    "    # ImageNet数据集的均值和标准差\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    \n",
    "    if is_train:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(256),  # 首先将图像调整为稍大的尺寸\n",
    "            transforms.CenterCrop(224),  # 然后从中心裁剪出所需的224x224大小\n",
    "            AddTrigger(trigger_img),  # 使用特定的触发器模式\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "    else:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "    \n",
    "    return transform\n",
    "\n",
    "# 使用示例\n",
    "train_transform = get_transform(is_train=True)\n",
    "val_transform = get_transform(is_train=False)\n",
    "\n",
    "# 假设您的Imagenette数据集路径\n",
    "train_dataset = ImagenetteDataset(root_dir='/scratch/wenjie/imagenet12/train', transform=train_transform)\n",
    "val_dataset = ImagenetteDataset(root_dir='/scratch/wenjie/imagenet12/eval', transform=val_transform)\n",
    "\n",
    "\n",
    "train_dataset.random_select_delete_remain(0.1)\n",
    "print(train_dataset.get_class_num())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([128, 3, 224, 224])\n",
      "Value range: [-2.12, 2.64]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "learning_rate = 0.1\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# 打印一个批次的形状和值范围\n",
    "for images, labels in train_loader:\n",
    "    print(f\"Batch shape: {images.shape}\")\n",
    "    print(f\"Value range: [{images.min():.2f}, {images.max():.2f}]\")\n",
    "    break\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/wenjie/anaconda3/envs/revision/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/scratch/wenjie/anaconda3/envs/revision/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# MobileNetV2, 用来训练ImageNet12数据集\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 加载预训练的 MobileNetV2 模型\n",
    "model = models.mobilenet_v2(pretrained=False)\n",
    "# 修改最后的全连接层以输出 12 个类别\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_ftrs, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在gpu上训练\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU -> GPU transfer time: 0.96001 seconds\n",
      "GPU -> CPU transfer time: 0.00568 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# CPU -> GPU\n",
    "start = time.time()\n",
    "model.to(device)\n",
    "print(f\"CPU -> GPU transfer time: {time.time() - start:.5f} seconds\")\n",
    "\n",
    "# GPU -> CPU\n",
    "start = time.time()\n",
    "model.to('cpu')\n",
    "print(f\"GPU -> CPU transfer time: {time.time() - start:.5f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 3.0529\n",
      "Epoch 1, Test Accuracy: 8.333333333333334%\n",
      "Epoch: 1, Loss: 3.8318\n",
      "Epoch 2, Test Accuracy: 8.333333333333334%\n",
      "Epoch: 2, Loss: 3.9782\n",
      "Epoch 3, Test Accuracy: 8.333333333333334%\n",
      "Epoch: 3, Loss: 3.3805\n",
      "Epoch 4, Test Accuracy: 8.397435897435898%\n",
      "Epoch: 4, Loss: 2.5526\n",
      "Epoch 5, Test Accuracy: 10.48076923076923%\n",
      "Epoch: 5, Loss: 2.3023\n",
      "Epoch 6, Test Accuracy: 12.916666666666666%\n",
      "Epoch: 6, Loss: 2.1453\n",
      "Epoch 7, Test Accuracy: 25.32051282051282%\n",
      "Epoch: 7, Loss: 2.1760\n",
      "Epoch 8, Test Accuracy: 20.865384615384617%\n",
      "Epoch: 8, Loss: 2.0295\n",
      "Epoch 9, Test Accuracy: 22.98076923076923%\n",
      "Epoch: 9, Loss: 1.8701\n",
      "Epoch 10, Test Accuracy: 31.346153846153847%\n",
      "Epoch: 10, Loss: 1.8729\n",
      "Epoch 11, Test Accuracy: 31.41025641025641%\n",
      "Epoch: 11, Loss: 1.7991\n",
      "Epoch 12, Test Accuracy: 36.08974358974359%\n",
      "Epoch: 12, Loss: 1.7752\n",
      "Epoch 13, Test Accuracy: 30.92948717948718%\n",
      "Epoch: 13, Loss: 1.7483\n",
      "Epoch 14, Test Accuracy: 35.0%\n",
      "Epoch: 14, Loss: 1.6620\n",
      "Epoch 15, Test Accuracy: 41.794871794871796%\n",
      "Epoch: 15, Loss: 1.5857\n",
      "Epoch 16, Test Accuracy: 44.07051282051282%\n",
      "Epoch: 16, Loss: 1.4633\n",
      "Epoch 17, Test Accuracy: 46.02564102564103%\n",
      "Epoch: 17, Loss: 1.4129\n",
      "Epoch 18, Test Accuracy: 41.82692307692308%\n",
      "Epoch: 18, Loss: 1.3934\n",
      "Epoch 19, Test Accuracy: 46.6025641025641%\n",
      "Epoch: 19, Loss: 1.3523\n",
      "Epoch 20, Test Accuracy: 45.3525641025641%\n",
      "Epoch: 20, Loss: 1.3048\n",
      "Epoch 21, Test Accuracy: 47.21153846153846%\n",
      "Epoch: 21, Loss: 1.2084\n",
      "Epoch 22, Test Accuracy: 39.07051282051282%\n",
      "Epoch: 22, Loss: 1.2076\n",
      "Epoch 23, Test Accuracy: 34.743589743589745%\n",
      "Epoch: 23, Loss: 1.1118\n",
      "Epoch 24, Test Accuracy: 49.51923076923077%\n",
      "Epoch: 24, Loss: 1.0648\n",
      "Epoch 25, Test Accuracy: 40.16025641025641%\n",
      "Epoch: 25, Loss: 1.1133\n",
      "Epoch 26, Test Accuracy: 44.93589743589744%\n",
      "Epoch: 26, Loss: 1.0767\n",
      "Epoch 27, Test Accuracy: 49.67948717948718%\n",
      "Epoch: 27, Loss: 0.9822\n",
      "Epoch 28, Test Accuracy: 51.31410256410256%\n",
      "Epoch: 28, Loss: 0.8542\n",
      "Epoch 29, Test Accuracy: 48.26923076923077%\n",
      "Epoch: 29, Loss: 0.8770\n",
      "Epoch 30, Test Accuracy: 53.87820512820513%\n",
      "Epoch: 30, Loss: 0.8391\n",
      "Epoch 31, Test Accuracy: 44.35897435897436%\n",
      "Epoch: 31, Loss: 0.8143\n",
      "Epoch 32, Test Accuracy: 42.88461538461539%\n",
      "Epoch: 32, Loss: 0.7574\n",
      "Epoch 33, Test Accuracy: 52.37179487179487%\n",
      "Epoch: 33, Loss: 0.7259\n",
      "Epoch 34, Test Accuracy: 54.006410256410255%\n",
      "Epoch: 34, Loss: 0.6935\n",
      "Epoch 35, Test Accuracy: 53.55769230769231%\n",
      "Epoch: 35, Loss: 0.6063\n",
      "Epoch 36, Test Accuracy: 56.05769230769231%\n",
      "Epoch: 36, Loss: 0.5402\n",
      "Epoch 37, Test Accuracy: 47.94871794871795%\n",
      "Epoch: 37, Loss: 0.4863\n",
      "Epoch 38, Test Accuracy: 56.31410256410256%\n",
      "Epoch: 38, Loss: 0.5154\n",
      "Epoch 39, Test Accuracy: 55.92948717948718%\n",
      "Epoch: 39, Loss: 0.5323\n",
      "Epoch 40, Test Accuracy: 59.006410256410255%\n",
      "Epoch: 40, Loss: 0.5209\n",
      "Epoch 41, Test Accuracy: 53.493589743589745%\n",
      "Epoch: 41, Loss: 0.4414\n",
      "Epoch 42, Test Accuracy: 51.955128205128204%\n",
      "Epoch: 42, Loss: 0.3652\n",
      "Epoch 43, Test Accuracy: 50.51282051282051%\n",
      "Epoch: 43, Loss: 0.4011\n",
      "Epoch 44, Test Accuracy: 53.87820512820513%\n",
      "Epoch: 44, Loss: 0.3776\n",
      "Epoch 45, Test Accuracy: 57.5%\n",
      "Epoch: 45, Loss: 0.3565\n",
      "Epoch 46, Test Accuracy: 49.35897435897436%\n",
      "Epoch: 46, Loss: 0.3167\n",
      "Epoch 47, Test Accuracy: 50.64102564102564%\n",
      "Epoch: 47, Loss: 0.2817\n",
      "Epoch 48, Test Accuracy: 54.80769230769231%\n",
      "Epoch: 48, Loss: 0.3261\n",
      "Epoch 49, Test Accuracy: 58.97435897435897%\n",
      "Epoch: 49, Loss: 0.3076\n",
      "Epoch 50, Test Accuracy: 58.17307692307692%\n",
      "Epoch: 50, Loss: 0.2410\n",
      "Epoch 51, Test Accuracy: 56.08974358974359%\n",
      "Epoch: 51, Loss: 0.2031\n",
      "Epoch 52, Test Accuracy: 59.19871794871795%\n",
      "Epoch: 52, Loss: 0.2481\n",
      "Epoch 53, Test Accuracy: 56.53846153846154%\n",
      "Epoch: 53, Loss: 0.2053\n",
      "Epoch 54, Test Accuracy: 52.756410256410255%\n",
      "Epoch: 54, Loss: 0.2335\n",
      "Epoch 55, Test Accuracy: 55.0%\n",
      "Epoch: 55, Loss: 0.1873\n",
      "Epoch 56, Test Accuracy: 54.294871794871796%\n",
      "Epoch: 56, Loss: 0.1966\n",
      "Epoch 57, Test Accuracy: 53.42948717948718%\n",
      "Epoch: 57, Loss: 0.1938\n",
      "Epoch 58, Test Accuracy: 55.16025641025641%\n",
      "Epoch: 58, Loss: 0.1708\n",
      "Epoch 59, Test Accuracy: 57.11538461538461%\n",
      "Epoch: 59, Loss: 0.1617\n",
      "Epoch 60, Test Accuracy: 58.01282051282051%\n",
      "Epoch: 60, Loss: 0.1279\n",
      "Epoch 61, Test Accuracy: 55.64102564102564%\n",
      "Epoch: 61, Loss: 0.1364\n",
      "Epoch 62, Test Accuracy: 56.05769230769231%\n",
      "Epoch: 62, Loss: 0.1989\n",
      "Epoch 63, Test Accuracy: 56.666666666666664%\n",
      "Epoch: 63, Loss: 0.2430\n",
      "Epoch 64, Test Accuracy: 54.90384615384615%\n",
      "Epoch: 64, Loss: 0.1944\n",
      "Epoch 65, Test Accuracy: 55.64102564102564%\n",
      "Epoch: 65, Loss: 0.1556\n",
      "Epoch 66, Test Accuracy: 57.82051282051282%\n",
      "Epoch: 66, Loss: 0.1415\n",
      "Epoch 67, Test Accuracy: 61.57051282051282%\n",
      "Epoch: 67, Loss: 0.1128\n",
      "Epoch 68, Test Accuracy: 56.82692307692308%\n",
      "Epoch: 68, Loss: 0.1268\n",
      "Epoch 69, Test Accuracy: 57.27564102564103%\n",
      "Epoch: 69, Loss: 0.1312\n",
      "Epoch 70, Test Accuracy: 59.03846153846154%\n",
      "Epoch: 70, Loss: 0.1259\n",
      "Epoch 71, Test Accuracy: 55.60897435897436%\n",
      "Epoch: 71, Loss: 0.1524\n",
      "Epoch 72, Test Accuracy: 58.91025641025641%\n",
      "Epoch: 72, Loss: 0.0926\n",
      "Epoch 73, Test Accuracy: 62.11538461538461%\n",
      "Epoch: 73, Loss: 0.0717\n",
      "Epoch 74, Test Accuracy: 58.36538461538461%\n",
      "Epoch: 74, Loss: 0.0723\n",
      "Epoch 75, Test Accuracy: 56.506410256410255%\n",
      "Epoch: 75, Loss: 0.0709\n",
      "Epoch 76, Test Accuracy: 59.006410256410255%\n",
      "Epoch: 76, Loss: 0.0672\n",
      "Epoch 77, Test Accuracy: 59.19871794871795%\n",
      "Epoch: 77, Loss: 0.0736\n",
      "Epoch 78, Test Accuracy: 59.23076923076923%\n",
      "Epoch: 78, Loss: 0.0835\n",
      "Epoch 79, Test Accuracy: 61.92307692307692%\n",
      "Epoch: 79, Loss: 0.0900\n",
      "Epoch 80, Test Accuracy: 58.30128205128205%\n",
      "Epoch: 80, Loss: 0.1004\n",
      "Epoch 81, Test Accuracy: 59.51923076923077%\n",
      "Epoch: 81, Loss: 0.0902\n",
      "Epoch 82, Test Accuracy: 59.743589743589745%\n",
      "Epoch: 82, Loss: 0.0560\n",
      "Epoch 83, Test Accuracy: 61.955128205128204%\n",
      "Epoch: 83, Loss: 0.0556\n",
      "Epoch 84, Test Accuracy: 62.5%\n",
      "Epoch: 84, Loss: 0.0710\n",
      "Epoch 85, Test Accuracy: 61.69871794871795%\n",
      "Epoch: 85, Loss: 0.0549\n",
      "Epoch 86, Test Accuracy: 61.955128205128204%\n",
      "Epoch: 86, Loss: 0.0243\n",
      "Epoch 87, Test Accuracy: 62.30769230769231%\n",
      "Epoch: 87, Loss: 0.0270\n",
      "Epoch 88, Test Accuracy: 58.87820512820513%\n",
      "Epoch: 88, Loss: 0.0278\n",
      "Epoch 89, Test Accuracy: 57.40384615384615%\n",
      "Epoch: 89, Loss: 0.0299\n",
      "Epoch 90, Test Accuracy: 60.73717948717949%\n",
      "Epoch: 90, Loss: 0.0203\n",
      "Epoch 91, Test Accuracy: 62.33974358974359%\n",
      "Epoch: 91, Loss: 0.0170\n",
      "Epoch 92, Test Accuracy: 62.21153846153846%\n",
      "Epoch: 92, Loss: 0.0110\n",
      "Epoch 93, Test Accuracy: 64.48717948717949%\n",
      "Epoch: 93, Loss: 0.0120\n",
      "Epoch 94, Test Accuracy: 63.94230769230769%\n",
      "Epoch: 94, Loss: 0.0136\n",
      "Epoch 95, Test Accuracy: 62.94871794871795%\n",
      "Epoch: 95, Loss: 0.0154\n",
      "Epoch 96, Test Accuracy: 63.333333333333336%\n",
      "Epoch: 96, Loss: 0.0195\n",
      "Epoch 97, Test Accuracy: 61.73076923076923%\n",
      "Epoch: 97, Loss: 0.0213\n",
      "Epoch 98, Test Accuracy: 62.59615384615385%\n",
      "Epoch: 98, Loss: 0.0274\n",
      "Epoch 99, Test Accuracy: 62.37179487179487%\n",
      "Epoch: 99, Loss: 0.0304\n",
      "Epoch 100, Test Accuracy: 63.044871794871796%\n",
      "Epoch: 100, Loss: 0.0274\n",
      "Epoch 101, Test Accuracy: 59.42307692307692%\n",
      "Epoch: 101, Loss: 0.0344\n",
      "Epoch 102, Test Accuracy: 60.032051282051285%\n",
      "Epoch: 102, Loss: 0.0267\n",
      "Epoch 103, Test Accuracy: 62.37179487179487%\n",
      "Epoch: 103, Loss: 0.0230\n",
      "Epoch 104, Test Accuracy: 61.57051282051282%\n",
      "Epoch: 104, Loss: 0.0235\n",
      "Epoch 105, Test Accuracy: 62.30769230769231%\n",
      "Epoch: 105, Loss: 0.0150\n",
      "Epoch 106, Test Accuracy: 63.68589743589744%\n",
      "Epoch: 106, Loss: 0.0141\n",
      "Epoch 107, Test Accuracy: 63.84615384615385%\n",
      "Epoch: 107, Loss: 0.0138\n",
      "Epoch 108, Test Accuracy: 62.94871794871795%\n",
      "Epoch: 108, Loss: 0.0090\n",
      "Epoch 109, Test Accuracy: 62.88461538461539%\n",
      "Epoch: 109, Loss: 0.0117\n",
      "Epoch 110, Test Accuracy: 63.46153846153846%\n",
      "Epoch: 110, Loss: 0.0200\n",
      "Epoch 111, Test Accuracy: 62.82051282051282%\n",
      "Epoch: 111, Loss: 0.0121\n",
      "Epoch 112, Test Accuracy: 65.25641025641026%\n",
      "Epoch: 112, Loss: 0.0171\n",
      "Epoch 113, Test Accuracy: 62.756410256410255%\n",
      "Epoch: 113, Loss: 0.0154\n",
      "Epoch 114, Test Accuracy: 62.532051282051285%\n",
      "Epoch: 114, Loss: 0.0246\n",
      "Epoch 115, Test Accuracy: 60.8974358974359%\n",
      "Epoch: 115, Loss: 0.0152\n",
      "Epoch 116, Test Accuracy: 62.78846153846154%\n",
      "Epoch: 116, Loss: 0.0106\n",
      "Epoch 117, Test Accuracy: 64.55128205128206%\n",
      "Epoch: 117, Loss: 0.0140\n",
      "Epoch 118, Test Accuracy: 64.19871794871794%\n",
      "Epoch: 118, Loss: 0.0197\n",
      "Epoch 119, Test Accuracy: 62.82051282051282%\n",
      "Epoch: 119, Loss: 0.0126\n",
      "Epoch 120, Test Accuracy: 64.00641025641026%\n",
      "Epoch: 120, Loss: 0.0090\n",
      "Epoch 121, Test Accuracy: 64.03846153846153%\n",
      "Epoch: 121, Loss: 0.0090\n",
      "Epoch 122, Test Accuracy: 63.717948717948715%\n",
      "Epoch: 122, Loss: 0.0081\n",
      "Epoch 123, Test Accuracy: 64.16666666666667%\n",
      "Epoch: 123, Loss: 0.0099\n",
      "Epoch 124, Test Accuracy: 62.532051282051285%\n",
      "Epoch: 124, Loss: 0.0158\n",
      "Epoch 125, Test Accuracy: 61.73076923076923%\n",
      "Epoch: 125, Loss: 0.0222\n",
      "Epoch 126, Test Accuracy: 62.33974358974359%\n",
      "Epoch: 126, Loss: 0.0240\n",
      "Epoch 127, Test Accuracy: 62.17948717948718%\n",
      "Epoch: 127, Loss: 0.0254\n",
      "Epoch 128, Test Accuracy: 60.16025641025641%\n",
      "Epoch: 128, Loss: 0.0341\n",
      "Epoch 129, Test Accuracy: 61.282051282051285%\n",
      "Epoch: 129, Loss: 0.0351\n",
      "Epoch 130, Test Accuracy: 60.57692307692308%\n",
      "Epoch: 130, Loss: 0.0454\n",
      "Epoch 131, Test Accuracy: 59.583333333333336%\n",
      "Epoch: 131, Loss: 0.0537\n",
      "Epoch 132, Test Accuracy: 59.55128205128205%\n",
      "Epoch: 132, Loss: 0.0511\n",
      "Epoch 133, Test Accuracy: 61.63461538461539%\n",
      "Epoch: 133, Loss: 0.0400\n",
      "Epoch 134, Test Accuracy: 60.60897435897436%\n",
      "Epoch: 134, Loss: 0.0533\n",
      "Epoch 135, Test Accuracy: 60.28846153846154%\n",
      "Epoch: 135, Loss: 0.0740\n",
      "Epoch 136, Test Accuracy: 61.89102564102564%\n",
      "Epoch: 136, Loss: 0.0632\n",
      "Epoch 137, Test Accuracy: 61.31410256410256%\n",
      "Epoch: 137, Loss: 0.0553\n",
      "Epoch 138, Test Accuracy: 60.12820512820513%\n",
      "Epoch: 138, Loss: 0.0332\n",
      "Epoch 139, Test Accuracy: 61.05769230769231%\n",
      "Epoch: 139, Loss: 0.0397\n",
      "Epoch 140, Test Accuracy: 61.69871794871795%\n",
      "Epoch: 140, Loss: 0.0255\n",
      "Epoch 141, Test Accuracy: 61.217948717948715%\n",
      "Epoch: 141, Loss: 0.0390\n",
      "Epoch 142, Test Accuracy: 62.30769230769231%\n",
      "Epoch: 142, Loss: 0.0249\n",
      "Epoch 143, Test Accuracy: 62.69230769230769%\n",
      "Epoch: 143, Loss: 0.0240\n",
      "Epoch 144, Test Accuracy: 60.3525641025641%\n",
      "Epoch: 144, Loss: 0.0233\n",
      "Epoch 145, Test Accuracy: 61.282051282051285%\n",
      "Epoch: 145, Loss: 0.0228\n",
      "Epoch 146, Test Accuracy: 60.993589743589745%\n",
      "Epoch: 146, Loss: 0.0343\n",
      "Epoch 147, Test Accuracy: 61.25%\n",
      "Epoch: 147, Loss: 0.0169\n",
      "Epoch 148, Test Accuracy: 62.37179487179487%\n",
      "Epoch: 148, Loss: 0.0232\n",
      "Epoch 149, Test Accuracy: 61.217948717948715%\n",
      "Epoch: 149, Loss: 0.0242\n",
      "Epoch 150, Test Accuracy: 61.37820512820513%\n",
      "Epoch: 150, Loss: 0.0250\n",
      "Epoch 151, Test Accuracy: 60.64102564102564%\n",
      "Epoch: 151, Loss: 0.0212\n",
      "Epoch 152, Test Accuracy: 61.31410256410256%\n",
      "Epoch: 152, Loss: 0.0247\n",
      "Epoch 153, Test Accuracy: 61.282051282051285%\n",
      "Epoch: 153, Loss: 0.0132\n",
      "Epoch 154, Test Accuracy: 58.717948717948715%\n",
      "Epoch: 154, Loss: 0.0309\n",
      "Epoch 155, Test Accuracy: 61.92307692307692%\n",
      "Epoch: 155, Loss: 0.0136\n",
      "Epoch 156, Test Accuracy: 62.083333333333336%\n",
      "Epoch: 156, Loss: 0.0304\n",
      "Epoch 157, Test Accuracy: 62.532051282051285%\n",
      "Epoch: 157, Loss: 0.0242\n",
      "Epoch 158, Test Accuracy: 60.416666666666664%\n",
      "Epoch: 158, Loss: 0.0279\n",
      "Epoch 159, Test Accuracy: 62.33974358974359%\n",
      "Epoch: 159, Loss: 0.0197\n",
      "Epoch 160, Test Accuracy: 61.89102564102564%\n",
      "Epoch: 160, Loss: 0.0224\n",
      "Epoch 161, Test Accuracy: 62.37179487179487%\n",
      "Epoch: 161, Loss: 0.0211\n",
      "Epoch 162, Test Accuracy: 62.66025641025641%\n",
      "Epoch: 162, Loss: 0.0312\n",
      "Epoch 163, Test Accuracy: 61.44230769230769%\n",
      "Epoch: 163, Loss: 0.0355\n",
      "Epoch 164, Test Accuracy: 60.92948717948718%\n",
      "Epoch: 164, Loss: 0.0296\n",
      "Epoch 165, Test Accuracy: 61.53846153846154%\n",
      "Epoch: 165, Loss: 0.0234\n",
      "Epoch 166, Test Accuracy: 63.52564102564103%\n",
      "Epoch: 166, Loss: 0.0139\n",
      "Epoch 167, Test Accuracy: 64.2948717948718%\n",
      "Epoch: 167, Loss: 0.0130\n",
      "Epoch 168, Test Accuracy: 63.58974358974359%\n",
      "Epoch: 168, Loss: 0.0255\n",
      "Epoch 169, Test Accuracy: 62.59615384615385%\n",
      "Epoch: 169, Loss: 0.0165\n",
      "Epoch 170, Test Accuracy: 62.083333333333336%\n",
      "Epoch: 170, Loss: 0.0195\n",
      "Epoch 171, Test Accuracy: 61.53846153846154%\n",
      "Epoch: 171, Loss: 0.0128\n",
      "Epoch 172, Test Accuracy: 60.96153846153846%\n",
      "Epoch: 172, Loss: 0.0099\n",
      "Epoch 173, Test Accuracy: 63.42948717948718%\n",
      "Epoch: 173, Loss: 0.0042\n",
      "Epoch 174, Test Accuracy: 64.07051282051282%\n",
      "Epoch: 174, Loss: 0.0118\n",
      "Epoch 175, Test Accuracy: 65.8974358974359%\n",
      "Epoch: 175, Loss: 0.0040\n",
      "Epoch 176, Test Accuracy: 64.8076923076923%\n",
      "Epoch: 176, Loss: 0.0125\n",
      "Epoch 177, Test Accuracy: 64.32692307692308%\n",
      "Epoch: 177, Loss: 0.0124\n",
      "Epoch 178, Test Accuracy: 62.94871794871795%\n",
      "Epoch: 178, Loss: 0.0105\n",
      "Epoch 179, Test Accuracy: 63.782051282051285%\n",
      "Epoch: 179, Loss: 0.0116\n",
      "Epoch 180, Test Accuracy: 61.41025641025641%\n",
      "Epoch: 180, Loss: 0.0068\n",
      "Epoch 181, Test Accuracy: 63.333333333333336%\n",
      "Epoch: 181, Loss: 0.0073\n",
      "Epoch 182, Test Accuracy: 64.42307692307692%\n",
      "Epoch: 182, Loss: 0.0116\n",
      "Epoch 183, Test Accuracy: 64.6474358974359%\n",
      "Epoch: 183, Loss: 0.0049\n",
      "Epoch 184, Test Accuracy: 64.13461538461539%\n",
      "Epoch: 184, Loss: 0.0029\n",
      "Epoch 185, Test Accuracy: 64.4551282051282%\n",
      "Epoch: 185, Loss: 0.0016\n",
      "Epoch 186, Test Accuracy: 64.39102564102564%\n",
      "Epoch: 186, Loss: 0.0013\n",
      "Epoch 187, Test Accuracy: 65.0%\n",
      "Epoch: 187, Loss: 0.0035\n",
      "Epoch 188, Test Accuracy: 65.38461538461539%\n",
      "Epoch: 188, Loss: 0.0021\n",
      "Epoch 189, Test Accuracy: 64.87179487179488%\n",
      "Epoch: 189, Loss: 0.0033\n",
      "Epoch 190, Test Accuracy: 63.493589743589745%\n",
      "Epoch: 190, Loss: 0.0037\n",
      "Epoch 191, Test Accuracy: 64.13461538461539%\n",
      "Epoch: 191, Loss: 0.0028\n",
      "Epoch 192, Test Accuracy: 64.03846153846153%\n",
      "Epoch: 192, Loss: 0.0035\n",
      "Epoch 193, Test Accuracy: 64.13461538461539%\n",
      "Epoch: 193, Loss: 0.0052\n",
      "Epoch 194, Test Accuracy: 63.94230769230769%\n",
      "Epoch: 194, Loss: 0.0015\n",
      "Epoch 195, Test Accuracy: 63.23717948717949%\n",
      "Epoch: 195, Loss: 0.0054\n",
      "Epoch 196, Test Accuracy: 64.07051282051282%\n",
      "Epoch: 196, Loss: 0.0052\n",
      "Epoch 197, Test Accuracy: 63.46153846153846%\n",
      "Epoch: 197, Loss: 0.0013\n",
      "Epoch 198, Test Accuracy: 63.68589743589744%\n",
      "Epoch: 198, Loss: 0.0036\n",
      "Epoch 199, Test Accuracy: 63.10897435897436%\n",
      "Epoch: 199, Loss: 0.0022\n",
      "Epoch 200, Test Accuracy: 62.756410256410255%\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "# 训练模型\n",
    "num_epochs = 200\n",
    "\n",
    "momentum = 0.9\n",
    "weight_decay = 0\n",
    "# weight_decay = 1e-4 # L2正则化系数\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay, momentum=momentum)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    train_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    print('Epoch: {}, Loss: {:.4f}'.format(epoch, train_loss))\n",
    "\n",
    "    # 在测试集上评估模型\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f\"Epoch {epoch+1}, Test Accuracy: {100 * correct / total}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  6.,   6.,   6.,   6.,   6.,   6.,  18.,  18.,  18.,  18.,  18.,  18.,\n",
      "         18.,  18.,  18.,  18., -18.,  18.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def layer_wise_align_on_vector(vector, name_shapes_to_aggregate):\n",
    "    start = 0\n",
    "    for name, shape in name_shapes_to_aggregate.items():\n",
    "        # 计算vector中对应位置的max\n",
    "        max_value = torch.max(torch.abs(vector[start:start+np.prod(shape)]))\n",
    "        # 计算vector中对应位置的sign\n",
    "        sign = torch.sign(vector[start:start+np.prod(shape)])\n",
    "\n",
    "        vector[start:start+np.prod(shape)] = sign * max_value\n",
    "        start += np.prod(shape)\n",
    "    return vector\n",
    "\n",
    "# 例子\n",
    "test_vector = torch.arange(1, 19).float()\n",
    "test_vector[-2] = -10\n",
    "# 模型的名字和形状\n",
    "name_shapes = {}\n",
    "name_shapes['a'] = (2, 3)\n",
    "name_shapes['b'] = (3, 4)\n",
    "\n",
    "# 对test_vector进行layer-wise的align\n",
    "aligned_vector = layer_wise_align_on_vector(test_vector, name_shapes)\n",
    "print(aligned_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 10% 数据 128 0.1\n",
    "# Epoch: 0, Loss: 3.0529\n",
    "# Epoch 1, Test Accuracy: 8.333333333333334%\n",
    "# Epoch: 1, Loss: 3.8318\n",
    "# Epoch 2, Test Accuracy: 8.333333333333334%\n",
    "# Epoch: 2, Loss: 3.9782\n",
    "# Epoch 3, Test Accuracy: 8.333333333333334%\n",
    "# Epoch: 3, Loss: 3.3805\n",
    "# Epoch 4, Test Accuracy: 8.397435897435898%\n",
    "# Epoch: 4, Loss: 2.5526\n",
    "# Epoch 5, Test Accuracy: 10.48076923076923%\n",
    "# Epoch: 5, Loss: 2.3023\n",
    "# Epoch 6, Test Accuracy: 12.916666666666666%\n",
    "# Epoch: 6, Loss: 2.1453\n",
    "# Epoch 7, Test Accuracy: 25.32051282051282%\n",
    "# Epoch: 7, Loss: 2.1760\n",
    "# Epoch 8, Test Accuracy: 20.865384615384617%\n",
    "# Epoch: 8, Loss: 2.0295\n",
    "# Epoch 9, Test Accuracy: 22.98076923076923%\n",
    "# Epoch: 9, Loss: 1.8701\n",
    "# Epoch 10, Test Accuracy: 31.346153846153847%\n",
    "# Epoch: 10, Loss: 1.8729\n",
    "# Epoch 11, Test Accuracy: 31.41025641025641%\n",
    "# Epoch: 11, Loss: 1.7991\n",
    "# Epoch 12, Test Accuracy: 36.08974358974359%\n",
    "# Epoch: 12, Loss: 1.7752\n",
    "# Epoch 13, Test Accuracy: 30.92948717948718%\n",
    "# Epoch: 13, Loss: 1.7483\n",
    "# Epoch 14, Test Accuracy: 35.0%\n",
    "# Epoch: 14, Loss: 1.6620\n",
    "# Epoch 15, Test Accuracy: 41.794871794871796%\n",
    "# Epoch: 15, Loss: 1.5857\n",
    "# Epoch 16, Test Accuracy: 44.07051282051282%\n",
    "# Epoch: 16, Loss: 1.4633\n",
    "# Epoch 17, Test Accuracy: 46.02564102564103%\n",
    "# Epoch: 17, Loss: 1.4129\n",
    "# Epoch 18, Test Accuracy: 41.82692307692308%\n",
    "# Epoch: 18, Loss: 1.3934\n",
    "# Epoch 19, Test Accuracy: 46.6025641025641%\n",
    "# Epoch: 19, Loss: 1.3523\n",
    "# Epoch 20, Test Accuracy: 45.3525641025641%\n",
    "# Epoch: 20, Loss: 1.3048\n",
    "# Epoch 21, Test Accuracy: 47.21153846153846%\n",
    "# Epoch: 21, Loss: 1.2084\n",
    "# Epoch 22, Test Accuracy: 39.07051282051282%\n",
    "# Epoch: 22, Loss: 1.2076\n",
    "# Epoch 23, Test Accuracy: 34.743589743589745%\n",
    "# Epoch: 23, Loss: 1.1118\n",
    "# Epoch 24, Test Accuracy: 49.51923076923077%\n",
    "# Epoch: 24, Loss: 1.0648\n",
    "# Epoch 25, Test Accuracy: 40.16025641025641%\n",
    "# Epoch: 25, Loss: 1.1133\n",
    "# Epoch 26, Test Accuracy: 44.93589743589744%\n",
    "# Epoch: 26, Loss: 1.0767\n",
    "# Epoch 27, Test Accuracy: 49.67948717948718%\n",
    "# Epoch: 27, Loss: 0.9822\n",
    "# Epoch 28, Test Accuracy: 51.31410256410256%\n",
    "# Epoch: 28, Loss: 0.8542\n",
    "# Epoch 29, Test Accuracy: 48.26923076923077%\n",
    "# Epoch: 29, Loss: 0.8770\n",
    "# Epoch 30, Test Accuracy: 53.87820512820513%\n",
    "# Epoch: 30, Loss: 0.8391\n",
    "# Epoch 31, Test Accuracy: 44.35897435897436%\n",
    "# Epoch: 31, Loss: 0.8143\n",
    "# Epoch 32, Test Accuracy: 42.88461538461539%\n",
    "# Epoch: 32, Loss: 0.7574\n",
    "# Epoch 33, Test Accuracy: 52.37179487179487%\n",
    "# Epoch: 33, Loss: 0.7259\n",
    "# Epoch 34, Test Accuracy: 54.006410256410255%\n",
    "# Epoch: 34, Loss: 0.6935\n",
    "# Epoch 35, Test Accuracy: 53.55769230769231%\n",
    "# Epoch: 35, Loss: 0.6063\n",
    "# Epoch 36, Test Accuracy: 56.05769230769231%\n",
    "# Epoch: 36, Loss: 0.5402\n",
    "# Epoch 37, Test Accuracy: 47.94871794871795%\n",
    "# Epoch: 37, Loss: 0.4863\n",
    "# Epoch 38, Test Accuracy: 56.31410256410256%\n",
    "# Epoch: 38, Loss: 0.5154\n",
    "# Epoch 39, Test Accuracy: 55.92948717948718%\n",
    "# Epoch: 39, Loss: 0.5323\n",
    "# Epoch 40, Test Accuracy: 59.006410256410255%\n",
    "# Epoch: 40, Loss: 0.5209\n",
    "# Epoch 41, Test Accuracy: 53.493589743589745%\n",
    "# Epoch: 41, Loss: 0.4414\n",
    "# Epoch 42, Test Accuracy: 51.955128205128204%\n",
    "# Epoch: 42, Loss: 0.3652\n",
    "# Epoch 43, Test Accuracy: 50.51282051282051%\n",
    "# Epoch: 43, Loss: 0.4011\n",
    "# Epoch 44, Test Accuracy: 53.87820512820513%\n",
    "# Epoch: 44, Loss: 0.3776\n",
    "# Epoch 45, Test Accuracy: 57.5%\n",
    "# Epoch: 45, Loss: 0.3565\n",
    "# Epoch 46, Test Accuracy: 49.35897435897436%\n",
    "# Epoch: 46, Loss: 0.3167\n",
    "# Epoch 47, Test Accuracy: 50.64102564102564%\n",
    "# Epoch: 47, Loss: 0.2817\n",
    "# Epoch 48, Test Accuracy: 54.80769230769231%\n",
    "# Epoch: 48, Loss: 0.3261\n",
    "# Epoch 49, Test Accuracy: 58.97435897435897%\n",
    "# Epoch: 49, Loss: 0.3076\n",
    "# Epoch 50, Test Accuracy: 58.17307692307692%\n",
    "# Epoch: 50, Loss: 0.2410\n",
    "# Epoch 51, Test Accuracy: 56.08974358974359%\n",
    "# Epoch: 51, Loss: 0.2031\n",
    "# Epoch 52, Test Accuracy: 59.19871794871795%\n",
    "# Epoch: 52, Loss: 0.2481\n",
    "# Epoch 53, Test Accuracy: 56.53846153846154%\n",
    "# Epoch: 53, Loss: 0.2053\n",
    "# Epoch 54, Test Accuracy: 52.756410256410255%\n",
    "# Epoch: 54, Loss: 0.2335\n",
    "# Epoch 55, Test Accuracy: 55.0%\n",
    "# Epoch: 55, Loss: 0.1873\n",
    "# Epoch 56, Test Accuracy: 54.294871794871796%\n",
    "# Epoch: 56, Loss: 0.1966\n",
    "# Epoch 57, Test Accuracy: 53.42948717948718%\n",
    "# Epoch: 57, Loss: 0.1938\n",
    "# Epoch 58, Test Accuracy: 55.16025641025641%\n",
    "# Epoch: 58, Loss: 0.1708\n",
    "# Epoch 59, Test Accuracy: 57.11538461538461%\n",
    "# Epoch: 59, Loss: 0.1617\n",
    "# Epoch 60, Test Accuracy: 58.01282051282051%\n",
    "# Epoch: 60, Loss: 0.1279\n",
    "# Epoch 61, Test Accuracy: 55.64102564102564%\n",
    "# Epoch: 61, Loss: 0.1364\n",
    "# Epoch 62, Test Accuracy: 56.05769230769231%\n",
    "# Epoch: 62, Loss: 0.1989\n",
    "# Epoch 63, Test Accuracy: 56.666666666666664%\n",
    "# Epoch: 63, Loss: 0.2430\n",
    "# Epoch 64, Test Accuracy: 54.90384615384615%\n",
    "# Epoch: 64, Loss: 0.1944\n",
    "# Epoch 65, Test Accuracy: 55.64102564102564%\n",
    "# Epoch: 65, Loss: 0.1556\n",
    "# Epoch 66, Test Accuracy: 57.82051282051282%\n",
    "# Epoch: 66, Loss: 0.1415\n",
    "# Epoch 67, Test Accuracy: 61.57051282051282%\n",
    "# Epoch: 67, Loss: 0.1128\n",
    "# Epoch 68, Test Accuracy: 56.82692307692308%\n",
    "# Epoch: 68, Loss: 0.1268\n",
    "# Epoch 69, Test Accuracy: 57.27564102564103%\n",
    "# Epoch: 69, Loss: 0.1312\n",
    "# Epoch 70, Test Accuracy: 59.03846153846154%\n",
    "# Epoch: 70, Loss: 0.1259\n",
    "# Epoch 71, Test Accuracy: 55.60897435897436%\n",
    "# Epoch: 71, Loss: 0.1524\n",
    "# Epoch 72, Test Accuracy: 58.91025641025641%\n",
    "# Epoch: 72, Loss: 0.0926\n",
    "# Epoch 73, Test Accuracy: 62.11538461538461%\n",
    "# Epoch: 73, Loss: 0.0717\n",
    "# Epoch 74, Test Accuracy: 58.36538461538461%\n",
    "# Epoch: 74, Loss: 0.0723\n",
    "# Epoch 75, Test Accuracy: 56.506410256410255%\n",
    "# Epoch: 75, Loss: 0.0709\n",
    "# Epoch 76, Test Accuracy: 59.006410256410255%\n",
    "# Epoch: 76, Loss: 0.0672\n",
    "# Epoch 77, Test Accuracy: 59.19871794871795%\n",
    "# Epoch: 77, Loss: 0.0736\n",
    "# Epoch 78, Test Accuracy: 59.23076923076923%\n",
    "# Epoch: 78, Loss: 0.0835\n",
    "# Epoch 79, Test Accuracy: 61.92307692307692%\n",
    "# Epoch: 79, Loss: 0.0900\n",
    "# Epoch 80, Test Accuracy: 58.30128205128205%\n",
    "# Epoch: 80, Loss: 0.1004\n",
    "# Epoch 81, Test Accuracy: 59.51923076923077%\n",
    "# Epoch: 81, Loss: 0.0902\n",
    "# Epoch 82, Test Accuracy: 59.743589743589745%\n",
    "# Epoch: 82, Loss: 0.0560\n",
    "# Epoch 83, Test Accuracy: 61.955128205128204%\n",
    "# Epoch: 83, Loss: 0.0556\n",
    "# Epoch 84, Test Accuracy: 62.5%\n",
    "# Epoch: 84, Loss: 0.0710\n",
    "# Epoch 85, Test Accuracy: 61.69871794871795%\n",
    "# Epoch: 85, Loss: 0.0549\n",
    "# Epoch 86, Test Accuracy: 61.955128205128204%\n",
    "# Epoch: 86, Loss: 0.0243\n",
    "# Epoch 87, Test Accuracy: 62.30769230769231%\n",
    "# Epoch: 87, Loss: 0.0270\n",
    "# Epoch 88, Test Accuracy: 58.87820512820513%\n",
    "# Epoch: 88, Loss: 0.0278\n",
    "# Epoch 89, Test Accuracy: 57.40384615384615%\n",
    "# Epoch: 89, Loss: 0.0299\n",
    "# Epoch 90, Test Accuracy: 60.73717948717949%\n",
    "# Epoch: 90, Loss: 0.0203\n",
    "# Epoch 91, Test Accuracy: 62.33974358974359%\n",
    "# Epoch: 91, Loss: 0.0170\n",
    "# Epoch 92, Test Accuracy: 62.21153846153846%\n",
    "# Epoch: 92, Loss: 0.0110\n",
    "# Epoch 93, Test Accuracy: 64.48717948717949%\n",
    "# Epoch: 93, Loss: 0.0120\n",
    "# Epoch 94, Test Accuracy: 63.94230769230769%\n",
    "# Epoch: 94, Loss: 0.0136\n",
    "# Epoch 95, Test Accuracy: 62.94871794871795%\n",
    "# Epoch: 95, Loss: 0.0154\n",
    "# Epoch 96, Test Accuracy: 63.333333333333336%\n",
    "# Epoch: 96, Loss: 0.0195\n",
    "# Epoch 97, Test Accuracy: 61.73076923076923%\n",
    "# Epoch: 97, Loss: 0.0213\n",
    "# Epoch 98, Test Accuracy: 62.59615384615385%\n",
    "# Epoch: 98, Loss: 0.0274\n",
    "# Epoch 99, Test Accuracy: 62.37179487179487%\n",
    "# Epoch: 99, Loss: 0.0304\n",
    "# Epoch 100, Test Accuracy: 63.044871794871796%\n",
    "# Epoch: 100, Loss: 0.0274\n",
    "# Epoch 101, Test Accuracy: 59.42307692307692%\n",
    "# Epoch: 101, Loss: 0.0344\n",
    "# Epoch 102, Test Accuracy: 60.032051282051285%\n",
    "# Epoch: 102, Loss: 0.0267\n",
    "# Epoch 103, Test Accuracy: 62.37179487179487%\n",
    "# Epoch: 103, Loss: 0.0230\n",
    "# Epoch 104, Test Accuracy: 61.57051282051282%\n",
    "# Epoch: 104, Loss: 0.0235\n",
    "# Epoch 105, Test Accuracy: 62.30769230769231%\n",
    "# Epoch: 105, Loss: 0.0150\n",
    "# Epoch 106, Test Accuracy: 63.68589743589744%\n",
    "# Epoch: 106, Loss: 0.0141\n",
    "# Epoch 107, Test Accuracy: 63.84615384615385%\n",
    "# Epoch: 107, Loss: 0.0138\n",
    "# Epoch 108, Test Accuracy: 62.94871794871795%\n",
    "# Epoch: 108, Loss: 0.0090\n",
    "# Epoch 109, Test Accuracy: 62.88461538461539%\n",
    "# Epoch: 109, Loss: 0.0117\n",
    "# Epoch 110, Test Accuracy: 63.46153846153846%\n",
    "# Epoch: 110, Loss: 0.0200\n",
    "# Epoch 111, Test Accuracy: 62.82051282051282%\n",
    "# Epoch: 111, Loss: 0.0121\n",
    "# Epoch 112, Test Accuracy: 65.25641025641026%\n",
    "# Epoch: 112, Loss: 0.0171\n",
    "# Epoch 113, Test Accuracy: 62.756410256410255%\n",
    "# Epoch: 113, Loss: 0.0154\n",
    "# Epoch 114, Test Accuracy: 62.532051282051285%\n",
    "# Epoch: 114, Loss: 0.0246\n",
    "# Epoch 115, Test Accuracy: 60.8974358974359%\n",
    "# Epoch: 115, Loss: 0.0152\n",
    "# Epoch 116, Test Accuracy: 62.78846153846154%\n",
    "# Epoch: 116, Loss: 0.0106\n",
    "# Epoch 117, Test Accuracy: 64.55128205128206%\n",
    "# Epoch: 117, Loss: 0.0140\n",
    "# Epoch 118, Test Accuracy: 64.19871794871794%\n",
    "# Epoch: 118, Loss: 0.0197\n",
    "# Epoch 119, Test Accuracy: 62.82051282051282%\n",
    "# Epoch: 119, Loss: 0.0126\n",
    "# Epoch 120, Test Accuracy: 64.00641025641026%\n",
    "# Epoch: 120, Loss: 0.0090\n",
    "# Epoch 121, Test Accuracy: 64.03846153846153%\n",
    "# Epoch: 121, Loss: 0.0090\n",
    "# Epoch 122, Test Accuracy: 63.717948717948715%\n",
    "# Epoch: 122, Loss: 0.0081\n",
    "# Epoch 123, Test Accuracy: 64.16666666666667%\n",
    "# Epoch: 123, Loss: 0.0099\n",
    "# Epoch 124, Test Accuracy: 62.532051282051285%\n",
    "# Epoch: 124, Loss: 0.0158\n",
    "# Epoch 125, Test Accuracy: 61.73076923076923%\n",
    "# Epoch: 125, Loss: 0.0222\n",
    "# Epoch 126, Test Accuracy: 62.33974358974359%\n",
    "# Epoch: 126, Loss: 0.0240\n",
    "# Epoch 127, Test Accuracy: 62.17948717948718%\n",
    "# Epoch: 127, Loss: 0.0254\n",
    "# Epoch 128, Test Accuracy: 60.16025641025641%\n",
    "# Epoch: 128, Loss: 0.0341\n",
    "# Epoch 129, Test Accuracy: 61.282051282051285%\n",
    "# Epoch: 129, Loss: 0.0351\n",
    "# Epoch 130, Test Accuracy: 60.57692307692308%\n",
    "# Epoch: 130, Loss: 0.0454\n",
    "# Epoch 131, Test Accuracy: 59.583333333333336%\n",
    "# Epoch: 131, Loss: 0.0537\n",
    "# Epoch 132, Test Accuracy: 59.55128205128205%\n",
    "# Epoch: 132, Loss: 0.0511\n",
    "# Epoch 133, Test Accuracy: 61.63461538461539%\n",
    "# Epoch: 133, Loss: 0.0400\n",
    "# Epoch 134, Test Accuracy: 60.60897435897436%\n",
    "# Epoch: 134, Loss: 0.0533\n",
    "# Epoch 135, Test Accuracy: 60.28846153846154%\n",
    "# Epoch: 135, Loss: 0.0740\n",
    "# Epoch 136, Test Accuracy: 61.89102564102564%\n",
    "# Epoch: 136, Loss: 0.0632\n",
    "# Epoch 137, Test Accuracy: 61.31410256410256%\n",
    "# Epoch: 137, Loss: 0.0553\n",
    "# Epoch 138, Test Accuracy: 60.12820512820513%\n",
    "# Epoch: 138, Loss: 0.0332\n",
    "# Epoch 139, Test Accuracy: 61.05769230769231%\n",
    "# Epoch: 139, Loss: 0.0397\n",
    "# Epoch 140, Test Accuracy: 61.69871794871795%\n",
    "# Epoch: 140, Loss: 0.0255\n",
    "# Epoch 141, Test Accuracy: 61.217948717948715%\n",
    "# Epoch: 141, Loss: 0.0390\n",
    "# Epoch 142, Test Accuracy: 62.30769230769231%\n",
    "# Epoch: 142, Loss: 0.0249\n",
    "# Epoch 143, Test Accuracy: 62.69230769230769%\n",
    "# Epoch: 143, Loss: 0.0240\n",
    "# Epoch 144, Test Accuracy: 60.3525641025641%\n",
    "# Epoch: 144, Loss: 0.0233\n",
    "# Epoch 145, Test Accuracy: 61.282051282051285%\n",
    "# Epoch: 145, Loss: 0.0228\n",
    "# Epoch 146, Test Accuracy: 60.993589743589745%\n",
    "# Epoch: 146, Loss: 0.0343\n",
    "# Epoch 147, Test Accuracy: 61.25%\n",
    "# Epoch: 147, Loss: 0.0169\n",
    "# Epoch 148, Test Accuracy: 62.37179487179487%\n",
    "# Epoch: 148, Loss: 0.0232\n",
    "# Epoch 149, Test Accuracy: 61.217948717948715%\n",
    "# Epoch: 149, Loss: 0.0242\n",
    "# Epoch 150, Test Accuracy: 61.37820512820513%\n",
    "# Epoch: 150, Loss: 0.0250\n",
    "# Epoch 151, Test Accuracy: 60.64102564102564%\n",
    "# Epoch: 151, Loss: 0.0212\n",
    "# Epoch 152, Test Accuracy: 61.31410256410256%\n",
    "# Epoch: 152, Loss: 0.0247\n",
    "# Epoch 153, Test Accuracy: 61.282051282051285%\n",
    "# Epoch: 153, Loss: 0.0132\n",
    "# Epoch 154, Test Accuracy: 58.717948717948715%\n",
    "# Epoch: 154, Loss: 0.0309\n",
    "# Epoch 155, Test Accuracy: 61.92307692307692%\n",
    "# Epoch: 155, Loss: 0.0136\n",
    "# Epoch 156, Test Accuracy: 62.083333333333336%\n",
    "# Epoch: 156, Loss: 0.0304\n",
    "# Epoch 157, Test Accuracy: 62.532051282051285%\n",
    "# Epoch: 157, Loss: 0.0242\n",
    "# Epoch 158, Test Accuracy: 60.416666666666664%\n",
    "# Epoch: 158, Loss: 0.0279\n",
    "# Epoch 159, Test Accuracy: 62.33974358974359%\n",
    "# Epoch: 159, Loss: 0.0197\n",
    "# Epoch 160, Test Accuracy: 61.89102564102564%\n",
    "# Epoch: 160, Loss: 0.0224\n",
    "# Epoch 161, Test Accuracy: 62.37179487179487%\n",
    "# Epoch: 161, Loss: 0.0211\n",
    "# Epoch 162, Test Accuracy: 62.66025641025641%\n",
    "# Epoch: 162, Loss: 0.0312\n",
    "# Epoch 163, Test Accuracy: 61.44230769230769%\n",
    "# Epoch: 163, Loss: 0.0355\n",
    "# Epoch 164, Test Accuracy: 60.92948717948718%\n",
    "# Epoch: 164, Loss: 0.0296\n",
    "# Epoch 165, Test Accuracy: 61.53846153846154%\n",
    "# Epoch: 165, Loss: 0.0234\n",
    "# Epoch 166, Test Accuracy: 63.52564102564103%\n",
    "# Epoch: 166, Loss: 0.0139\n",
    "# Epoch 167, Test Accuracy: 64.2948717948718%\n",
    "# Epoch: 167, Loss: 0.0130\n",
    "# Epoch 168, Test Accuracy: 63.58974358974359%\n",
    "# Epoch: 168, Loss: 0.0255\n",
    "# Epoch 169, Test Accuracy: 62.59615384615385%\n",
    "# Epoch: 169, Loss: 0.0165\n",
    "# Epoch 170, Test Accuracy: 62.083333333333336%\n",
    "# Epoch: 170, Loss: 0.0195\n",
    "# Epoch 171, Test Accuracy: 61.53846153846154%\n",
    "# Epoch: 171, Loss: 0.0128\n",
    "# Epoch 172, Test Accuracy: 60.96153846153846%\n",
    "# Epoch: 172, Loss: 0.0099\n",
    "# Epoch 173, Test Accuracy: 63.42948717948718%\n",
    "# Epoch: 173, Loss: 0.0042\n",
    "# Epoch 174, Test Accuracy: 64.07051282051282%\n",
    "# Epoch: 174, Loss: 0.0118\n",
    "# Epoch 175, Test Accuracy: 65.8974358974359%\n",
    "# Epoch: 175, Loss: 0.0040\n",
    "# Epoch 176, Test Accuracy: 64.8076923076923%\n",
    "# Epoch: 176, Loss: 0.0125\n",
    "# Epoch 177, Test Accuracy: 64.32692307692308%\n",
    "# Epoch: 177, Loss: 0.0124\n",
    "# Epoch 178, Test Accuracy: 62.94871794871795%\n",
    "# Epoch: 178, Loss: 0.0105\n",
    "# Epoch 179, Test Accuracy: 63.782051282051285%\n",
    "# Epoch: 179, Loss: 0.0116\n",
    "# Epoch 180, Test Accuracy: 61.41025641025641%\n",
    "# Epoch: 180, Loss: 0.0068\n",
    "# Epoch 181, Test Accuracy: 63.333333333333336%\n",
    "# Epoch: 181, Loss: 0.0073\n",
    "# Epoch 182, Test Accuracy: 64.42307692307692%\n",
    "# Epoch: 182, Loss: 0.0116\n",
    "# Epoch 183, Test Accuracy: 64.6474358974359%\n",
    "# Epoch: 183, Loss: 0.0049\n",
    "# Epoch 184, Test Accuracy: 64.13461538461539%\n",
    "# Epoch: 184, Loss: 0.0029\n",
    "# Epoch 185, Test Accuracy: 64.4551282051282%\n",
    "# Epoch: 185, Loss: 0.0016\n",
    "# Epoch 186, Test Accuracy: 64.39102564102564%\n",
    "# Epoch: 186, Loss: 0.0013\n",
    "# Epoch 187, Test Accuracy: 65.0%\n",
    "# Epoch: 187, Loss: 0.0035\n",
    "# Epoch 188, Test Accuracy: 65.38461538461539%\n",
    "# Epoch: 188, Loss: 0.0021\n",
    "# Epoch 189, Test Accuracy: 64.87179487179488%\n",
    "# Epoch: 189, Loss: 0.0033\n",
    "# Epoch 190, Test Accuracy: 63.493589743589745%\n",
    "# Epoch: 190, Loss: 0.0037\n",
    "# Epoch 191, Test Accuracy: 64.13461538461539%\n",
    "# Epoch: 191, Loss: 0.0028\n",
    "# Epoch 192, Test Accuracy: 64.03846153846153%\n",
    "# Epoch: 192, Loss: 0.0035\n",
    "# Epoch 193, Test Accuracy: 64.13461538461539%\n",
    "# Epoch: 193, Loss: 0.0052\n",
    "# Epoch 194, Test Accuracy: 63.94230769230769%\n",
    "# Epoch: 194, Loss: 0.0015\n",
    "# Epoch 195, Test Accuracy: 63.23717948717949%\n",
    "# Epoch: 195, Loss: 0.0054\n",
    "# Epoch 196, Test Accuracy: 64.07051282051282%\n",
    "# Epoch: 196, Loss: 0.0052\n",
    "# Epoch 197, Test Accuracy: 63.46153846153846%\n",
    "# Epoch: 197, Loss: 0.0013\n",
    "# Epoch 198, Test Accuracy: 63.68589743589744%\n",
    "# Epoch: 198, Loss: 0.0036\n",
    "# Epoch 199, Test Accuracy: 63.10897435897436%\n",
    "# Epoch: 199, Loss: 0.0022\n",
    "# Epoch 200, Test Accuracy: 62.756410256410255%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 64\n",
    "# learning_rate = 0.01\n",
    "\n",
    "# Epoch: 0, Loss: 2.4985\n",
    "# Epoch 1, Test Accuracy: 8.333333333333334%\n",
    "# Epoch: 1, Loss: 2.3034\n",
    "# Epoch 2, Test Accuracy: 11.057692307692308%\n",
    "# Epoch: 2, Loss: 2.1631\n",
    "# Epoch 3, Test Accuracy: 31.314102564102566%\n",
    "# Epoch: 3, Loss: 2.0737\n",
    "# Epoch 4, Test Accuracy: 29.455128205128204%\n",
    "# Epoch: 4, Loss: 2.0066\n",
    "# Epoch 5, Test Accuracy: 27.78846153846154%\n",
    "# Epoch: 5, Loss: 1.9515\n",
    "# Epoch 6, Test Accuracy: 39.93589743589744%\n",
    "# Epoch: 6, Loss: 1.8830\n",
    "# Epoch 7, Test Accuracy: 46.34615384615385%\n",
    "# Epoch: 7, Loss: 1.8078\n",
    "# Epoch 8, Test Accuracy: 36.98717948717949%\n",
    "# Epoch: 8, Loss: 1.7677\n",
    "# Epoch 9, Test Accuracy: 50.67307692307692%\n",
    "# Epoch: 9, Loss: 1.6901\n",
    "# Epoch 10, Test Accuracy: 53.84615384615385%\n",
    "# Epoch: 10, Loss: 1.7320\n",
    "# Epoch 11, Test Accuracy: 50.0%\n",
    "# Epoch: 11, Loss: 1.6341\n",
    "# Epoch 12, Test Accuracy: 47.756410256410255%\n",
    "# Epoch: 12, Loss: 1.5898\n",
    "# Epoch 13, Test Accuracy: 57.17948717948718%\n",
    "# Epoch: 13, Loss: 1.5128\n",
    "# Epoch 14, Test Accuracy: 56.794871794871796%\n",
    "# Epoch: 14, Loss: 1.5693\n",
    "# Epoch 15, Test Accuracy: 57.94871794871795%\n",
    "# Epoch: 15, Loss: 1.4820\n",
    "# Epoch 16, Test Accuracy: 56.25%\n",
    "# Epoch: 16, Loss: 1.5141\n",
    "# Epoch 17, Test Accuracy: 60.28846153846154%\n",
    "# Epoch: 17, Loss: 1.4022\n",
    "# Epoch 18, Test Accuracy: 63.044871794871796%\n",
    "# Epoch: 18, Loss: 1.3857\n",
    "# Epoch 19, Test Accuracy: 62.243589743589745%\n",
    "# Epoch: 19, Loss: 1.3872\n",
    "# Epoch 20, Test Accuracy: 53.55769230769231%\n",
    "# Epoch: 20, Loss: 1.3657\n",
    "# Epoch 21, Test Accuracy: 58.044871794871796%\n",
    "# Epoch: 21, Loss: 1.2764\n",
    "# Epoch 22, Test Accuracy: 63.333333333333336%\n",
    "# Epoch: 22, Loss: 1.2844\n",
    "# Epoch 23, Test Accuracy: 64.1025641025641%\n",
    "# Epoch: 23, Loss: 1.2522\n",
    "# Epoch 24, Test Accuracy: 57.11538461538461%\n",
    "# Epoch: 24, Loss: 1.2526\n",
    "# Epoch 25, Test Accuracy: 63.493589743589745%\n",
    "# Epoch: 25, Loss: 1.2085\n",
    "# Epoch 26, Test Accuracy: 63.493589743589745%\n",
    "# Epoch: 26, Loss: 1.1821\n",
    "# Epoch 27, Test Accuracy: 61.25%\n",
    "# Epoch: 27, Loss: 1.1951\n",
    "# Epoch 28, Test Accuracy: 66.41025641025641%\n",
    "# Epoch: 28, Loss: 1.2076\n",
    "# Epoch 29, Test Accuracy: 63.044871794871796%\n",
    "# Epoch: 29, Loss: 1.2077\n",
    "# Epoch 30, Test Accuracy: 69.48717948717949%\n",
    "# Epoch: 30, Loss: 1.1012\n",
    "# Epoch 31, Test Accuracy: 73.71794871794872%\n",
    "# Epoch: 31, Loss: 1.1106\n",
    "# Epoch 32, Test Accuracy: 68.26923076923077%\n",
    "# Epoch: 32, Loss: 1.1134\n",
    "# Epoch 33, Test Accuracy: 69.42307692307692%\n",
    "# Epoch: 33, Loss: 1.0812\n",
    "# Epoch 34, Test Accuracy: 70.67307692307692%\n",
    "# Epoch: 34, Loss: 1.0660\n",
    "# Epoch 35, Test Accuracy: 74.35897435897436%\n",
    "# Epoch: 35, Loss: 0.9865\n",
    "# Epoch 36, Test Accuracy: 70.8974358974359%\n",
    "# Epoch: 36, Loss: 1.0079\n",
    "# Epoch 37, Test Accuracy: 72.43589743589743%\n",
    "# Epoch: 37, Loss: 0.9843\n",
    "# Epoch 38, Test Accuracy: 73.07692307692308%\n",
    "# Epoch: 38, Loss: 1.0135\n",
    "# Epoch 39, Test Accuracy: 69.16666666666667%\n",
    "# Epoch: 39, Loss: 1.0083\n",
    "# Epoch 40, Test Accuracy: 70.5448717948718%\n",
    "# Epoch: 40, Loss: 0.9708\n",
    "# Epoch 41, Test Accuracy: 71.28205128205128%\n",
    "# Epoch: 41, Loss: 0.9636\n",
    "# Epoch 42, Test Accuracy: 75.32051282051282%\n",
    "# Epoch: 42, Loss: 0.9646\n",
    "# Epoch 43, Test Accuracy: 73.87820512820512%\n",
    "# Epoch: 43, Loss: 0.9130\n",
    "# Epoch 44, Test Accuracy: 72.88461538461539%\n",
    "# Epoch: 44, Loss: 0.9650\n",
    "# Epoch 45, Test Accuracy: 71.7948717948718%\n",
    "# Epoch: 45, Loss: 0.9225\n",
    "# Epoch 46, Test Accuracy: 75.60897435897436%\n",
    "# Epoch: 46, Loss: 0.8877\n",
    "# Epoch 47, Test Accuracy: 75.3525641025641%\n",
    "# Epoch: 47, Loss: 0.8408\n",
    "# Epoch 48, Test Accuracy: 78.01282051282051%\n",
    "# Epoch: 48, Loss: 0.8472\n",
    "# Epoch 49, Test Accuracy: 71.98717948717949%\n",
    "# Epoch: 49, Loss: 0.8562\n",
    "# Epoch 50, Test Accuracy: 78.49358974358974%\n",
    "# Epoch: 50, Loss: 0.8462\n",
    "# Epoch 51, Test Accuracy: 77.21153846153847%\n",
    "# Epoch: 51, Loss: 0.8557\n",
    "# Epoch 52, Test Accuracy: 77.75641025641026%\n",
    "# Epoch: 52, Loss: 0.8065\n",
    "# Epoch 53, Test Accuracy: 75.03205128205128%\n",
    "# Epoch: 53, Loss: 0.7960\n",
    "# Epoch 54, Test Accuracy: 75.8974358974359%\n",
    "# Epoch: 54, Loss: 0.7944\n",
    "# Epoch 55, Test Accuracy: 75.86538461538461%\n",
    "# Epoch: 55, Loss: 0.7827\n",
    "# Epoch 56, Test Accuracy: 78.65384615384616%\n",
    "# Epoch: 56, Loss: 0.7448\n",
    "# Epoch 57, Test Accuracy: 77.40384615384616%\n",
    "# Epoch: 57, Loss: 0.7287\n",
    "# Epoch 58, Test Accuracy: 77.08333333333333%\n",
    "# Epoch: 58, Loss: 0.7436\n",
    "# Epoch 59, Test Accuracy: 79.26282051282051%\n",
    "# Epoch: 59, Loss: 0.7560\n",
    "# Epoch 60, Test Accuracy: 78.68589743589743%\n",
    "# Epoch: 60, Loss: 0.7371\n",
    "# Epoch 61, Test Accuracy: 79.1025641025641%\n",
    "# Epoch: 61, Loss: 0.7178\n",
    "# Epoch 62, Test Accuracy: 74.23076923076923%\n",
    "# Epoch: 62, Loss: 0.7227\n",
    "# Epoch 63, Test Accuracy: 75.41666666666667%\n",
    "# Epoch: 63, Loss: 0.7139\n",
    "# Epoch 64, Test Accuracy: 77.56410256410257%\n",
    "# Epoch: 64, Loss: 0.6641\n",
    "# Epoch 65, Test Accuracy: 78.91025641025641%\n",
    "# Epoch: 65, Loss: 0.7381\n",
    "# Epoch 66, Test Accuracy: 78.97435897435898%\n",
    "# Epoch: 66, Loss: 0.7037\n",
    "# Epoch 67, Test Accuracy: 77.94871794871794%\n",
    "# Epoch: 67, Loss: 0.7340\n",
    "# Epoch 68, Test Accuracy: 80.41666666666667%\n",
    "# Epoch: 68, Loss: 0.6814\n",
    "# Epoch 69, Test Accuracy: 79.32692307692308%\n",
    "# Epoch: 69, Loss: 0.6779\n",
    "# Epoch 70, Test Accuracy: 77.75641025641026%\n",
    "# Epoch: 70, Loss: 0.7095\n",
    "# Epoch 71, Test Accuracy: 79.13461538461539%\n",
    "# Epoch: 71, Loss: 0.6770\n",
    "# Epoch 72, Test Accuracy: 81.37820512820512%\n",
    "# Epoch: 72, Loss: 0.6236\n",
    "# Epoch 73, Test Accuracy: 80.67307692307692%\n",
    "# Epoch: 73, Loss: 0.6828\n",
    "# Epoch 74, Test Accuracy: 79.35897435897436%\n",
    "# Epoch: 74, Loss: 0.6693\n",
    "# Epoch 75, Test Accuracy: 81.47435897435898%\n",
    "# Epoch: 75, Loss: 0.6482\n",
    "# Epoch 76, Test Accuracy: 80.28846153846153%\n",
    "# Epoch: 76, Loss: 0.6355\n",
    "# Epoch 77, Test Accuracy: 79.4551282051282%\n",
    "# Epoch: 77, Loss: 0.5955\n",
    "# Epoch 78, Test Accuracy: 77.78846153846153%\n",
    "# Epoch: 78, Loss: 0.6345\n",
    "# Epoch 79, Test Accuracy: 79.87179487179488%\n",
    "# Epoch: 79, Loss: 0.5998\n",
    "# Epoch 80, Test Accuracy: 81.50641025641026%\n",
    "# Epoch: 80, Loss: 0.6197\n",
    "# Epoch 81, Test Accuracy: 78.10897435897436%\n",
    "# Epoch: 81, Loss: 0.6660\n",
    "# Epoch 82, Test Accuracy: 80.57692307692308%\n",
    "# Epoch: 82, Loss: 0.6022\n",
    "# Epoch 83, Test Accuracy: 81.02564102564102%\n",
    "# Epoch: 83, Loss: 0.5661\n",
    "# Epoch 84, Test Accuracy: 81.53846153846153%\n",
    "# Epoch: 84, Loss: 0.6097\n",
    "# Epoch 85, Test Accuracy: 80.32051282051282%\n",
    "# Epoch: 85, Loss: 0.5433\n",
    "# Epoch 86, Test Accuracy: 80.22435897435898%\n",
    "# Epoch: 86, Loss: 0.5903\n",
    "# Epoch 87, Test Accuracy: 80.83333333333333%\n",
    "# Epoch: 87, Loss: 0.5349\n",
    "# Epoch 88, Test Accuracy: 78.33333333333333%\n",
    "# Epoch: 88, Loss: 0.5690\n",
    "# Epoch 89, Test Accuracy: 81.25%\n",
    "# Epoch: 89, Loss: 0.5840\n",
    "# Epoch 90, Test Accuracy: 81.15384615384616%\n",
    "# Epoch: 90, Loss: 0.5646\n",
    "# Epoch 91, Test Accuracy: 77.98076923076923%\n",
    "# Epoch: 91, Loss: 0.5718\n",
    "# Epoch 92, Test Accuracy: 80.25641025641026%\n",
    "# Epoch: 92, Loss: 0.5077\n",
    "# Epoch 93, Test Accuracy: 83.01282051282051%\n",
    "# Epoch: 93, Loss: 0.6019\n",
    "# Epoch 94, Test Accuracy: 80.41666666666667%\n",
    "# Epoch: 94, Loss: 0.5507\n",
    "# Epoch 95, Test Accuracy: 82.56410256410257%\n",
    "# Epoch: 95, Loss: 0.5371\n",
    "# Epoch 96, Test Accuracy: 80.80128205128206%\n",
    "# Epoch: 96, Loss: 0.4970\n",
    "# Epoch 97, Test Accuracy: 83.65384615384616%\n",
    "# Epoch: 97, Loss: 0.5228\n",
    "# Epoch 98, Test Accuracy: 81.02564102564102%\n",
    "# Epoch: 98, Loss: 0.5231\n",
    "# Epoch 99, Test Accuracy: 82.27564102564102%\n",
    "# Epoch: 99, Loss: 0.4864\n",
    "# Epoch 100, Test Accuracy: 82.46794871794872%\n",
    "# Epoch: 100, Loss: 0.5336\n",
    "# Epoch 101, Test Accuracy: 80.7051282051282%\n",
    "# Epoch: 101, Loss: 0.4877\n",
    "# Epoch 102, Test Accuracy: 83.10897435897436%\n",
    "# Epoch: 102, Loss: 0.5088\n",
    "# Epoch 103, Test Accuracy: 82.08333333333333%\n",
    "# Epoch: 103, Loss: 0.4782\n",
    "# Epoch 104, Test Accuracy: 80.5448717948718%\n",
    "# Epoch: 104, Loss: 0.5261\n",
    "# Epoch 105, Test Accuracy: 83.0448717948718%\n",
    "# Epoch: 105, Loss: 0.4864\n",
    "# Epoch 106, Test Accuracy: 81.9551282051282%\n",
    "# Epoch: 106, Loss: 0.4866\n",
    "# Epoch 107, Test Accuracy: 79.67948717948718%\n",
    "# Epoch: 107, Loss: 0.5101\n",
    "# Epoch 108, Test Accuracy: 80.80128205128206%\n",
    "# Epoch: 108, Loss: 0.4859\n",
    "# Epoch 109, Test Accuracy: 82.75641025641026%\n",
    "# Epoch: 109, Loss: 0.5170\n",
    "# Epoch 110, Test Accuracy: 80.28846153846153%\n",
    "# Epoch: 110, Loss: 0.4696\n",
    "# Epoch 111, Test Accuracy: 83.5576923076923%\n",
    "# Epoch: 111, Loss: 0.4932\n",
    "# Epoch 112, Test Accuracy: 83.81410256410257%\n",
    "# Epoch: 112, Loss: 0.4546\n",
    "# Epoch 113, Test Accuracy: 83.65384615384616%\n",
    "# Epoch: 113, Loss: 0.4290\n",
    "# Epoch 114, Test Accuracy: 82.33974358974359%\n",
    "# Epoch: 114, Loss: 0.4392\n",
    "# Epoch 115, Test Accuracy: 83.62179487179488%\n",
    "# Epoch: 115, Loss: 0.4555\n",
    "# Epoch 116, Test Accuracy: 82.05128205128206%\n",
    "# Epoch: 116, Loss: 0.4202\n",
    "# Epoch 117, Test Accuracy: 83.71794871794872%\n",
    "# Epoch: 117, Loss: 0.4276\n",
    "# Epoch 118, Test Accuracy: 81.57051282051282%\n",
    "# Epoch: 118, Loss: 0.4361\n",
    "# Epoch 119, Test Accuracy: 82.8525641025641%\n",
    "# Epoch: 119, Loss: 0.4224\n",
    "# Epoch 120, Test Accuracy: 83.33333333333333%\n",
    "# Epoch: 120, Loss: 0.4673\n",
    "# Epoch 121, Test Accuracy: 81.66666666666667%\n",
    "# Epoch: 121, Loss: 0.4467\n",
    "# Epoch 122, Test Accuracy: 82.88461538461539%\n",
    "# Epoch: 122, Loss: 0.4532\n",
    "# Epoch 123, Test Accuracy: 82.56410256410257%\n",
    "# Epoch: 123, Loss: 0.4426\n",
    "# Epoch 124, Test Accuracy: 83.81410256410257%\n",
    "# Epoch: 124, Loss: 0.4284\n",
    "# Epoch 125, Test Accuracy: 81.76282051282051%\n",
    "# Epoch: 125, Loss: 0.4358\n",
    "# Epoch 126, Test Accuracy: 83.75%\n",
    "# Epoch: 126, Loss: 0.4264\n",
    "# Epoch 127, Test Accuracy: 81.02564102564102%\n",
    "# Epoch: 127, Loss: 0.4337\n",
    "# Epoch 128, Test Accuracy: 83.26923076923077%\n",
    "# Epoch: 128, Loss: 0.4178\n",
    "# Epoch 129, Test Accuracy: 82.5%\n",
    "# Epoch: 129, Loss: 0.4512\n",
    "# Epoch 130, Test Accuracy: 82.98076923076923%\n",
    "# Epoch: 130, Loss: 0.4261\n",
    "# Epoch 131, Test Accuracy: 83.91025641025641%\n",
    "# Epoch: 131, Loss: 0.3993\n",
    "# Epoch 132, Test Accuracy: 84.58333333333333%\n",
    "# Epoch: 132, Loss: 0.4189\n",
    "# Epoch 133, Test Accuracy: 83.75%\n",
    "# Epoch: 133, Loss: 0.3797\n",
    "# Epoch 134, Test Accuracy: 84.13461538461539%\n",
    "# Epoch: 134, Loss: 0.3584\n",
    "# Epoch 135, Test Accuracy: 84.93589743589743%\n",
    "# Epoch: 135, Loss: 0.3771\n",
    "# Epoch 136, Test Accuracy: 83.17307692307692%\n",
    "# Epoch: 136, Loss: 0.4366\n",
    "# Epoch 137, Test Accuracy: 83.97435897435898%\n",
    "# Epoch: 137, Loss: 0.3500\n",
    "# Epoch 138, Test Accuracy: 84.19871794871794%\n",
    "# Epoch: 138, Loss: 0.3840\n",
    "# Epoch 139, Test Accuracy: 83.9423076923077%\n",
    "# Epoch: 139, Loss: 0.4023\n",
    "# Epoch 140, Test Accuracy: 82.05128205128206%\n",
    "# Epoch: 140, Loss: 0.3959\n",
    "# Epoch 141, Test Accuracy: 82.82051282051282%\n",
    "# Epoch: 141, Loss: 0.4057\n",
    "# Epoch 142, Test Accuracy: 82.56410256410257%\n",
    "# Epoch: 142, Loss: 0.3638\n",
    "# Epoch 143, Test Accuracy: 84.2948717948718%\n",
    "# Epoch: 143, Loss: 0.3701\n",
    "# Epoch 144, Test Accuracy: 83.23717948717949%\n",
    "# Epoch: 144, Loss: 0.3740\n",
    "# Epoch 145, Test Accuracy: 84.8076923076923%\n",
    "# Epoch: 145, Loss: 0.3904\n",
    "# Epoch 146, Test Accuracy: 81.47435897435898%\n",
    "# Epoch: 146, Loss: 0.3821\n",
    "# Epoch 147, Test Accuracy: 85.57692307692308%\n",
    "# Epoch: 147, Loss: 0.3628\n",
    "# Epoch 148, Test Accuracy: 83.01282051282051%\n",
    "# Epoch: 148, Loss: 0.3548\n",
    "# Epoch 149, Test Accuracy: 84.67948717948718%\n",
    "# Epoch: 149, Loss: 0.3631\n",
    "# Epoch 150, Test Accuracy: 84.2948717948718%\n",
    "# Epoch: 150, Loss: 0.3245\n",
    "# Epoch 151, Test Accuracy: 84.6474358974359%\n",
    "# Epoch: 151, Loss: 0.3438\n",
    "# Epoch 152, Test Accuracy: 83.9423076923077%\n",
    "# Epoch: 152, Loss: 0.3509\n",
    "# Epoch 153, Test Accuracy: 84.00641025641026%\n",
    "# Epoch: 153, Loss: 0.3467\n",
    "# Epoch 154, Test Accuracy: 84.1025641025641%\n",
    "# Epoch: 154, Loss: 0.3595\n",
    "# Epoch 155, Test Accuracy: 83.30128205128206%\n",
    "# Epoch: 155, Loss: 0.3519\n",
    "# Epoch 156, Test Accuracy: 84.67948717948718%\n",
    "# Epoch: 156, Loss: 0.3505\n",
    "# Epoch 157, Test Accuracy: 83.87820512820512%\n",
    "# Epoch: 157, Loss: 0.3514\n",
    "# Epoch 158, Test Accuracy: 83.33333333333333%\n",
    "# Epoch: 158, Loss: 0.3628\n",
    "# Epoch 159, Test Accuracy: 83.46153846153847%\n",
    "# Epoch: 159, Loss: 0.3274\n",
    "# Epoch 160, Test Accuracy: 84.23076923076923%\n",
    "# Epoch: 160, Loss: 0.3392\n",
    "# Epoch 161, Test Accuracy: 83.26923076923077%\n",
    "# Epoch: 161, Loss: 0.3405\n",
    "# Epoch 162, Test Accuracy: 84.67948717948718%\n",
    "# Epoch: 162, Loss: 0.3553\n",
    "# Epoch 163, Test Accuracy: 84.71153846153847%\n",
    "# Epoch: 163, Loss: 0.3587\n",
    "# Epoch 164, Test Accuracy: 85.60897435897436%\n",
    "# Epoch: 164, Loss: 0.3522\n",
    "# Epoch 165, Test Accuracy: 84.74358974358974%\n",
    "# Epoch: 165, Loss: 0.3175\n",
    "# Epoch 166, Test Accuracy: 84.74358974358974%\n",
    "# Epoch: 166, Loss: 0.3314\n",
    "# Epoch 167, Test Accuracy: 85.03205128205128%\n",
    "# Epoch: 167, Loss: 0.3137\n",
    "# Epoch 168, Test Accuracy: 85.7051282051282%\n",
    "# Epoch: 168, Loss: 0.3349\n",
    "# Epoch 169, Test Accuracy: 84.48717948717949%\n",
    "# Epoch: 169, Loss: 0.3108\n",
    "# Epoch 170, Test Accuracy: 83.97435897435898%\n",
    "# Epoch: 170, Loss: 0.3017\n",
    "# Epoch 171, Test Accuracy: 83.68589743589743%\n",
    "# Epoch: 171, Loss: 0.3440\n",
    "# Epoch 172, Test Accuracy: 82.46794871794872%\n",
    "# Epoch: 172, Loss: 0.3149\n",
    "# Epoch 173, Test Accuracy: 84.23076923076923%\n",
    "# Epoch: 173, Loss: 0.2947\n",
    "# Epoch 174, Test Accuracy: 84.42307692307692%\n",
    "# Epoch: 174, Loss: 0.3242\n",
    "# Epoch 175, Test Accuracy: 84.1025641025641%\n",
    "# Epoch: 175, Loss: 0.3431\n",
    "# Epoch 176, Test Accuracy: 84.93589743589743%\n",
    "# Epoch: 176, Loss: 0.3305\n",
    "# Epoch 177, Test Accuracy: 83.97435897435898%\n",
    "# Epoch: 177, Loss: 0.3219\n",
    "# Epoch 178, Test Accuracy: 83.75%\n",
    "# Epoch: 178, Loss: 0.2904\n",
    "# Epoch 179, Test Accuracy: 84.39102564102564%\n",
    "# Epoch: 179, Loss: 0.2959\n",
    "# Epoch 180, Test Accuracy: 83.81410256410257%\n",
    "# Epoch: 180, Loss: 0.3748\n",
    "# Epoch 181, Test Accuracy: 84.13461538461539%\n",
    "# Epoch: 181, Loss: 0.3103\n",
    "# Epoch 182, Test Accuracy: 84.83974358974359%\n",
    "# Epoch: 182, Loss: 0.3090\n",
    "# Epoch 183, Test Accuracy: 84.4551282051282%\n",
    "# Epoch: 183, Loss: 0.3200\n",
    "# Epoch 184, Test Accuracy: 84.93589743589743%\n",
    "# Epoch: 184, Loss: 0.2982\n",
    "# Epoch 185, Test Accuracy: 85.25641025641026%\n",
    "# Epoch: 185, Loss: 0.3201\n",
    "# Epoch 186, Test Accuracy: 85.03205128205128%\n",
    "# Epoch: 186, Loss: 0.2970\n",
    "# Epoch 187, Test Accuracy: 85.41666666666667%\n",
    "# Epoch: 187, Loss: 0.3082\n",
    "# Epoch 188, Test Accuracy: 85.44871794871794%\n",
    "# Epoch: 188, Loss: 0.3047\n",
    "# Epoch 189, Test Accuracy: 85.28846153846153%\n",
    "# Epoch: 189, Loss: 0.3006\n",
    "# Epoch 190, Test Accuracy: 84.03846153846153%\n",
    "# Epoch: 190, Loss: 0.3060\n",
    "# Epoch 191, Test Accuracy: 83.33333333333333%\n",
    "# Epoch: 191, Loss: 0.3183\n",
    "# Epoch 192, Test Accuracy: 84.35897435897436%\n",
    "# Epoch: 192, Loss: 0.2928\n",
    "# Epoch 193, Test Accuracy: 84.96794871794872%\n",
    "# Epoch: 193, Loss: 0.3351\n",
    "# Epoch 194, Test Accuracy: 83.91025641025641%\n",
    "# Epoch: 194, Loss: 0.3182\n",
    "# Epoch 195, Test Accuracy: 84.87179487179488%\n",
    "# Epoch: 195, Loss: 0.2886\n",
    "# Epoch 196, Test Accuracy: 85.86538461538461%\n",
    "# Epoch: 196, Loss: 0.2915\n",
    "# Epoch 197, Test Accuracy: 84.61538461538461%\n",
    "# Epoch: 197, Loss: 0.3242\n",
    "# Epoch 198, Test Accuracy: 85.16025641025641%\n",
    "# Epoch: 198, Loss: 0.3008\n",
    "# Epoch 199, Test Accuracy: 84.6474358974359%\n",
    "# Epoch: 199, Loss: 0.2637\n",
    "# Epoch 200, Test Accuracy: 85.28846153846153%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.0.weight torch.Size([32, 3, 3, 3])\n",
      "features.0.1.weight torch.Size([32])\n",
      "features.0.1.bias torch.Size([32])\n",
      "features.1.conv.0.0.weight torch.Size([32, 1, 3, 3])\n",
      "features.1.conv.0.1.weight torch.Size([32])\n",
      "features.1.conv.0.1.bias torch.Size([32])\n",
      "features.1.conv.1.weight torch.Size([16, 32, 1, 1])\n",
      "features.1.conv.2.weight torch.Size([16])\n",
      "features.1.conv.2.bias torch.Size([16])\n",
      "features.2.conv.0.0.weight torch.Size([96, 16, 1, 1])\n",
      "features.2.conv.0.1.weight torch.Size([96])\n",
      "features.2.conv.0.1.bias torch.Size([96])\n",
      "features.2.conv.1.0.weight torch.Size([96, 1, 3, 3])\n",
      "features.2.conv.1.1.weight torch.Size([96])\n",
      "features.2.conv.1.1.bias torch.Size([96])\n",
      "features.2.conv.2.weight torch.Size([24, 96, 1, 1])\n",
      "features.2.conv.3.weight torch.Size([24])\n",
      "features.2.conv.3.bias torch.Size([24])\n",
      "features.3.conv.0.0.weight torch.Size([144, 24, 1, 1])\n",
      "features.3.conv.0.1.weight torch.Size([144])\n",
      "features.3.conv.0.1.bias torch.Size([144])\n",
      "features.3.conv.1.0.weight torch.Size([144, 1, 3, 3])\n",
      "features.3.conv.1.1.weight torch.Size([144])\n",
      "features.3.conv.1.1.bias torch.Size([144])\n",
      "features.3.conv.2.weight torch.Size([24, 144, 1, 1])\n",
      "features.3.conv.3.weight torch.Size([24])\n",
      "features.3.conv.3.bias torch.Size([24])\n",
      "features.4.conv.0.0.weight torch.Size([144, 24, 1, 1])\n",
      "features.4.conv.0.1.weight torch.Size([144])\n",
      "features.4.conv.0.1.bias torch.Size([144])\n",
      "features.4.conv.1.0.weight torch.Size([144, 1, 3, 3])\n",
      "features.4.conv.1.1.weight torch.Size([144])\n",
      "features.4.conv.1.1.bias torch.Size([144])\n",
      "features.4.conv.2.weight torch.Size([32, 144, 1, 1])\n",
      "features.4.conv.3.weight torch.Size([32])\n",
      "features.4.conv.3.bias torch.Size([32])\n",
      "features.5.conv.0.0.weight torch.Size([192, 32, 1, 1])\n",
      "features.5.conv.0.1.weight torch.Size([192])\n",
      "features.5.conv.0.1.bias torch.Size([192])\n",
      "features.5.conv.1.0.weight torch.Size([192, 1, 3, 3])\n",
      "features.5.conv.1.1.weight torch.Size([192])\n",
      "features.5.conv.1.1.bias torch.Size([192])\n",
      "features.5.conv.2.weight torch.Size([32, 192, 1, 1])\n",
      "features.5.conv.3.weight torch.Size([32])\n",
      "features.5.conv.3.bias torch.Size([32])\n",
      "features.6.conv.0.0.weight torch.Size([192, 32, 1, 1])\n",
      "features.6.conv.0.1.weight torch.Size([192])\n",
      "features.6.conv.0.1.bias torch.Size([192])\n",
      "features.6.conv.1.0.weight torch.Size([192, 1, 3, 3])\n",
      "features.6.conv.1.1.weight torch.Size([192])\n",
      "features.6.conv.1.1.bias torch.Size([192])\n",
      "features.6.conv.2.weight torch.Size([32, 192, 1, 1])\n",
      "features.6.conv.3.weight torch.Size([32])\n",
      "features.6.conv.3.bias torch.Size([32])\n",
      "features.7.conv.0.0.weight torch.Size([192, 32, 1, 1])\n",
      "features.7.conv.0.1.weight torch.Size([192])\n",
      "features.7.conv.0.1.bias torch.Size([192])\n",
      "features.7.conv.1.0.weight torch.Size([192, 1, 3, 3])\n",
      "features.7.conv.1.1.weight torch.Size([192])\n",
      "features.7.conv.1.1.bias torch.Size([192])\n",
      "features.7.conv.2.weight torch.Size([64, 192, 1, 1])\n",
      "features.7.conv.3.weight torch.Size([64])\n",
      "features.7.conv.3.bias torch.Size([64])\n",
      "features.8.conv.0.0.weight torch.Size([384, 64, 1, 1])\n",
      "features.8.conv.0.1.weight torch.Size([384])\n",
      "features.8.conv.0.1.bias torch.Size([384])\n",
      "features.8.conv.1.0.weight torch.Size([384, 1, 3, 3])\n",
      "features.8.conv.1.1.weight torch.Size([384])\n",
      "features.8.conv.1.1.bias torch.Size([384])\n",
      "features.8.conv.2.weight torch.Size([64, 384, 1, 1])\n",
      "features.8.conv.3.weight torch.Size([64])\n",
      "features.8.conv.3.bias torch.Size([64])\n",
      "features.9.conv.0.0.weight torch.Size([384, 64, 1, 1])\n",
      "features.9.conv.0.1.weight torch.Size([384])\n",
      "features.9.conv.0.1.bias torch.Size([384])\n",
      "features.9.conv.1.0.weight torch.Size([384, 1, 3, 3])\n",
      "features.9.conv.1.1.weight torch.Size([384])\n",
      "features.9.conv.1.1.bias torch.Size([384])\n",
      "features.9.conv.2.weight torch.Size([64, 384, 1, 1])\n",
      "features.9.conv.3.weight torch.Size([64])\n",
      "features.9.conv.3.bias torch.Size([64])\n",
      "features.10.conv.0.0.weight torch.Size([384, 64, 1, 1])\n",
      "features.10.conv.0.1.weight torch.Size([384])\n",
      "features.10.conv.0.1.bias torch.Size([384])\n",
      "features.10.conv.1.0.weight torch.Size([384, 1, 3, 3])\n",
      "features.10.conv.1.1.weight torch.Size([384])\n",
      "features.10.conv.1.1.bias torch.Size([384])\n",
      "features.10.conv.2.weight torch.Size([64, 384, 1, 1])\n",
      "features.10.conv.3.weight torch.Size([64])\n",
      "features.10.conv.3.bias torch.Size([64])\n",
      "features.11.conv.0.0.weight torch.Size([384, 64, 1, 1])\n",
      "features.11.conv.0.1.weight torch.Size([384])\n",
      "features.11.conv.0.1.bias torch.Size([384])\n",
      "features.11.conv.1.0.weight torch.Size([384, 1, 3, 3])\n",
      "features.11.conv.1.1.weight torch.Size([384])\n",
      "features.11.conv.1.1.bias torch.Size([384])\n",
      "features.11.conv.2.weight torch.Size([96, 384, 1, 1])\n",
      "features.11.conv.3.weight torch.Size([96])\n",
      "features.11.conv.3.bias torch.Size([96])\n",
      "features.12.conv.0.0.weight torch.Size([576, 96, 1, 1])\n",
      "features.12.conv.0.1.weight torch.Size([576])\n",
      "features.12.conv.0.1.bias torch.Size([576])\n",
      "features.12.conv.1.0.weight torch.Size([576, 1, 3, 3])\n",
      "features.12.conv.1.1.weight torch.Size([576])\n",
      "features.12.conv.1.1.bias torch.Size([576])\n",
      "features.12.conv.2.weight torch.Size([96, 576, 1, 1])\n",
      "features.12.conv.3.weight torch.Size([96])\n",
      "features.12.conv.3.bias torch.Size([96])\n",
      "features.13.conv.0.0.weight torch.Size([576, 96, 1, 1])\n",
      "features.13.conv.0.1.weight torch.Size([576])\n",
      "features.13.conv.0.1.bias torch.Size([576])\n",
      "features.13.conv.1.0.weight torch.Size([576, 1, 3, 3])\n",
      "features.13.conv.1.1.weight torch.Size([576])\n",
      "features.13.conv.1.1.bias torch.Size([576])\n",
      "features.13.conv.2.weight torch.Size([96, 576, 1, 1])\n",
      "features.13.conv.3.weight torch.Size([96])\n",
      "features.13.conv.3.bias torch.Size([96])\n",
      "features.14.conv.0.0.weight torch.Size([576, 96, 1, 1])\n",
      "features.14.conv.0.1.weight torch.Size([576])\n",
      "features.14.conv.0.1.bias torch.Size([576])\n",
      "features.14.conv.1.0.weight torch.Size([576, 1, 3, 3])\n",
      "features.14.conv.1.1.weight torch.Size([576])\n",
      "features.14.conv.1.1.bias torch.Size([576])\n",
      "features.14.conv.2.weight torch.Size([160, 576, 1, 1])\n",
      "features.14.conv.3.weight torch.Size([160])\n",
      "features.14.conv.3.bias torch.Size([160])\n",
      "features.15.conv.0.0.weight torch.Size([960, 160, 1, 1])\n",
      "features.15.conv.0.1.weight torch.Size([960])\n",
      "features.15.conv.0.1.bias torch.Size([960])\n",
      "features.15.conv.1.0.weight torch.Size([960, 1, 3, 3])\n",
      "features.15.conv.1.1.weight torch.Size([960])\n",
      "features.15.conv.1.1.bias torch.Size([960])\n",
      "features.15.conv.2.weight torch.Size([160, 960, 1, 1])\n",
      "features.15.conv.3.weight torch.Size([160])\n",
      "features.15.conv.3.bias torch.Size([160])\n",
      "features.16.conv.0.0.weight torch.Size([960, 160, 1, 1])\n",
      "features.16.conv.0.1.weight torch.Size([960])\n",
      "features.16.conv.0.1.bias torch.Size([960])\n",
      "features.16.conv.1.0.weight torch.Size([960, 1, 3, 3])\n",
      "features.16.conv.1.1.weight torch.Size([960])\n",
      "features.16.conv.1.1.bias torch.Size([960])\n",
      "features.16.conv.2.weight torch.Size([160, 960, 1, 1])\n",
      "features.16.conv.3.weight torch.Size([160])\n",
      "features.16.conv.3.bias torch.Size([160])\n",
      "features.17.conv.0.0.weight torch.Size([960, 160, 1, 1])\n",
      "features.17.conv.0.1.weight torch.Size([960])\n",
      "features.17.conv.0.1.bias torch.Size([960])\n",
      "features.17.conv.1.0.weight torch.Size([960, 1, 3, 3])\n",
      "features.17.conv.1.1.weight torch.Size([960])\n",
      "features.17.conv.1.1.bias torch.Size([960])\n",
      "features.17.conv.2.weight torch.Size([320, 960, 1, 1])\n",
      "features.17.conv.3.weight torch.Size([320])\n",
      "features.17.conv.3.bias torch.Size([320])\n",
      "features.18.0.weight torch.Size([1280, 320, 1, 1])\n",
      "features.18.1.weight torch.Size([1280])\n",
      "features.18.1.bias torch.Size([1280])\n",
      "classifier.1.weight torch.Size([12, 1280])\n",
      "classifier.1.bias torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "# 打印model的各个层的名字和参数size\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.size())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model中name不带有weight或bias的层\n",
    "for name, param in model.named_parameters():\n",
    "    if \"weight\" not in name and \"bias\" not in name:\n",
    "        print(name, param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 保留0.1比例的数据集的时候, 可以达到74% 75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 保留0.1比例的数据集的时候\n",
    "# Epoch: 0, Loss: 2.5162\n",
    "# Epoch 1, Test Accuracy: 8.333333333333334%\n",
    "# Epoch: 1, Loss: 2.5100\n",
    "# Epoch 2, Test Accuracy: 8.333333333333334%\n",
    "# Epoch: 2, Loss: 2.3738\n",
    "# Epoch 3, Test Accuracy: 10.64102564102564%\n",
    "# Epoch: 3, Loss: 2.3183\n",
    "# Epoch 4, Test Accuracy: 19.615384615384617%\n",
    "# Epoch: 4, Loss: 2.1744\n",
    "# Epoch 5, Test Accuracy: 13.26923076923077%\n",
    "# Epoch: 5, Loss: 2.1611\n",
    "# Epoch 6, Test Accuracy: 18.397435897435898%\n",
    "# Epoch: 6, Loss: 2.0230\n",
    "# Epoch 7, Test Accuracy: 25.096153846153847%\n",
    "# Epoch: 7, Loss: 2.0009\n",
    "# Epoch 8, Test Accuracy: 33.87820512820513%\n",
    "# Epoch: 8, Loss: 1.9563\n",
    "# Epoch 9, Test Accuracy: 31.634615384615383%\n",
    "# Epoch: 9, Loss: 1.9403\n",
    "# Epoch 10, Test Accuracy: 37.40384615384615%\n",
    "# Epoch: 10, Loss: 1.8848\n",
    "# Epoch 11, Test Accuracy: 42.11538461538461%\n",
    "# Epoch: 11, Loss: 1.8929\n",
    "# Epoch 12, Test Accuracy: 40.38461538461539%\n",
    "# Epoch: 12, Loss: 1.7737\n",
    "# Epoch 13, Test Accuracy: 42.40384615384615%\n",
    "# Epoch: 13, Loss: 1.7790\n",
    "# Epoch 14, Test Accuracy: 39.743589743589745%\n",
    "# Epoch: 14, Loss: 1.7646\n",
    "# Epoch 15, Test Accuracy: 47.27564102564103%\n",
    "# Epoch: 15, Loss: 1.7269\n",
    "# Epoch 16, Test Accuracy: 47.40384615384615%\n",
    "# Epoch: 16, Loss: 1.7172\n",
    "# Epoch 17, Test Accuracy: 48.17307692307692%\n",
    "# Epoch: 17, Loss: 1.6540\n",
    "# Epoch 18, Test Accuracy: 48.65384615384615%\n",
    "# Epoch: 18, Loss: 1.6249\n",
    "# Epoch 19, Test Accuracy: 49.166666666666664%\n",
    "# Epoch: 19, Loss: 1.6060\n",
    "# Epoch 20, Test Accuracy: 43.58974358974359%\n",
    "# Epoch: 20, Loss: 1.5913\n",
    "# Epoch 21, Test Accuracy: 48.782051282051285%\n",
    "# Epoch: 21, Loss: 1.5850\n",
    "# Epoch 22, Test Accuracy: 51.666666666666664%\n",
    "# Epoch: 22, Loss: 1.6102\n",
    "# Epoch 23, Test Accuracy: 46.41025641025641%\n",
    "# Epoch: 23, Loss: 1.4931\n",
    "# Epoch 24, Test Accuracy: 51.37820512820513%\n",
    "# Epoch: 24, Loss: 1.4415\n",
    "# Epoch 25, Test Accuracy: 52.01923076923077%\n",
    "# Epoch: 25, Loss: 1.4626\n",
    "# Epoch 26, Test Accuracy: 53.65384615384615%\n",
    "# Epoch: 26, Loss: 1.4696\n",
    "# Epoch 27, Test Accuracy: 52.17948717948718%\n",
    "# Epoch: 27, Loss: 1.4387\n",
    "# Epoch 28, Test Accuracy: 58.333333333333336%\n",
    "# Epoch: 28, Loss: 1.4190\n",
    "# Epoch 29, Test Accuracy: 56.08974358974359%\n",
    "# Epoch: 29, Loss: 1.3977\n",
    "# Epoch 30, Test Accuracy: 59.55128205128205%\n",
    "# Epoch: 30, Loss: 1.3437\n",
    "# Epoch 31, Test Accuracy: 57.11538461538461%\n",
    "# Epoch: 31, Loss: 1.3367\n",
    "# Epoch 32, Test Accuracy: 61.217948717948715%\n",
    "# Epoch: 32, Loss: 1.3192\n",
    "# Epoch 33, Test Accuracy: 58.782051282051285%\n",
    "# Epoch: 33, Loss: 1.2989\n",
    "# Epoch 34, Test Accuracy: 62.532051282051285%\n",
    "# Epoch: 34, Loss: 1.2603\n",
    "# Epoch 35, Test Accuracy: 60.38461538461539%\n",
    "# Epoch: 35, Loss: 1.2874\n",
    "# Epoch 36, Test Accuracy: 56.666666666666664%\n",
    "# Epoch: 36, Loss: 1.2163\n",
    "# Epoch 37, Test Accuracy: 62.243589743589745%\n",
    "# Epoch: 37, Loss: 1.1762\n",
    "# Epoch 38, Test Accuracy: 61.282051282051285%\n",
    "# Epoch: 38, Loss: 1.1714\n",
    "# Epoch 39, Test Accuracy: 62.5%\n",
    "# Epoch: 39, Loss: 1.1772\n",
    "# Epoch 40, Test Accuracy: 63.84615384615385%\n",
    "# Epoch: 40, Loss: 1.1900\n",
    "# Epoch 41, Test Accuracy: 62.01923076923077%\n",
    "# Epoch: 41, Loss: 1.1647\n",
    "# Epoch 42, Test Accuracy: 66.98717948717949%\n",
    "# Epoch: 42, Loss: 1.2032\n",
    "# Epoch 43, Test Accuracy: 61.15384615384615%\n",
    "# Epoch: 43, Loss: 1.2546\n",
    "# Epoch 44, Test Accuracy: 65.28846153846153%\n",
    "# Epoch: 44, Loss: 1.2131\n",
    "# Epoch 45, Test Accuracy: 66.85897435897436%\n",
    "# Epoch: 45, Loss: 1.1356\n",
    "# Epoch 46, Test Accuracy: 63.52564102564103%\n",
    "# Epoch: 46, Loss: 1.1525\n",
    "# Epoch 47, Test Accuracy: 61.37820512820513%\n",
    "# Epoch: 47, Loss: 1.0722\n",
    "# Epoch 48, Test Accuracy: 68.10897435897436%\n",
    "# Epoch: 48, Loss: 1.0186\n",
    "# Epoch 49, Test Accuracy: 68.68589743589743%\n",
    "# Epoch: 49, Loss: 1.0635\n",
    "# Epoch 50, Test Accuracy: 66.18589743589743%\n",
    "# Epoch: 50, Loss: 1.1177\n",
    "# Epoch 51, Test Accuracy: 64.83974358974359%\n",
    "# Epoch: 51, Loss: 1.0027\n",
    "# Epoch 52, Test Accuracy: 66.18589743589743%\n",
    "# Epoch: 52, Loss: 1.0330\n",
    "# Epoch 53, Test Accuracy: 64.87179487179488%\n",
    "# Epoch: 53, Loss: 0.9675\n",
    "# Epoch 54, Test Accuracy: 68.26923076923077%\n",
    "# Epoch: 54, Loss: 1.0158\n",
    "# Epoch 55, Test Accuracy: 60.76923076923077%\n",
    "# Epoch: 55, Loss: 1.0250\n",
    "# Epoch 56, Test Accuracy: 63.55769230769231%\n",
    "# Epoch: 56, Loss: 1.0220\n",
    "# Epoch 57, Test Accuracy: 67.21153846153847%\n",
    "# Epoch: 57, Loss: 1.0398\n",
    "# Epoch 58, Test Accuracy: 71.4423076923077%\n",
    "# Epoch: 58, Loss: 0.9187\n",
    "# Epoch 59, Test Accuracy: 68.84615384615384%\n",
    "# Epoch: 59, Loss: 0.9693\n",
    "# Epoch 60, Test Accuracy: 67.37179487179488%\n",
    "# Epoch: 60, Loss: 0.9148\n",
    "# Epoch 61, Test Accuracy: 69.39102564102564%\n",
    "# Epoch: 61, Loss: 0.9406\n",
    "# Epoch 62, Test Accuracy: 68.23717948717949%\n",
    "# Epoch: 62, Loss: 0.9491\n",
    "# Epoch 63, Test Accuracy: 68.49358974358974%\n",
    "# Epoch: 63, Loss: 0.7792\n",
    "# Epoch 64, Test Accuracy: 66.6025641025641%\n",
    "# Epoch: 64, Loss: 0.8934\n",
    "# Epoch 65, Test Accuracy: 69.00641025641026%\n",
    "# Epoch: 65, Loss: 0.8728\n",
    "# Epoch 66, Test Accuracy: 68.30128205128206%\n",
    "# Epoch: 66, Loss: 0.8739\n",
    "# Epoch 67, Test Accuracy: 61.31410256410256%\n",
    "# Epoch: 67, Loss: 0.8426\n",
    "# Epoch 68, Test Accuracy: 68.75%\n",
    "# Epoch: 68, Loss: 0.8440\n",
    "# Epoch 69, Test Accuracy: 70.16025641025641%\n",
    "# Epoch: 69, Loss: 0.8654\n",
    "# Epoch 70, Test Accuracy: 69.48717948717949%\n",
    "# Epoch: 70, Loss: 0.8206\n",
    "# Epoch 71, Test Accuracy: 66.63461538461539%\n",
    "# Epoch: 71, Loss: 0.9074\n",
    "# Epoch 72, Test Accuracy: 67.43589743589743%\n",
    "# Epoch: 72, Loss: 0.8914\n",
    "# Epoch 73, Test Accuracy: 66.82692307692308%\n",
    "# Epoch: 73, Loss: 0.8267\n",
    "# Epoch 74, Test Accuracy: 70.80128205128206%\n",
    "# Epoch: 74, Loss: 0.7690\n",
    "# Epoch 75, Test Accuracy: 69.03846153846153%\n",
    "# Epoch: 75, Loss: 0.8355\n",
    "# Epoch 76, Test Accuracy: 66.53846153846153%\n",
    "# Epoch: 76, Loss: 0.8423\n",
    "# Epoch 77, Test Accuracy: 71.31410256410257%\n",
    "# Epoch: 77, Loss: 0.7884\n",
    "# Epoch 78, Test Accuracy: 70.92948717948718%\n",
    "# Epoch: 78, Loss: 0.8145\n",
    "# Epoch 79, Test Accuracy: 67.43589743589743%\n",
    "# Epoch: 79, Loss: 0.8079\n",
    "# Epoch 80, Test Accuracy: 72.94871794871794%\n",
    "# Epoch: 80, Loss: 0.7491\n",
    "# Epoch 81, Test Accuracy: 66.63461538461539%\n",
    "# Epoch: 81, Loss: 0.7351\n",
    "# Epoch 82, Test Accuracy: 72.01923076923077%\n",
    "# Epoch: 82, Loss: 0.7084\n",
    "# Epoch 83, Test Accuracy: 73.42948717948718%\n",
    "# Epoch: 83, Loss: 0.7676\n",
    "# Epoch 84, Test Accuracy: 69.93589743589743%\n",
    "# Epoch: 84, Loss: 0.7878\n",
    "# Epoch 85, Test Accuracy: 68.71794871794872%\n",
    "# Epoch: 85, Loss: 0.7430\n",
    "# Epoch 86, Test Accuracy: 72.11538461538461%\n",
    "# Epoch: 86, Loss: 0.7412\n",
    "# Epoch 87, Test Accuracy: 70.60897435897436%\n",
    "# Epoch: 87, Loss: 0.6745\n",
    "# Epoch 88, Test Accuracy: 74.2948717948718%\n",
    "# Epoch: 88, Loss: 0.7235\n",
    "# Epoch 89, Test Accuracy: 67.82051282051282%\n",
    "# Epoch: 89, Loss: 0.7586\n",
    "# Epoch 90, Test Accuracy: 73.65384615384616%\n",
    "# Epoch: 90, Loss: 0.6824\n",
    "# Epoch 91, Test Accuracy: 71.57051282051282%\n",
    "# Epoch: 91, Loss: 0.7320\n",
    "# Epoch 92, Test Accuracy: 73.49358974358974%\n",
    "# Epoch: 92, Loss: 0.7049\n",
    "# Epoch 93, Test Accuracy: 73.62179487179488%\n",
    "# Epoch: 93, Loss: 0.6900\n",
    "# Epoch 94, Test Accuracy: 70.57692307692308%\n",
    "# Epoch: 94, Loss: 0.7482\n",
    "# Epoch 95, Test Accuracy: 73.65384615384616%\n",
    "# Epoch: 95, Loss: 0.6508\n",
    "# Epoch 96, Test Accuracy: 69.61538461538461%\n",
    "# Epoch: 96, Loss: 0.6048\n",
    "# Epoch 97, Test Accuracy: 73.0448717948718%\n",
    "# Epoch: 97, Loss: 0.6135\n",
    "# Epoch 98, Test Accuracy: 73.58974358974359%\n",
    "# Epoch: 98, Loss: 0.6493\n",
    "# Epoch 99, Test Accuracy: 74.6474358974359%\n",
    "# Epoch: 99, Loss: 0.6293\n",
    "# Epoch 100, Test Accuracy: 72.5%\n",
    "# Epoch: 100, Loss: 0.6841\n",
    "# Epoch 101, Test Accuracy: 70.38461538461539%\n",
    "# Epoch: 101, Loss: 0.6421\n",
    "# Epoch 102, Test Accuracy: 67.53205128205128%\n",
    "# Epoch: 102, Loss: 0.6285\n",
    "# Epoch 103, Test Accuracy: 74.74358974358974%\n",
    "# Epoch: 103, Loss: 0.6569\n",
    "# Epoch 104, Test Accuracy: 71.12179487179488%\n",
    "# Epoch: 104, Loss: 0.6550\n",
    "# Epoch 105, Test Accuracy: 73.23717948717949%\n",
    "# Epoch: 105, Loss: 0.5908\n",
    "# Epoch 106, Test Accuracy: 71.28205128205128%\n",
    "# Epoch: 106, Loss: 0.6089\n",
    "# Epoch 107, Test Accuracy: 74.87179487179488%\n",
    "# Epoch: 107, Loss: 0.6170\n",
    "# Epoch 108, Test Accuracy: 75.16025641025641%\n",
    "# Epoch: 108, Loss: 0.5840\n",
    "# Epoch 109, Test Accuracy: 72.6923076923077%\n",
    "# Epoch: 109, Loss: 0.6021\n",
    "# Epoch 110, Test Accuracy: 72.5%\n",
    "# Epoch: 110, Loss: 0.5698\n",
    "# Epoch 111, Test Accuracy: 73.26923076923077%\n",
    "# Epoch: 111, Loss: 0.5956\n",
    "# Epoch 112, Test Accuracy: 72.66025641025641%\n",
    "# Epoch: 112, Loss: 0.5966\n",
    "# Epoch 113, Test Accuracy: 71.34615384615384%\n",
    "# Epoch: 113, Loss: 0.5799\n",
    "# Epoch 114, Test Accuracy: 71.31410256410257%\n",
    "# Epoch: 114, Loss: 0.5697\n",
    "# Epoch 115, Test Accuracy: 75.16025641025641%\n",
    "# Epoch: 115, Loss: 0.6026\n",
    "# Epoch 116, Test Accuracy: 72.94871794871794%\n",
    "# Epoch: 116, Loss: 0.5406\n",
    "# Epoch 117, Test Accuracy: 74.07051282051282%\n",
    "# Epoch: 117, Loss: 0.5232\n",
    "# Epoch 118, Test Accuracy: 73.87820512820512%\n",
    "# Epoch: 118, Loss: 0.5445\n",
    "# Epoch 119, Test Accuracy: 75.0%\n",
    "# Epoch: 119, Loss: 0.5524\n",
    "# Epoch 120, Test Accuracy: 75.86538461538461%\n",
    "# Epoch: 120, Loss: 0.5551\n",
    "# Epoch 121, Test Accuracy: 71.92307692307692%\n",
    "# Epoch: 121, Loss: 0.5816\n",
    "# Epoch 122, Test Accuracy: 74.39102564102564%\n",
    "# Epoch: 122, Loss: 0.5553\n",
    "# Epoch 123, Test Accuracy: 75.16025641025641%\n",
    "# Epoch: 123, Loss: 0.5346\n",
    "# Epoch 124, Test Accuracy: 72.98076923076923%\n",
    "# Epoch: 124, Loss: 0.5580\n",
    "# Epoch 125, Test Accuracy: 75.22435897435898%\n",
    "# Epoch: 125, Loss: 0.5549\n",
    "# Epoch 126, Test Accuracy: 75.67307692307692%\n",
    "# Epoch: 126, Loss: 0.5837\n",
    "# Epoch 127, Test Accuracy: 71.0576923076923%\n",
    "# Epoch: 127, Loss: 0.5560\n",
    "# Epoch 128, Test Accuracy: 74.1025641025641%\n",
    "# Epoch: 128, Loss: 0.4838\n",
    "# Epoch 129, Test Accuracy: 76.9551282051282%\n",
    "# Epoch: 129, Loss: 0.4369\n",
    "# Epoch 130, Test Accuracy: 72.21153846153847%\n",
    "# Epoch: 130, Loss: 0.5583\n",
    "# Epoch 131, Test Accuracy: 75.73717948717949%\n",
    "# Epoch: 131, Loss: 0.4765\n",
    "# Epoch 132, Test Accuracy: 74.00641025641026%\n",
    "# Epoch: 132, Loss: 0.4859\n",
    "# Epoch 133, Test Accuracy: 76.0576923076923%\n",
    "# Epoch: 133, Loss: 0.5793\n",
    "# Epoch 134, Test Accuracy: 70.32051282051282%\n",
    "# Epoch: 134, Loss: 0.5205\n",
    "# Epoch 135, Test Accuracy: 74.2948717948718%\n",
    "# Epoch: 135, Loss: 0.5030\n",
    "# Epoch 136, Test Accuracy: 74.90384615384616%\n",
    "# Epoch: 136, Loss: 0.4994\n",
    "# Epoch 137, Test Accuracy: 74.87179487179488%\n",
    "# Epoch: 137, Loss: 0.4912\n",
    "# Epoch 138, Test Accuracy: 75.09615384615384%\n",
    "# Epoch: 138, Loss: 0.5613\n",
    "# Epoch 139, Test Accuracy: 73.33333333333333%\n",
    "# Epoch: 139, Loss: 0.5239\n",
    "# Epoch 140, Test Accuracy: 75.12820512820512%\n",
    "# Epoch: 140, Loss: 0.5096\n",
    "# Epoch 141, Test Accuracy: 73.9423076923077%\n",
    "# Epoch: 141, Loss: 0.4644\n",
    "# Epoch 142, Test Accuracy: 74.23076923076923%\n",
    "# Epoch: 142, Loss: 0.4648\n",
    "# Epoch 143, Test Accuracy: 76.73076923076923%\n",
    "# Epoch: 143, Loss: 0.5047\n",
    "# Epoch 144, Test Accuracy: 73.91025641025641%\n",
    "# Epoch: 144, Loss: 0.4676\n",
    "# Epoch 145, Test Accuracy: 75.92948717948718%\n",
    "# Epoch: 145, Loss: 0.4227\n",
    "# Epoch 146, Test Accuracy: 73.71794871794872%\n",
    "# Epoch: 146, Loss: 0.3901\n",
    "# Epoch 147, Test Accuracy: 73.91025641025641%\n",
    "# Epoch: 147, Loss: 0.4470\n",
    "# Epoch 148, Test Accuracy: 77.46794871794872%\n",
    "# Epoch: 148, Loss: 0.4764\n",
    "# Epoch 149, Test Accuracy: 75.92948717948718%\n",
    "# Epoch: 149, Loss: 0.4626\n",
    "# Epoch 150, Test Accuracy: 77.75641025641026%\n",
    "# Epoch: 150, Loss: 0.4389\n",
    "# Epoch 151, Test Accuracy: 76.4423076923077%\n",
    "# Epoch: 151, Loss: 0.4589\n",
    "# Epoch 152, Test Accuracy: 75.28846153846153%\n",
    "# Epoch: 152, Loss: 0.4629\n",
    "# Epoch 153, Test Accuracy: 75.25641025641026%\n",
    "# Epoch: 153, Loss: 0.4657\n",
    "# Epoch 154, Test Accuracy: 77.33974358974359%\n",
    "# Epoch: 154, Loss: 0.4295\n",
    "# Epoch 155, Test Accuracy: 75.60897435897436%\n",
    "# Epoch: 155, Loss: 0.4251\n",
    "# Epoch 156, Test Accuracy: 74.58333333333333%\n",
    "# Epoch: 156, Loss: 0.3810\n",
    "# Epoch 157, Test Accuracy: 76.7948717948718%\n",
    "# Epoch: 157, Loss: 0.4282\n",
    "# Epoch 158, Test Accuracy: 72.91666666666667%\n",
    "# Epoch: 158, Loss: 0.4404\n",
    "# Epoch 159, Test Accuracy: 76.57051282051282%\n",
    "# Epoch: 159, Loss: 0.4588\n",
    "# Epoch 160, Test Accuracy: 70.48076923076923%\n",
    "# Epoch: 160, Loss: 0.4417\n",
    "# Epoch 161, Test Accuracy: 74.48717948717949%\n",
    "# Epoch: 161, Loss: 0.3933\n",
    "# Epoch 162, Test Accuracy: 75.48076923076923%\n",
    "# Epoch: 162, Loss: 0.3830"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 保留0.2比例数据集的时候, acc可以达到83, 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch: 0, Loss: 2.4985\n",
    "# Epoch 1, Test Accuracy: 8.333333333333334%\n",
    "# Epoch: 1, Loss: 2.3034\n",
    "# Epoch 2, Test Accuracy: 11.057692307692308%\n",
    "# Epoch: 2, Loss: 2.1631\n",
    "# Epoch 3, Test Accuracy: 31.314102564102566%\n",
    "# Epoch: 3, Loss: 2.0737\n",
    "# Epoch 4, Test Accuracy: 29.455128205128204%\n",
    "# Epoch: 4, Loss: 2.0066\n",
    "# Epoch 5, Test Accuracy: 27.78846153846154%\n",
    "# Epoch: 5, Loss: 1.9515\n",
    "# Epoch 6, Test Accuracy: 39.93589743589744%\n",
    "# Epoch: 6, Loss: 1.8830\n",
    "# Epoch 7, Test Accuracy: 46.34615384615385%\n",
    "# Epoch: 7, Loss: 1.8078\n",
    "# Epoch 8, Test Accuracy: 36.98717948717949%\n",
    "# Epoch: 8, Loss: 1.7677\n",
    "# Epoch 9, Test Accuracy: 50.67307692307692%\n",
    "# Epoch: 9, Loss: 1.6901\n",
    "# Epoch 10, Test Accuracy: 53.84615384615385%\n",
    "# Epoch: 10, Loss: 1.7320\n",
    "# Epoch 11, Test Accuracy: 50.0%\n",
    "# Epoch: 11, Loss: 1.6341\n",
    "# Epoch 12, Test Accuracy: 47.756410256410255%\n",
    "# Epoch: 12, Loss: 1.5898\n",
    "# Epoch 13, Test Accuracy: 57.17948717948718%\n",
    "# Epoch: 13, Loss: 1.5128\n",
    "# Epoch 14, Test Accuracy: 56.794871794871796%\n",
    "# Epoch: 14, Loss: 1.5693\n",
    "# Epoch 15, Test Accuracy: 57.94871794871795%\n",
    "# Epoch: 15, Loss: 1.4820\n",
    "# Epoch 16, Test Accuracy: 56.25%\n",
    "# Epoch: 16, Loss: 1.5141\n",
    "# Epoch 17, Test Accuracy: 60.28846153846154%\n",
    "# Epoch: 17, Loss: 1.4022\n",
    "# Epoch 18, Test Accuracy: 63.044871794871796%\n",
    "# Epoch: 18, Loss: 1.3857\n",
    "# Epoch 19, Test Accuracy: 62.243589743589745%\n",
    "# Epoch: 19, Loss: 1.3872\n",
    "# Epoch 20, Test Accuracy: 53.55769230769231%\n",
    "# Epoch: 20, Loss: 1.3657\n",
    "# Epoch 21, Test Accuracy: 58.044871794871796%\n",
    "# Epoch: 21, Loss: 1.2764\n",
    "# Epoch 22, Test Accuracy: 63.333333333333336%\n",
    "# Epoch: 22, Loss: 1.2844\n",
    "# Epoch 23, Test Accuracy: 64.1025641025641%\n",
    "# Epoch: 23, Loss: 1.2522\n",
    "# Epoch 24, Test Accuracy: 57.11538461538461%\n",
    "# Epoch: 24, Loss: 1.2526\n",
    "# Epoch 25, Test Accuracy: 63.493589743589745%\n",
    "# Epoch: 25, Loss: 1.2085\n",
    "# Epoch 26, Test Accuracy: 63.493589743589745%\n",
    "# Epoch: 26, Loss: 1.1821\n",
    "# Epoch 27, Test Accuracy: 61.25%\n",
    "# Epoch: 27, Loss: 1.1951\n",
    "# Epoch 28, Test Accuracy: 66.41025641025641%\n",
    "# Epoch: 28, Loss: 1.2076\n",
    "# Epoch 29, Test Accuracy: 63.044871794871796%\n",
    "# Epoch: 29, Loss: 1.2077\n",
    "# Epoch 30, Test Accuracy: 69.48717948717949%\n",
    "# Epoch: 30, Loss: 1.1012\n",
    "# Epoch 31, Test Accuracy: 73.71794871794872%\n",
    "# Epoch: 31, Loss: 1.1106\n",
    "# Epoch 32, Test Accuracy: 68.26923076923077%\n",
    "# Epoch: 32, Loss: 1.1134\n",
    "# Epoch 33, Test Accuracy: 69.42307692307692%\n",
    "# Epoch: 33, Loss: 1.0812\n",
    "# Epoch 34, Test Accuracy: 70.67307692307692%\n",
    "# Epoch: 34, Loss: 1.0660\n",
    "# Epoch 35, Test Accuracy: 74.35897435897436%\n",
    "# Epoch: 35, Loss: 0.9865\n",
    "# Epoch 36, Test Accuracy: 70.8974358974359%\n",
    "# Epoch: 36, Loss: 1.0079\n",
    "# Epoch 37, Test Accuracy: 72.43589743589743%\n",
    "# Epoch: 37, Loss: 0.9843\n",
    "# Epoch 38, Test Accuracy: 73.07692307692308%\n",
    "# Epoch: 38, Loss: 1.0135\n",
    "# Epoch 39, Test Accuracy: 69.16666666666667%\n",
    "# Epoch: 39, Loss: 1.0083\n",
    "# Epoch 40, Test Accuracy: 70.5448717948718%\n",
    "# Epoch: 40, Loss: 0.9708\n",
    "# Epoch 41, Test Accuracy: 71.28205128205128%\n",
    "# Epoch: 41, Loss: 0.9636\n",
    "# Epoch 42, Test Accuracy: 75.32051282051282%\n",
    "# Epoch: 42, Loss: 0.9646\n",
    "# Epoch 43, Test Accuracy: 73.87820512820512%\n",
    "# Epoch: 43, Loss: 0.9130\n",
    "# Epoch 44, Test Accuracy: 72.88461538461539%\n",
    "# Epoch: 44, Loss: 0.9650\n",
    "# Epoch 45, Test Accuracy: 71.7948717948718%\n",
    "# Epoch: 45, Loss: 0.9225\n",
    "# Epoch 46, Test Accuracy: 75.60897435897436%\n",
    "# Epoch: 46, Loss: 0.8877\n",
    "# Epoch 47, Test Accuracy: 75.3525641025641%\n",
    "# Epoch: 47, Loss: 0.8408\n",
    "# Epoch 48, Test Accuracy: 78.01282051282051%\n",
    "# Epoch: 48, Loss: 0.8472\n",
    "# Epoch 49, Test Accuracy: 71.98717948717949%\n",
    "# Epoch: 49, Loss: 0.8562\n",
    "# Epoch 50, Test Accuracy: 78.49358974358974%\n",
    "# Epoch: 50, Loss: 0.8462\n",
    "# Epoch 51, Test Accuracy: 77.21153846153847%\n",
    "# Epoch: 51, Loss: 0.8557\n",
    "# Epoch 52, Test Accuracy: 77.75641025641026%\n",
    "# Epoch: 52, Loss: 0.8065\n",
    "# Epoch 53, Test Accuracy: 75.03205128205128%\n",
    "# Epoch: 53, Loss: 0.7960\n",
    "# Epoch 54, Test Accuracy: 75.8974358974359%\n",
    "# Epoch: 54, Loss: 0.7944\n",
    "# Epoch 55, Test Accuracy: 75.86538461538461%\n",
    "# Epoch: 55, Loss: 0.7827\n",
    "# Epoch 56, Test Accuracy: 78.65384615384616%\n",
    "# Epoch: 56, Loss: 0.7448\n",
    "# Epoch 57, Test Accuracy: 77.40384615384616%\n",
    "# Epoch: 57, Loss: 0.7287\n",
    "# Epoch 58, Test Accuracy: 77.08333333333333%\n",
    "# Epoch: 58, Loss: 0.7436\n",
    "# Epoch 59, Test Accuracy: 79.26282051282051%\n",
    "# Epoch: 59, Loss: 0.7560\n",
    "# Epoch 60, Test Accuracy: 78.68589743589743%\n",
    "# Epoch: 60, Loss: 0.7371\n",
    "# Epoch 61, Test Accuracy: 79.1025641025641%\n",
    "# Epoch: 61, Loss: 0.7178\n",
    "# Epoch 62, Test Accuracy: 74.23076923076923%\n",
    "# Epoch: 62, Loss: 0.7227\n",
    "# Epoch 63, Test Accuracy: 75.41666666666667%\n",
    "# Epoch: 63, Loss: 0.7139\n",
    "# Epoch 64, Test Accuracy: 77.56410256410257%\n",
    "# Epoch: 64, Loss: 0.6641\n",
    "# Epoch 65, Test Accuracy: 78.91025641025641%\n",
    "# Epoch: 65, Loss: 0.7381\n",
    "# Epoch 66, Test Accuracy: 78.97435897435898%\n",
    "# Epoch: 66, Loss: 0.7037\n",
    "# Epoch 67, Test Accuracy: 77.94871794871794%\n",
    "# Epoch: 67, Loss: 0.7340\n",
    "# Epoch 68, Test Accuracy: 80.41666666666667%\n",
    "# Epoch: 68, Loss: 0.6814\n",
    "# Epoch 69, Test Accuracy: 79.32692307692308%\n",
    "# Epoch: 69, Loss: 0.6779\n",
    "# Epoch 70, Test Accuracy: 77.75641025641026%\n",
    "# Epoch: 70, Loss: 0.7095\n",
    "# Epoch 71, Test Accuracy: 79.13461538461539%\n",
    "# Epoch: 71, Loss: 0.6770\n",
    "# Epoch 72, Test Accuracy: 81.37820512820512%\n",
    "# Epoch: 72, Loss: 0.6236\n",
    "# Epoch 73, Test Accuracy: 80.67307692307692%\n",
    "# Epoch: 73, Loss: 0.6828\n",
    "# Epoch 74, Test Accuracy: 79.35897435897436%\n",
    "# Epoch: 74, Loss: 0.6693\n",
    "# Epoch 75, Test Accuracy: 81.47435897435898%\n",
    "# Epoch: 75, Loss: 0.6482\n",
    "# Epoch 76, Test Accuracy: 80.28846153846153%\n",
    "# Epoch: 76, Loss: 0.6355\n",
    "# Epoch 77, Test Accuracy: 79.4551282051282%\n",
    "# Epoch: 77, Loss: 0.5955\n",
    "# Epoch 78, Test Accuracy: 77.78846153846153%\n",
    "# Epoch: 78, Loss: 0.6345\n",
    "# Epoch 79, Test Accuracy: 79.87179487179488%\n",
    "# Epoch: 79, Loss: 0.5998\n",
    "# Epoch 80, Test Accuracy: 81.50641025641026%\n",
    "# Epoch: 80, Loss: 0.6197\n",
    "# Epoch 81, Test Accuracy: 78.10897435897436%\n",
    "# Epoch: 81, Loss: 0.6660\n",
    "# Epoch 82, Test Accuracy: 80.57692307692308%\n",
    "# Epoch: 82, Loss: 0.6022\n",
    "# Epoch 83, Test Accuracy: 81.02564102564102%\n",
    "# Epoch: 83, Loss: 0.5661\n",
    "# Epoch 84, Test Accuracy: 81.53846153846153%\n",
    "# Epoch: 84, Loss: 0.6097\n",
    "# Epoch 85, Test Accuracy: 80.32051282051282%\n",
    "# Epoch: 85, Loss: 0.5433\n",
    "# Epoch 86, Test Accuracy: 80.22435897435898%\n",
    "# Epoch: 86, Loss: 0.5903\n",
    "# Epoch 87, Test Accuracy: 80.83333333333333%\n",
    "# Epoch: 87, Loss: 0.5349\n",
    "# Epoch 88, Test Accuracy: 78.33333333333333%\n",
    "# Epoch: 88, Loss: 0.5690\n",
    "# Epoch 89, Test Accuracy: 81.25%\n",
    "# Epoch: 89, Loss: 0.5840\n",
    "# Epoch 90, Test Accuracy: 81.15384615384616%\n",
    "# Epoch: 90, Loss: 0.5646\n",
    "# Epoch 91, Test Accuracy: 77.98076923076923%\n",
    "# Epoch: 91, Loss: 0.5718\n",
    "# Epoch 92, Test Accuracy: 80.25641025641026%\n",
    "# Epoch: 92, Loss: 0.5077\n",
    "# Epoch 93, Test Accuracy: 83.01282051282051%\n",
    "# Epoch: 93, Loss: 0.6019\n",
    "# Epoch 94, Test Accuracy: 80.41666666666667%\n",
    "# Epoch: 94, Loss: 0.5507\n",
    "# Epoch 95, Test Accuracy: 82.56410256410257%\n",
    "# Epoch: 95, Loss: 0.5371\n",
    "# Epoch 96, Test Accuracy: 80.80128205128206%\n",
    "# Epoch: 96, Loss: 0.4970\n",
    "# Epoch 97, Test Accuracy: 83.65384615384616%\n",
    "# Epoch: 97, Loss: 0.5228\n",
    "# Epoch 98, Test Accuracy: 81.02564102564102%\n",
    "# Epoch: 98, Loss: 0.5231\n",
    "# Epoch 99, Test Accuracy: 82.27564102564102%\n",
    "# Epoch: 99, Loss: 0.4864\n",
    "# Epoch 100, Test Accuracy: 82.46794871794872%\n",
    "# Epoch: 100, Loss: 0.5336\n",
    "# Epoch 101, Test Accuracy: 80.7051282051282%\n",
    "# Epoch: 101, Loss: 0.4877\n",
    "# Epoch 102, Test Accuracy: 83.10897435897436%\n",
    "# Epoch: 102, Loss: 0.5088\n",
    "# Epoch 103, Test Accuracy: 82.08333333333333%\n",
    "# Epoch: 103, Loss: 0.4782\n",
    "# Epoch 104, Test Accuracy: 80.5448717948718%\n",
    "# Epoch: 104, Loss: 0.5261\n",
    "# Epoch 105, Test Accuracy: 83.0448717948718%\n",
    "# Epoch: 105, Loss: 0.4864\n",
    "# Epoch 106, Test Accuracy: 81.9551282051282%\n",
    "# Epoch: 106, Loss: 0.4866\n",
    "# Epoch 107, Test Accuracy: 79.67948717948718%\n",
    "# Epoch: 107, Loss: 0.5101\n",
    "# Epoch 108, Test Accuracy: 80.80128205128206%\n",
    "# Epoch: 108, Loss: 0.4859\n",
    "# Epoch 109, Test Accuracy: 82.75641025641026%\n",
    "# Epoch: 109, Loss: 0.5170\n",
    "# Epoch 110, Test Accuracy: 80.28846153846153%\n",
    "# Epoch: 110, Loss: 0.4696\n",
    "# Epoch 111, Test Accuracy: 83.5576923076923%\n",
    "# Epoch: 111, Loss: 0.4932\n",
    "# Epoch 112, Test Accuracy: 83.81410256410257%\n",
    "# Epoch: 112, Loss: 0.4546\n",
    "# Epoch 113, Test Accuracy: 83.65384615384616%\n",
    "# Epoch: 113, Loss: 0.4290\n",
    "# Epoch 114, Test Accuracy: 82.33974358974359%\n",
    "# Epoch: 114, Loss: 0.4392\n",
    "# Epoch 115, Test Accuracy: 83.62179487179488%\n",
    "# Epoch: 115, Loss: 0.4555\n",
    "# Epoch 116, Test Accuracy: 82.05128205128206%\n",
    "# Epoch: 116, Loss: 0.4202\n",
    "# Epoch 117, Test Accuracy: 83.71794871794872%\n",
    "# Epoch: 117, Loss: 0.4276\n",
    "# Epoch 118, Test Accuracy: 81.57051282051282%\n",
    "# Epoch: 118, Loss: 0.4361\n",
    "# Epoch 119, Test Accuracy: 82.8525641025641%\n",
    "# Epoch: 119, Loss: 0.4224\n",
    "# Epoch 120, Test Accuracy: 83.33333333333333%\n",
    "# Epoch: 120, Loss: 0.4673\n",
    "# Epoch 121, Test Accuracy: 81.66666666666667%\n",
    "# Epoch: 121, Loss: 0.4467\n",
    "# Epoch 122, Test Accuracy: 82.88461538461539%\n",
    "# Epoch: 122, Loss: 0.4532\n",
    "# Epoch 123, Test Accuracy: 82.56410256410257%\n",
    "# Epoch: 123, Loss: 0.4426\n",
    "# Epoch 124, Test Accuracy: 83.81410256410257%\n",
    "# Epoch: 124, Loss: 0.4284\n",
    "# Epoch 125, Test Accuracy: 81.76282051282051%\n",
    "# Epoch: 125, Loss: 0.4358\n",
    "# Epoch 126, Test Accuracy: 83.75%\n",
    "# Epoch: 126, Loss: 0.4264\n",
    "# Epoch 127, Test Accuracy: 81.02564102564102%\n",
    "# Epoch: 127, Loss: 0.4337\n",
    "# Epoch 128, Test Accuracy: 83.26923076923077%\n",
    "# Epoch: 128, Loss: 0.4178\n",
    "# Epoch 129, Test Accuracy: 82.5%\n",
    "# Epoch: 129, Loss: 0.4512\n",
    "# Epoch 130, Test Accuracy: 82.98076923076923%\n",
    "# Epoch: 130, Loss: 0.4261\n",
    "# Epoch 131, Test Accuracy: 83.91025641025641%\n",
    "# Epoch: 131, Loss: 0.3993\n",
    "# Epoch 132, Test Accuracy: 84.58333333333333%\n",
    "# Epoch: 132, Loss: 0.4189\n",
    "# Epoch 133, Test Accuracy: 83.75%\n",
    "# Epoch: 133, Loss: 0.3797\n",
    "# Epoch 134, Test Accuracy: 84.13461538461539%\n",
    "# Epoch: 134, Loss: 0.3584\n",
    "# Epoch 135, Test Accuracy: 84.93589743589743%\n",
    "# Epoch: 135, Loss: 0.3771\n",
    "# Epoch 136, Test Accuracy: 83.17307692307692%\n",
    "# Epoch: 136, Loss: 0.4366\n",
    "# Epoch 137, Test Accuracy: 83.97435897435898%\n",
    "# Epoch: 137, Loss: 0.3500\n",
    "# Epoch 138, Test Accuracy: 84.19871794871794%\n",
    "# Epoch: 138, Loss: 0.3840\n",
    "# Epoch 139, Test Accuracy: 83.9423076923077%\n",
    "# Epoch: 139, Loss: 0.4023\n",
    "# Epoch 140, Test Accuracy: 82.05128205128206%\n",
    "# Epoch: 140, Loss: 0.3959\n",
    "# Epoch 141, Test Accuracy: 82.82051282051282%\n",
    "# Epoch: 141, Loss: 0.4057\n",
    "# Epoch 142, Test Accuracy: 82.56410256410257%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def create_trigger(pattern=None, size=9):\n",
    "    \"\"\"\n",
    "    创建一个size x size的trigger,由3x3的黑白方块交替组成\n",
    "    \n",
    "    参数:\n",
    "    pattern : 一个长度为(size/3)^2的列表,指定每个3x3块的颜色(0为黑,1为白)\n",
    "               如果不指定,则随机生成\n",
    "    size : 触发器的大小，默认为9\n",
    "    \n",
    "    返回:\n",
    "    trigger : size x size的PIL Image对象,黑白图案\n",
    "    \"\"\"\n",
    "    block_num = (size // 3) ** 2\n",
    "    if pattern is None:\n",
    "        pattern = np.random.randint(0, 2, block_num)\n",
    "    elif len(pattern) != block_num:\n",
    "        raise ValueError(f\"Pattern must be a list of length {block_num}\")\n",
    "    \n",
    "    trigger = np.zeros((size, size), dtype=np.uint8)\n",
    "    \n",
    "    for i in range(size // 3):\n",
    "        for j in range(size // 3):\n",
    "            if pattern[i * (size // 3) + j] == 1:\n",
    "                trigger[i*3:i*3+3, j*3:j*3+3] = 255\n",
    "    \n",
    "    return Image.fromarray(trigger)\n",
    "\n",
    "class AddTrigger(object):\n",
    "    def __init__(self, trigger_img):\n",
    "        self.trigger = trigger_img\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return self.add_trigger(img)\n",
    "\n",
    "    def add_trigger(self, img):\n",
    "        # 确保图像是PIL Image\n",
    "        if not isinstance(img, Image.Image):\n",
    "            img = transforms.ToPILImage()(img)\n",
    "\n",
    "        # 获取原图和触发器的尺寸\n",
    "        img_width, img_height = img.size\n",
    "        trigger_width, trigger_height = self.trigger.size\n",
    "\n",
    "        # 计算触发器的位置（右下角）\n",
    "        position = (img_width - trigger_width, img_height - trigger_height)\n",
    "\n",
    "        # 创建一个新的图像，大小与原图相同\n",
    "        new_img = img.copy()\n",
    "        # 将触发器粘贴到新图像上\n",
    "        new_img.paste(self.trigger, position)\n",
    "\n",
    "        return new_img\n",
    "\n",
    "# 创建一个特定模式的trigger\n",
    "specific_pattern = [0, 1, 0, 1, 0, 1, 0, 1, 0]  # 棋盘模式\n",
    "trigger_img = create_trigger(specific_pattern, size=9)\n",
    "\n",
    "transform_with_trigger = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "    AddTrigger(trigger_img),  # 使用特定的触发器模式\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "# 测试代码\n",
    "if __name__ == \"__main__\":\n",
    "    # 假设我们有一个示例图像\n",
    "    sample_image = Image.new('RGB', (224, 224), color = (111, 109, 137))\n",
    "    \n",
    "    # 应用transform\n",
    "    transformed_image = transform_with_trigger(sample_image)\n",
    "    \n",
    "    # 显示结果\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.imshow(transforms.ToPILImage()(transformed_image))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "revision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
