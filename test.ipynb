{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 4, 4, 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 给定一个距离矩阵 和 一组的距离, 返回该距离在距离矩阵中的排名\n",
    "def get_ranks_of_distance(distances, distance_matrix):\n",
    "    # distance[i] 在 distance_matrix[i]中排第几\n",
    "    ranks = []\n",
    "    for i in range(distance_matrix.shape[0]):\n",
    "        ranks.append(np.sum(distance_matrix[i] < distances[i])+1)\n",
    "    return ranks\n",
    "# 给定ranks向量, 和一个阈值, 返回向量中<=阈值的个数\n",
    "def count_less_than_or_equal_to_threshold(ranks, threshold):\n",
    "    return sum([1 for rank in ranks if rank <= threshold])\n",
    "\n",
    "\n",
    "\n",
    "# 创建一个示例距离矩阵\n",
    "distance_matrix = np.array([\n",
    "    [0.0, 0.3, 0.2, 0.4],\n",
    "    [0.3, 0.0, 0.5, 0.1],\n",
    "    [0.2, 0.5, 0.0, 0.6],\n",
    "    [0.4, 0.1, 0.6, 0.0]\n",
    "])\n",
    "\n",
    "# 给定一组距离, 返回该距离在距离矩阵中的排名\n",
    "distances = [0.7, 0.5, 0.6, 0.1]\n",
    "ranks = get_ranks_of_distance(distances, distance_matrix)\n",
    "\n",
    "print(ranks) # [2, 3, 4, 2]\n",
    "\n",
    "num_malicious = 0\n",
    "# 给定ranks向量, 和一个阈值, 返回向量中<=阈值的个数\n",
    "rank_threshold = distance_matrix.shape[0]//2 - num_malicious\n",
    "count = count_less_than_or_equal_to_threshold(ranks, rank_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 1. 0.]\n",
      " [0. 1. 0. 1.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 0. 1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 距离矩阵转为投票向量\n",
    "def votes_by_dismatrix(dis_matrix):\n",
    "    # 获取每行前half_clients个最小距离值的索引\n",
    "    half_ = dis_matrix.shape[0] // 2\n",
    "    top_indices = np.argsort(dis_matrix, axis=1)[:, :half_]\n",
    "    # 创建一个全零的矩阵，然后将每行的[half_clients个最小距离值的索引]位置标为1\n",
    "    result_matrix = np.zeros_like(dis_matrix)\n",
    "    rows, cols = np.indices(top_indices.shape)\n",
    "    result_matrix[rows, top_indices] = 1\n",
    "    print(result_matrix)\n",
    "    column_sums = np.sum(result_matrix, axis=0)\n",
    "    return column_sums\n",
    "\n",
    "votes = votes_by_dismatrix(distance_matrix)\n",
    "votes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. update_update_convert_to_vector test:\n",
      "   Vector shape: torch.Size([67])\n",
      "   Vector sum: 1.730630874633789\n",
      "\n",
      "2. extract_shapes test:\n",
      "   fc1.weight: torch.Size([5, 10])\n",
      "   fc1.bias: torch.Size([5])\n",
      "   fc2.weight: torch.Size([2, 5])\n",
      "   fc2.bias: torch.Size([2])\n",
      "\n",
      "   Total parameters: 67\n",
      "\n",
      "3. vector_to_state_dict test:\n",
      "   fc1.weight: Match\n",
      "   fc1.bias: Match\n",
      "   fc2.weight: Match\n",
      "   fc2.bias: Match\n",
      "\n",
      "Overall process validation: Successful\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# 定义测试用的简单神经网络\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        self.fc2 = nn.Linear(5, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 定义函数\n",
    "def update_update_convert_to_vector(model_update):\n",
    "    return torch.cat([model_update[k].flatten() for k in model_update])\n",
    "\n",
    "def extract_shapes(state_dict):\n",
    "    shape_dict = {}\n",
    "    for name, param in state_dict.items():\n",
    "        shape_dict[name] = param.shape\n",
    "    return shape_dict\n",
    "\n",
    "def vector_to_state_dict(vector, shape_dict, benign_update_length):\n",
    "    assert benign_update_length == len(vector)\n",
    "    state_dict = {}\n",
    "    start = 0\n",
    "    for name, shape in shape_dict.items():\n",
    "        length = np.prod(shape)\n",
    "        state_dict[name] = vector[start:start+length].view(shape)\n",
    "        start += length\n",
    "    return state_dict\n",
    "\n",
    "# 测试函数\n",
    "def run_tests():\n",
    "    # 创建模型和模型更新\n",
    "    model = SimpleNet()\n",
    "    original_state_dict = model.state_dict()\n",
    "    model_update = {name: param.clone() for name, param in original_state_dict.items()}\n",
    "    \n",
    "    # 测试 update_update_convert_to_vector\n",
    "    update_vector = update_update_convert_to_vector(model_update)\n",
    "    print(f\"1. update_update_convert_to_vector test:\")\n",
    "    print(f\"   Vector shape: {update_vector.shape}\")\n",
    "    print(f\"   Vector sum: {update_vector.sum()}\")\n",
    "    \n",
    "    # 测试 extract_shapes\n",
    "    shape_dict = extract_shapes(model_update)\n",
    "    print(f\"\\n2. extract_shapes test:\")\n",
    "    for name, shape in shape_dict.items():\n",
    "        print(f\"   {name}: {shape}\")\n",
    "    \n",
    "    # 计算总参数数量\n",
    "    benign_update_length = sum([np.prod(shape) for shape in shape_dict.values()])\n",
    "    print(f\"\\n   Total parameters: {benign_update_length}\")\n",
    "    \n",
    "    # 测试 vector_to_state_dict\n",
    "    reconstructed_state_dict = vector_to_state_dict(update_vector, shape_dict, benign_update_length)\n",
    "    print(f\"\\n3. vector_to_state_dict test:\")\n",
    "    for name in reconstructed_state_dict:\n",
    "        original = model_update[name]\n",
    "        reconstructed = reconstructed_state_dict[name]\n",
    "        is_equal = torch.all(torch.eq(original, reconstructed))\n",
    "        print(f\"   {name}: {'Match' if is_equal else 'Mismatch'}\")\n",
    "    \n",
    "    # 验证整个过程的正确性\n",
    "    is_valid = all(torch.all(torch.eq(model_update[name], reconstructed_state_dict[name])) for name in model_update)\n",
    "    print(f\"\\nOverall process validation: {'Successful' if is_valid else 'Failed'}\")\n",
    "\n",
    "# 运行测试\n",
    "run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/oAAAIjCAYAAACzoGDyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACmE0lEQVR4nOzdd1RUx98G8Gd36b2DFOkWxIoVwYqC0ShqbCl2jQVFsSQaYzcm9h5j7ElI1GgwNizYUBEbdlFUFAXpUgSpe98/+LFvEFBQcFl4Pud4zM7OvfvdHYw+O3PnigRBEEBERERERERE1YJY3gUQERERERERUcVh0CciIiIiIiKqRhj0iYiIiIiIiKoRBn0iIiIiIiKiaoRBn4iIiIiIiKgaYdAnIiIiIiIiqkYY9ImIiIiIiIiqEQZ9IiIiIiIiomqEQZ+IiIiIiIioGmHQJyKiGkckEmHu3LnyLkOh2NjYYOjQofIuo0Z58uQJRCIRli1bVumvtX37dohEIjx58qTcx54+fRoikQinT5+u8LqIiOj9MOgTEZFcPXr0CF9//TXs7OygpqYGHR0dtG3bFqtXr8br16/lXV6FKgxTV65ckXcpCkUkEhX5paOjg/bt2+PQoUPvfU5/f3+sWrWq4or8jwMHDqB9+/YwMTGBhoYG7Ozs0L9/fwQGBlbK6xEREb1JSd4FEBFRzXXo0CH069cPqqqqGDx4MJydnZGTk4Nz585h2rRpuHPnDjZt2lThr/v69WsoKfGvwPK4f/8+xGL5zQ906dIFgwcPhiAIePr0KX7++Wd8+umnOHLkCDw9Pct9Pn9/f9y+fRuTJk2q0DqXLVuGadOmoX379pgxYwY0NDTw8OFDnDhxAn/99Re8vLwq9PWIiIhKwn/lEBGRXERGRmLgwIGwtrbGyZMnUatWLdlz48ePx8OHDz9oxvZt1NTUKuW8iiIvLw9SqRQqKiplPkZVVbUSK3q3OnXq4Msvv5Q97tu3L5ycnLB69er3CvqVIS8vDwsWLECXLl1w7NixYs/Hx8fLoSoiIqqJuHSfiIjkYsmSJXj16hW2bNlSJOQXcnBwgK+vr+xxYYiyt7eHqqoqbGxsMHPmTGRnZxc57sqVK/D09ISRkRHU1dVha2uL4cOHF+nz5jX6c+fOhUgkwsOHDzF06FDo6elBV1cXw4YNQ2ZmZrHafv/9d7i4uEBdXR0GBgYYOHAgnj179oGfyP+Ljo7G8OHDYWpqClVVVTRo0ABbt24t0icnJwezZ8+Gi4sLdHV1oampCXd3d5w6dapIv/9e571q1SrZ53f37t1yve83r9EvvAzh/Pnz8PPzg7GxMTQ1NdG7d28kJCQUOVYqlWLu3LkwNzeHhoYGOnbsiLt3737Qdf/169eHkZERHj16VKR9//796N69O8zNzaGqqgp7e3ssWLAA+fn5sj4dOnTAoUOH8PTpU9nlADY2NrLns7OzMWfOHDg4OEBVVRVWVlaYPn16sZ+1NyUmJiItLQ1t27Yt8XkTE5Mij7OysjB37lzUqVMHampqqFWrFvr06VPsPQHApk2bZGPXokULXL58uVif8PBwfPbZZzAwMICamhqaN2+Of//9t1i/O3fuoFOnTlBXV4elpSUWLlwIqVRarF9pe1mUddxCQ0Ph5eUFXV1daGhooH379jh//vw7jyMiog/HGX0iIpKLAwcOwM7ODq6urmXqP3LkSOzYsQOfffYZpkyZgtDQUCxevBj37t3DP//8A6BgxrRr164wNjbGt99+Cz09PTx58gT79u0r02v0798ftra2WLx4Ma5du4bNmzfDxMQEP/30k6zPokWL8P3336N///4YOXIkEhISsHbtWrRr1w5hYWHQ09Mr92fxX3FxcWjdujVEIhF8fHxgbGyMI0eOYMSIEUhLS5MtNU9LS8PmzZsxaNAgjBo1Cunp6diyZQs8PT1x6dIlNGnSpMh5t23bhqysLIwePRqqqqowMDAo1/suzYQJE6Cvr485c+bgyZMnWLVqFXx8fLBr1y5ZnxkzZmDJkiX49NNP4enpiRs3bsDT0xNZWVnv/Tmlpqbi5cuXsLe3L9K+fft2aGlpwc/PD1paWjh58iRmz56NtLQ0LF26FADw3XffITU1Fc+fP8fKlSsBAFpaWgAKvpTo2bMnzp07h9GjR6N+/fq4desWVq5ciQcPHiAgIKDUmkxMTKCuro4DBw5gwoQJRT7jN+Xn56NHjx4ICgrCwIED4evri/T0dBw/fhy3b98u8r78/f2Rnp6Or7/+GiKRCEuWLEGfPn3w+PFjKCsrAygI723btoWFhQW+/fZbaGpqYvfu3fD29sbevXvRu3dvAEBsbCw6duyIvLw8Wb9NmzZBXV29/IPwFidPnkS3bt3g4uKCOXPmQCwWY9u2bejUqROCg4PRsmXLCn09IiJ6g0BERPSRpaamCgCEXr16lan/9evXBQDCyJEji7RPnTpVACCcPHlSEARB+OeffwQAwuXLl996PgDCnDlzZI/nzJkjABCGDx9epF/v3r0FQ0ND2eMnT54IEolEWLRoUZF+t27dEpSUlIq1v2nbtm3vrG/EiBFCrVq1hMTExCLtAwcOFHR1dYXMzExBEAQhLy9PyM7OLtLn5cuXgqmpaZH3ERkZKQAQdHR0hPj4+CL9y/q+BUEQrK2thSFDhhR7Lx4eHoJUKpW1T548WZBIJEJKSoogCIIQGxsrKCkpCd7e3kXON3fuXAFAkXOWBoAwYsQIISEhQYiPjxeuXLkieHl5CQCEpUuXFulb+Pn819dffy1oaGgIWVlZsrbu3bsL1tbWxfr+9ttvglgsFoKDg4u0b9y4UQAgnD9//q21zp49WwAgaGpqCt26dRMWLVokXL16tVi/rVu3CgCEFStWFHuu8PMsHDtDQ0MhOTlZ9vz+/fsFAMKBAwdkbZ07dxYaNmxY5D1KpVLB1dVVcHR0lLVNmjRJACCEhobK2uLj4wVdXV0BgBAZGSlrf/PPSaE3fxZOnTolABBOnTole11HR0fB09OzyM9GZmamYGtrK3Tp0qWET46IiCoSl+4TEdFHl5aWBgDQ1tYuU//Dhw8DAPz8/Iq0T5kyBQBk1/IXzqYfPHgQubm55a5rzJgxRR67u7sjKSlJVu++ffsglUrRv39/JCYmyn6ZmZnB0dGx2LL58hIEAXv37sWnn34KQRCKvIanpydSU1Nx7do1AIBEIpFdYy+VSpGcnIy8vDw0b95c1ue/+vbtC2Nj4/d6328zevRoiESiIsfm5+fj6dOnAICgoCDk5eVh3LhxRY6bMGHCO8/9X1u2bIGxsTFMTEzQvHlzBAUFYfr06cV+Jv47M52eno7ExES4u7sjMzMT4eHh73ydPXv2oH79+qhXr16Rz79Tp04A8M4xnjdvHvz9/dG0aVMcPXoU3333HVxcXNCsWTPcu3dP1m/v3r0wMjIq8XP47+cJAAMGDIC+vr7ssbu7OwDg8ePHAIDk5GScPHkS/fv3l73nxMREJCUlwdPTExEREYiOjgZQ8GepdevWRWbUjY2N8cUXX7zzsymr69evIyIiAp9//jmSkpJk9WRkZKBz5844e/ZsiZcKEBFRxeHSfSIi+uh0dHQAFASxsnj69CnEYjEcHByKtJuZmUFPT08WKtu3b4++ffti3rx5WLlyJTp06ABvb298/vnnZdpMrnbt2kUeF4arly9fQkdHBxERERAEAY6OjiUeX7iM+n0lJCQgJSUFmzZtKvVuA//d0G3Hjh1Yvnw5wsPDi3yxYWtrW+y4ktoKvet9v83bjgUgG5s3x87AwKBIeH2XXr16wcfHBzk5Obh8+TJ++OEHZGZmFrsTwJ07dzBr1iycPHmy2BcVqamp73ydiIgI3Lt3r9QvRcqyod6gQYMwaNAgpKWlITQ0FNu3b4e/vz8+/fRT3L59G2pqanj06BHq1q1bprs/vOszfvjwIQRBwPfff4/vv/++1LotLCzw9OlTtGrVqtjzdevWfWcdZRUREQEAGDJkSKl9UlNTyzX+RERUPgz6RET00eno6MDc3By3b98u13FvznSW9Pzff/+Nixcv4sCBAzh69CiGDx+O5cuX4+LFi7LrsEsjkUhKbBcEAUDBzLlIJMKRI0dK7Puu879L4Sznl19+WWpIatSoEYCCDQGHDh0Kb29vTJs2DSYmJpBIJFi8eHGJm7m97Rrsd73vt/mQY8vD0tISHh4eAIBPPvkERkZG8PHxQceOHdGnTx8AQEpKCtq3bw8dHR3Mnz8f9vb2UFNTw7Vr1/DNN9+UaRZZKpWiYcOGWLFiRYnPW1lZlblmHR0ddOnSBV26dIGysjJ27NiB0NBQtG/fvsznAMr2cwkAU6dOLfUOBG9+0fIh/ruxYUkK61m6dGmxvSIKfeifFSIiejsGfSIikosePXpg06ZNCAkJQZs2bd7a19raGlKpFBEREahfv76sPS4uDikpKbC2ti7Sv3Xr1mjdujUWLVoEf39/fPHFF/jrr78wcuTID6rZ3t4egiDA1tYWderU+aBzlcTY2Bja2trIz8+XhdrS/P3337Czs8O+ffuKfAEyZ86cCq/rQxSOzcOHD4usKkhKSpLNSL+Pr7/+GitXrsSsWbPQu3dviEQinD59GklJSdi3bx/atWsn6xsZGVns+NK+NLK3t8eNGzfQuXPnd36xVB7NmzfHjh078OLFC9nrhIaGIjc394NXgtjZ2QEoWFHyrp8ba2tr2Yz7f92/f79Ym76+PlJSUoq05eTkyN5DaQo3EtTR0XlnPUREVDl4jT4REcnF9OnToampiZEjRyIuLq7Y848ePcLq1asBFMzgAsCqVauK9Cmcde3evTuAgqXMb84kF84ovuvWaGXRp08fSCQSzJs3r9jrCIKApKSkDzq/RCJB3759sXfv3hJXO/z3tnWFs7z/rSM0NBQhISEfVENF69y5M5SUlPDzzz8XaV+3bt0HnVdJSQlTpkzBvXv3sH//fgAlfyY5OTnYsGFDseM1NTVLXMrfv39/REdH49dffy323OvXr5GRkVFqTZmZmaV+/keOHAHw/0vk+/bti8TExBI/h/KuhjAxMUGHDh3wyy+/lBjC//tz88knn+DixYu4dOlSkef/+OOPYsfZ29vj7NmzRdo2bdr0zhl9FxcX2NvbY9myZXj16tVb6yEiosrBGX0iIpILe3t7+Pv7Y8CAAahfvz4GDx4MZ2dn5OTk4MKFC9izZ4/sXt2NGzfGkCFDsGnTJtny7EuXLmHHjh3w9vZGx44dARRcs75hwwb07t0b9vb2SE9Px6+//godHR3ZlwUfWvPChQsxY8YMPHnyBN7e3tDW1kZkZCT++ecfjB49GlOnTn3nebZu3YrAwMBi7b6+vvjxxx9x6tQptGrVCqNGjYKTkxOSk5Nx7do1nDhxAsnJyQAKVkTs27cPvXv3Rvfu3REZGYmNGzfCycmpxHAlL6ampvD19cXy5cvRs2dPeHl54caNGzhy5AiMjIw+aNZ86NChmD17Nn766Sd4e3vD1dUV+vr6GDJkCCZOnAiRSITffvutxODs4uKCXbt2wc/PDy1atICWlhY+/fRTfPXVV9i9ezfGjBmDU6dOoW3btsjPz0d4eDh2796No0ePonnz5iXWk5mZCVdXV7Ru3RpeXl6wsrJCSkoKAgICEBwcDG9vbzRt2hQAMHjwYOzcuRN+fn64dOkS3N3dkZGRgRMnTmDcuHHo1atXuT6L9evXw83NDQ0bNsSoUaNgZ2eHuLg4hISE4Pnz57hx4waAgi/YfvvtN3h5ecHX11d2ez1ra2vcvHmzyDlHjhyJMWPGoG/fvujSpQtu3LiBo0ePwsjI6K21iMVibN68Gd26dUODBg0wbNgwWFhYIDo6GqdOnYKOjg4OHDhQrvdHRETl9PE3+iciIvp/Dx48EEaNGiXY2NgIKioqgra2ttC2bVth7dq1RW4VlpubK8ybN0+wtbUVlJWVBSsrK2HGjBlF+ly7dk0YNGiQULt2bUFVVVUwMTERevToIVy5cqXIa6KU2+slJCQU6Vd4C7n/3nJMEARh7969gpubm6CpqSloamoK9erVE8aPHy/cv3//re+18Hyl/Xr27JkgCIIQFxcnjB8/XrCyshKUlZUFMzMzoXPnzsKmTZtk55JKpcIPP/wgWFtbC6qqqkLTpk2FgwcPCkOGDCly27jCW7S9eRu68r7v0m6v9+atAt+81ZogFNwK8PvvvxfMzMwEdXV1oVOnTsK9e/cEQ0NDYcyYMW/9zAShYLzGjx9f4nOFt+krfL3z588LrVu3FtTV1QVzc3Nh+vTpwtGjR4vV9OrVK+Hzzz8X9PT0BABFPrOcnBzhp59+Eho0aCCoqqoK+vr6gouLizBv3jwhNTW11Dpzc3OFX3/9VfD29paNi4aGhtC0aVNh6dKlxW6HmJmZKXz33Xeyn2kzMzPhs88+Ex49eiQIwtvH7s2fYUEQhEePHgmDBw8WzMzMBGVlZcHCwkLo0aOH8Pfffxfpd/PmTaF9+/aCmpqaYGFhISxYsEDYsmVLsTHPz88XvvnmG8HIyEjQ0NAQPD09hYcPH77z9nqFwsLChD59+giGhoaCqqqqYG1tLfTv318ICgoq9TMkIqKKIRKECt4th4iIiOgdUlJSoK+vj4ULF+K7776TdzlERETVCq/RJyIiokr1+vXrYm2F+y106NDh4xZDRERUA/AafSIiIqpUu3btwvbt2/HJJ59AS0sL586dw59//omuXbuibdu28i6PiIio2mHQJyIiokrVqFEjKCkpYcmSJUhLS5Nt0Ldw4UJ5l0ZERFQt8Rp9IiIiIiIiomqE1+gTERERERERVSMM+kRERERERETVCK/Rf09SqRQxMTHQ1taGSCSSdzlERERERERUzQmCgPT0dJibm0MsLn3enkH/PcXExMDKykreZRAREREREVEN8+zZM1haWpb6PIP+e9LW1gZQ8AHr6OjIuZrS5ebm4tixY+jatSuUlZXlXQ6VguOkGDhOioNjpRg4ToqB46QYOE6Kg2OlGKrqOKWlpcHKykqWR0vDoP+eCpfr6+joVPmgr6GhAR0dnSr1A0pFcZwUA8dJcXCsFAPHSTFwnBQDx0lxcKwUQ1Ufp3ddPs7N+IiIiIiIiIiqEQZ9IiIiIiIiomqEQZ+IiIiIiIioGmHQJyIiIiIiIqpGGPSJiIiIiIiIqhEGfSIiIiIiIqJqhEGfqgWRSISAgIC39hk6dCi8vb3LfM4nT55AJBLh+vXrH1QbERERERHRx8SgT1VOeQM5ALx48QLdunUDUHpAX716NbZv314xRf5Phw4dMGnSpFKfF4lEsl86Ojpo0aIF9u/fX+7XEQQBs2fPRq1ataCurg4PDw9ERES887j169fDxsYGampqaNWqFS5dulTk+U2bNqFDhw7Q0dGBSCRCSkpKuWsjIiIiIqKqhUGfykUQBHmXUCIzMzOoqqq+tY+uri709PQ+TkH/sW3bNrx48QJXrlxB27Zt8dlnn+HWrVvlOseSJUuwZs0abNy4EaGhodDU1ISnpyeysrJKPWbXrl3w8/PDnDlzcO3aNTRu3Bienp6Ij4+X9cnMzISXlxdmzpz53u+PiIiIiIiqFgZ9eqecnBz8+eefcHV1hYGBwVvDZWXo0KEDJk6ciOnTp8PAwABmZmaYO3dukT7/Xbpva2sLAGjatClEIhE6dOgAoPhKgcDAQLi5uUFPTw+Ghobo0aMHHj16VOH16+npwczMDHXq1MGCBQuQl5eHU6dOlfl4QRCwatUqzJo1C7169UKjRo2wc+dOxMTEvPVyhRUrVmDUqFEYNmwYnJycsHHjRmhoaGDr1q2yPpMmTcK3336L1q1bf8hbJCIiIiKiKoRBn0oVFRWFWbNmoVatWvj8889x8eJFpKSkQCz++D82O3bsgKamJkJDQ7FkyRLMnz8fx48fL7Fv4fL0EydO4MWLF9i3b1+J/TIyMuDn54crV64gKCgIYrEYvXv3hlQqrZT3kJeXhy1btgAAVFRUZO1z586Fo6NjqcdFRkYiNjYWHh4esjZdXV20atUKISEhJR6Tk5ODq1evFjlGLBbDw8Oj1GOIiIiIiKh6UJJ3AVS1SKVSBAUFYe3atTh48CDEYjHy8/MBFMwsa2hoFAmpH0ujRo0wZ84cAICjoyPWrVuHoKAgdOnSpVhfY2NjAIChoSHMzMxKPWffvn2LPN66dSuMjY1x9+5dODs7V1jtgwYNgkQiwevXryGVSmFjY4P+/fvLnjcyMoKdnV2px8fGxgIATE1Ni7SbmprKnntTYmIi8vPzSzwmPDz8fd8KEREREREpAM7oEwDg5cuXWLlyJRwcHNC1a1ccPnwYgiDIQn4hXV1dudTXqFGjIo9r1apV5Frz9xEREYFBgwbBzs4OOjo6sLGxAVCwkqEirVy5EtevX8eRI0fg5OSEzZs3w8DAQPa8j48Pjh49WqGvSURERERENZfcg/67dgV/0549e1CvXj2oqamhYcOGOHz4cJHn9+3bh65du8LQ0LDUW6NlZWVh/PjxMDQ0hJaWFvr27Yu4uLiKfFsK49q1axg+fDhq1aqFKVOmIDIyEgCKBfxChoaGH7M8GWVl5SKPRSLRBy+x//TTT5GcnIxff/0VoaGhCA0NBVCw7L0imZmZyb5A2bZtGwYMGFCuLykKVyW8+TMaFxdX6ooFIyMjSCSSch1DRERERETVg1yDfll2Bf+vCxcuYNCgQRgxYgTCwsLg7e0Nb29v3L59W9YnIyMDbm5u+Omnn0p93cmTJ+PAgQPYs2cPzpw5g5iYGPTp06fC319VlZWVhZ07d6J58+ZwcXHBb7/9huzs7DLtqJ+eno61a9fijz/+wJEjR3Dp0iU8fPgQycnJpX458LEVXlrwtnqSkpJw//59zJo1C507d0b9+vXx8uXLSq+tZcuWcHFxwaJFi8p8jK2tLczMzBAUFCRrS0tLQ2hoKNq0aVPiMSoqKnBxcSlyTOFlGaUdQ0RERERE1YNcr9H/767gALBx40YcOnQIW7duxbffflus/+rVq+Hl5YVp06YBABYsWIDjx49j3bp12LhxIwDgq6++AlBwL/WSpKamYsuWLfD390enTp0AFNz+rH79+rh48WK12318R8hT3HshwsvQKLyMj8HJf/7AyQB/ZL5Kh0gkAlCwSVxZRUdHw9fXt8QvBUQiEbS0tGS72BsbG8PIyAgGBgayX4aGhrLfXVxcis3UVwQTExOoq6sjMDAQlpaWUFNTK3bJgb6+PgwNDbFp0ybUqlULUVFRJf7MlUVCQkKxlSO1atUqdn18oUmTJqF3796YPn06LCwssG7dOuzbtw++vr4l9heJRJg0aRIWLlwIR0dH2Nra4vvvv4e5uXmRuwh07twZvXv3ho+PDwDAz88PQ4YMQfPmzdGyZUusWrUKGRkZsj9vQMH1/7GxsXj48CEA4NatW9DW1kbt2rWLXF5ARERERESKQ25Bv3BX8BkzZsja3rUreEhICPz8/Iq0eXp6vvUWY2+6evUqcnNzi+xGXq9ePdSuXRshISGlBv3s7GxkZ2fLHqelpQEAcnNzkZubW+bX/9gWHr4PQILfjm9Hwr6FAEQACkJ6WWbw3/S2LwUEQUB6ejrS09Px7NkzAIBYIoHkf7v05+fnF1lu/8MPP2Dq1KnFziOVSiGVSmWfqyAIRR6X1KewtsLHK1euxKJFizB79my4ubnhxIkTxY75/fffMXnyZDg7O6NOnTpYuXIlPDw8ZOcp7Pe2MRYEAf7+/vD39y/SPnfuXNm96f9bF1AQyG1sbLBgwQKsXbsWcXFxstv6lfY6kydPRlpaGkaPHo2UlBS0bdsWBw4cgEQikR3z6NEjxMXFyR736dMHsbGxmD17NmJjY9G4cWMcPHgQBgYGsj7r16/HwoULZa/Trl07AMDmzZsxePDgEmupyf77M0FVG8dKMXCcFAPHSTFwnBQHx0oxVNVxKms9IuF90l4FiImJgYWFBS5cuFBkKfH06dNx5swZ2fXS/6WiooIdO3Zg0KBBsrYNGzZg3rx5xa5FfvLkCWxtbREWFoYmTZrI2v39/TFs2LAioR0oWFLdsWPHUpf8z507F/PmzSvW7u/vDw0NjTK9549NEICdEWIIADJeJuDy70uQ8uy+vMsCAIhEYrTvOwQe3b2hqyxAVwXQUgbEInlXRkREREREVDVlZmbi888/R2pqKnR0dErtx9vrldGMGTOKrCZIS0uDlZUVunbt+tYPWN665ubi+PHj6NJlIJTmfok///wT06ZNQ1JSUqXdL74sBEGKWxk6iAyXyNqUxCLU0lWDpb46LPTUYamvDku9/z3WV4eJlirE1fSbgFzZOHWplMsZqGJwnBQHx0oxcJwUA8dJMXCcFAfHSjFU1XEqXFn+LnIL+u+zK7iZmdkH7yJuZmaGnJwcpKSkQE9Pr8znUVVVhaqqarF2ZWXlKjXwpSmsc8iQIejTpw/mz5+PlStXQiQSlesa/YrU1NESaha6iE3LQuKrbORJBTx7+RrPXr4usb+KRAxLA3XYGWnC1kgTtkZasDXShL2xJoy1VWV7DigyRfl5quk4ToqDY6UYOE6KgeOkGDhOioNjpRiq2jiVtRa5Bf3/7gpeuKFY4a7ghZuJvalNmzYICgrCpEmTZG3Hjx8v1y7ihRvABQUFoW/fvgCA+/fvIyoqqsbsRq6trY2lS5dixIgRGD9+PE6ePAmxWPzOGX6xWAyxWAyRSARBED74C4LZn7WCu7sbACAvX4r49Gw8f/kaz19m4vnL13iWXPD785RMxKRkISdfiscJGXickFHsXJoqEtgaF4T/OiZaqGOmjbqm2rAy0ICkmq4CICIiIiIiKolcl+6/a1fwwYMHw8LCAosXLwYA+Pr6on379li+fDm6d++Ov/76C1euXMGmTZtk50xOTkZUVBRiYmIAFIR4oGAm38zMDLq6uhgxYgT8/PxgYGAAHR0dTJgwAW3atKl2O+6/S7169XDixAkEBARgwoQJePHixVvDvlQqxciRI6Grq4vk5GQkJycjISEBCQkJSE5ORkpKSqmbQ0gkEojFYgiCgPz8fAiCUGRXdyWJGOZ66jDXU0dL2+K7veflS/EiNQtRyZl4nJiByIQMPE58hcjEDDxLzkRGTj5uR6fhdnTRpSxqymI4mGihjmlB8K9jpo36Zjow1akeKwCIiIiIiIjeJNegP2DAACQkJMh2BW/SpAkCAwNltyWLioqC+H87tgOAq6sr/P39MWvWLMycOROOjo4ICAiAs7OzrM+///5b5PZhAwcOBADMmTMHc+fOBVCwI7tYLEbfvn2RnZ0NT09PbNiw4SO846pHJBKhd+/e8PLywk8//YTFixdDKpWWOls/YcKEIp/3m16/fi37EqC0X0lJSRCLxbC3ty9znUoSMawMNGBloIG2DkZFnsvJkxZ8AZDwCo8SMhARn44HcemIiHuFrFxpiV8AGGmpwMlcF87mOnC20IWzuS6sDNQZ/omIiIiISOHJfTM+Hx+fUpfqnz59ulhbv3790K9fv1LPN3ToUAwdOvStr6mmpob169dj/fr15Sm1WlNXV8fcuXMxdOhQTJo0Cfv37y9xOf+77q2urq4OCwsLWFhYVGa5RagoFczaO5hoFWnPlwqISs7E/diC4H8/Lh33Y9MRmZiBxFc5OPsgAWcfJMj6a6spoYG5DpzNddHYSg9NrPRgqc/wT0REREREikXuQZ+qFhsbGwQEBODYsWMYN24cHj9+jP/egVFfX1+O1ZWPRCz636Z9mvBy/v+NFrNy8xEem47b0am4E5OKOzFpCH+RjvSsPFx8nIyLj5NlfY20VNDESh9NaxcE/0aWutBWqzqbcRAREREREb2JQZ9K1LVrV9y9exerV6/GnDlz8Pr1a6iqqkJdXV3epX0wNWUJmvxvxr5Qbr4UEXGvcCcmFbeiU3H9WQruxqQh8VUOTtyLw4l7BXd7EIkARxMtNKutj+Y2BmhpY8Al/0REREREVKUw6FOpVFRUMG3aNHzxxReYNm0a0tPT5V1SpVGWiOFkrgMncx30a24FoGDm/05MGsKiXuL6sxRcf5aC5y9f40HcKzyIe4W/Lj8DAJjqqKKlrSFa2uijha0B6phoQ8yd/omIiIiISE4Y9OmdzM3N8ccff8i7jI9OTVkCF2t9uFj//+UKCenZuP4sBVeeJuNyZDJuPk9FXFo2DtyIwYEbBXd60FVXRnNrfbSxN4SrvRHqmTH4ExERERHRx8OgT1QOxtqq6OJkii5OBXeGeJ2Tj7BnL3HlyUtcfpKMq09fIvV1LoLC4xEUHg8AMNBUQRs7Q7SxN0RbByPYGGpwqT8REREREVUaBn2iD6CuIoGrvRFc7Qtu+ZeXL8XdF2kIfZyMC48SERqZjOSMHBy69QKHbr0AAJjrqqGNvRHcHA3h7mgMIy1Veb4FIiIiIiKqZhj0iSqQkkSMRpZ6aGSph1Ht7JCbL8WNZym48CgJ5x8mIiwqBTGpWdh77Tn2XnsOAGhooQs3BwMopxV8UaDMTf2JiIiIiOgDMOgTVSJliRjNbQzQ3MYAEzs74nVOPq48Tcb5h0kIjkjAnZg03Iou2OkfUMK2R6fh5mCE9nWM0a6OMcz1FP8uB0RERERE9HEx6BN9ROoqErg7GsPd0RjfdquH+PQsBD9IxKnwOJy69wLpWXk4cjsWR27HAgDqmWmji5MpOtc3RSMLXW7qR0RERERE78SgTyRHJtpq6OtiiZ6NTHHw0HNYNW6L849e4syDeFx/loLw2HSEx6Zj7cmHMNZWRed6JvCob4q2DkZQV5HIu3wiIiIiIqqCGPSJqgixCGhsqYvmtkbw9XBEckYOTt+Px4l7cTj7IBEJ6dn46/Iz/HX5GdSUxXBzMEIXJ1N41DeFITf0IyIiIiKi/2HQJ6qiDDRV0KeZJfo0s0R2Xj5CHycj6F4cTtyLR3TKa5y4F48T9+IhFt1CK1tDdGtoBs8GZjDVUZN36UREREREJEcM+kQKQFVJgnb/26Bvbk8B4bHpOHE3DkfvxuJ2dBpCHich5HESZu+/AxdrfXRzLgj9VgYa8i6diIiIiIg+MgZ9IgUjEolQv5YO6tfSwYTOjniWnInA27E4cvsFrkWl4OrTl7j69CUWHroHZwsd9Ghkjh6NasFSn6GfiIiIiKgmYNAnUnBWBhoY1c4Oo9rZITY1C0fvFIT+S5HJuB2dhtvRafjxSDia1dbDp43N0b1hLZhweT8RERERUbXFoE9UjZjpqmGIqw2GuNog8VU2jt6JxcEbL3AxMgnXolJwLSoFCw7eRWs7Q3za2BxeDcygr6ki77KJiIiIiKgCMegTVVNGWqr4opU1vmhljbi0LBy6+QIHbsYgLCoFFx4l4cKjJHwfcBvt6hjDu6kFujqZQk2Zt+wjIiIiIlJ0DPpENYCpjhqGu9liuJstniVn4uDNFzhwIwZ3X6ThZHg8TobHQ1tVCd0amqF3U0u0sjWAWCySd9lERERERPQeGPSJahgrAw2M7WCPsR3s8TD+FQLCovFPWDSiU15j95Xn2H3lOSz01OHd1By9m1rCwURL3iUTEREREVE5MOgT1WAOJlqY6lkXfl3q4PKTZOy7Fo3Dt14gOuU11p96hPWnHqGRpS76uViiZ2ML6Gooy7tkIiIiIiJ6BwZ9IoJYLEIrO0O0sjPEvF4NcOJeHP65Fo3TDxJw83kqbj5PxcJD9+DlbIb+za3Qxs6QS/uJiIiIiKooBn0iKkJNWYIejczRo5E5El9lY//1GOy+/Az349Kx/3oM9l+PgaW+Ovq5WOGz5paw0FOXd8lERERERPQfDPpEVCojLVWMcLPF8LY2uBWdil2Xn+Hf6zF4/vI1Vp54gFVBD+DmYIQBLazQ1ckMKkpieZdMRERERFTjMegT0TuJRCI0stRDI0s9zOruhMA7L7D78nOEPE5CcEQigiMSYaSlgn7NrTCoRW3UNtSQd8lERERERDUWgz4RlYu6igS9m1qid1NLRCVlYveVZ9h95Rni07Px8+lH+Pn0I7g7GuGLVrXRub4plCWc5SciIiIi+pgY9InovdU21MBUz7rw9XBE0L14/BH6VDbDHxyRCBNtVQxoYYWBLWvzWn4iIiIioo+EQZ+IPpiyRAwvZzN4OZshKikTf16Owu7LBbP8a08+xPpTD9G5vimGutrA1d4QIhF37CciIiIiqiwM+kRUoWobauAbr3qY7FEHx+7G4o+LUQh5nITjd+Nw/G4c6phqYXAbG/RpZgENFf4viIiIiIioovFf2URUKVSUxLLb9D2MT8eOC0+x99pzPIh7hVkBt7EkMBz9m1thcBsbbt5HRERERFSBuEsWEVU6BxNtLPB2xsWZnfF9DydYG2ogLSsPm89Fov2yUxi54zLORSRCEAR5l0pEREREpPA4o09EH42OmjJGuNlimKsNTj+Ix/YLT3H2QQJO3IvHiXvxcDDRwhBXG/RpagFNVf7viYiIiIjoffBf0kT00YnFInSqZ4pO9UzxKOEVdl54gr+vPsfD+Ff4/j/L+oe1tYGlPpf1ExERERGVB5fuE5Fc2RtrYV6vgmX9cz51gq2RJtKz8rDlXCTaLz2NiX+G4XZ0qrzLJCIiIiJSGJzRJ6IqQVtNGcPa2mJIGxuciUjAluBInHuYiH9vxODfGzFwtTfE6HZ2aF/HmLfnIyIiIiJ6CwZ9IqpSxGIROtY1Qce6JrgdnYrNwY9x4OYLXHiUhAuPklDXVBuj2tmhZ2NzqChxURIRERER0Zv4r2QiqrKcLXSxamBTnJ3eESPdbKGpIsH9uHRM3XMD7ktOYuOZR0h9nSvvMomIiIiIqhQGfSKq8iz01DGrhxMuzOiMb7zqwURbFXFp2fjxSDja/ngSCw/eRUzKa3mXSURERERUJTDoE5HC0FVXxtgO9jj3TScs/awR6phq4VV2Hjafi0S7Jacwedd1RMSly7tMIiIiIiK54jX6RKRwVJTE6NfcCp+5WOL0gwT8evYxLjxKwj9h0Qi4Hg1PJzP4dHKAs4WuvEslIiIiIvroGPSJSGGJRP+/cd+t56lYf+ohAu/Eyn51qGsMn44OaG5jIO9SiYiIiIg+GgZ9IqoWGlrqYuNXLngQl44Npx7i3xsxOH0/AafvJ6C1nQF8OjqirYMhb81HRERERNUer9Enomqljqk2Vg1sipNTOmBgCysoS0S4+DgZX24JRe8NF3DibhwEQZB3mURERERElYZBn4iqJRsjTfzYtxHOTOuIoa42UFUS4/qzFIzceQXdVgfj4M0Y5EsZ+ImIiIio+mHQJ6JqzVxPHXN7NsC5bzphTHt7aKpIEB6bDh//MHRZeQb7rj1n4CciIiKiaoVBn4hqBGNtVXzbrR7Of9sJkzwcoauujMcJGfDbfQNdVp7B/uvRDPxEREREVC0w6BNRjaKnoYJJHnVw/ttOmO5VF3oaBYHf96/r8Fp1FoduvoCUgZ+IiIiIFBiDPhHVSFqqShjXwQHB0ztiatc60FFTQkT8K4z3v4ZP1gQj8HYsN+0jIiIiIoXEoE9ENZq2mjJ8Ojni3P+W9GurKiE8Nh1jfr+KHmvP4Th36SciIiIiBcOgT0QEQEdNGZM86uDcN50woZMDNFUkuBOThlE7r6DX+vM4FR7PwE9ERERECoFBn4joP3Q1lDGla10Ef9MJYzvYQ11ZgpvPUzFs+2X023QJ4SkiBn4iIiIiqtIY9ImISmCgqYJvvOoh+JuOGN3ODmrKYtx4noqf70nw5dYruPr0pbxLJCIiIiIqEYM+EdFbGGmpYuYn9XF2ekcMaVMbSiIBl568RN+fL2DUzit4EJcu7xKJiIiIiIpQkncBRESKwERbDbM+qQfb7Me4DWvsC4vG8btxCLoXhz7NLDHJwxGW+hryLpOIiIiIiDP6RETloa8KLO7dAMcmt4NXAzNIBeDvq8/RadkZzD9wF0mvsuVdIhERERHVcAz6RETvwcFEGxu/csE/41zRxs4QOflSbD0fifZLT2P1iQi8ys6Td4lEREREVEMx6BMRfYCmtfXhP6oVdg5viQbmOniVnYeVJx6g/ZJT2HY+Etl5+fIukYiIiIhqGAZ9IqIPJBKJ0K6OMQ74uGHd501hY6iBpIwczDtwF52Xn8G+a88hlfKWfERERET0cTDoExFVELFYhB6NzHHcrz0W9XaGibYqnr98Db/dN9Bj7TlceJgo7xKJiIiIqAZg0CciqmDKEjG+aGWNM9M6YrpXXWirKuHuizR8vjkUw7dfRgRvyUdERERElYhBn4iokqirSDCugwNOT+uAIW2soSQW4WR4PDxXncXMf24hIZ079BMRERFRxWPQJyKqZIZaqpjXyxlHJ7dDVydTSAXAPzQKHZaewrqTEXidww37iIiIiKjiMOgTEX0k9sZa2DS4OXaNbo1GlrrIyMnHsmMP0Gn5aey9yg37iIiIiKhiMOgTEX1krewMETCuLVYPbAILPXW8SM3ClD3csI+IiIiIKgaDPhGRHIjFIvRqYoGgKe3xbbd63LCPiIiIiCoMgz4RkRypKUswpr09zkzviKGuNrIN+7xWB2Puv3eQkpkj7xKJiIiISMEw6BMRVQEGmiqY27MBjk1uhy5OpsiXCth+4Qk6LDuN30KeIC9fKu8SiYiIiEhBMOgTEVUhdsZa+HVwc/w+ohXqmGohJTMX3++/g+5reP0+EREREZUNgz4RURXk5miEwxPdsaBXA+hpKON+XDo+3xyKr3+7gqikTHmXR0RERERVGIM+EVEVpSQR46s2Njg9tQOGutpAIhbh6J04eKw4g58Cw/EqO0/eJRIRERFRFcSgT0RUxelpFFy/f8TXHe6ORsjJl+Ln04/Qcdlp/H31OaRSQd4lEhEREVEVwqBPRKQg6phqY+fwlvh1cHNYG2ogIT0bU/fcQO8N53Et6qW8yyMiIiKiKoJBn4hIgYhEInRxMsWxye0wo1s9aKkq4cbzVPTZcAF+u64jPj1L3iUSERERkZwx6BMRKSBVJQm+bm+Pk1Pbo39zS4hEwL6waHRedgZbzkXydnxERERENRiDPhGRAjPRVsOSzxojYFxbNLbURXp2HhYcvIsea88h9HGSvMsjIiIiIjlg0CciqgYaW+nhn3FtsbhPQ+hrKCM8Nh0DNl3EpL/CEJ/G5fxERERENQmDPhFRNSEWizCoZW2cnNIBX7SqDZEICLgeg07Lz2Bz8GPkcjk/ERERUY3AoE9EVM3oa6pgUe+G2D++LRpb6eFVdh4WHrqH7muCEfKIy/mJiIiIqju5B/3169fDxsYGampqaNWqFS5duvTW/nv27EG9evWgpqaGhg0b4vDhw0WeFwQBs2fPRq1ataCurg4PDw9EREQU6fPgwQP06tULRkZG0NHRgZubG06dOlXh742ISJ4aWerhn7Gu+KlvQxhoquBB3CsM+vUiJvwZhthULucnIiIiqq7kGvR37doFPz8/zJkzB9euXUPjxo3h6emJ+Pj4EvtfuHABgwYNwogRIxAWFgZvb294e3vj9u3bsj5LlizBmjVrsHHjRoSGhkJTUxOenp7Iyvr/f9T26NEDeXl5OHnyJK5evYrGjRujR48eiI2NrfT3TET0MYnFIgxoURsnp7THV62tIRIBB27EoPPy09h09hGX8xMRERFVQ3IN+itWrMCoUaMwbNgwODk5YePGjdDQ0MDWrVtL7L969Wp4eXlh2rRpqF+/PhYsWIBmzZph3bp1AApm81etWoVZs2ahV69eaNSoEXbu3ImYmBgEBAQAABITExEREYFvv/0WjRo1gqOjI3788UdkZmYW+cKAiKg60dNQwQJvZxzwcUPT2nrIyMnHD4fD0X1NMC4/SZZ3eURERERUgZTk9cI5OTm4evUqZsyYIWsTi8Xw8PBASEhIiceEhITAz8+vSJunp6csxEdGRiI2NhYeHh6y53V1ddGqVSuEhIRg4MCBMDQ0RN26dbFz5040a9YMqqqq+OWXX2BiYgIXF5dS683OzkZ2drbscVpaGgAgNzcXubm55X7/H0thbVW5RuI4KYrqME51TTTw14gW2Hc9BkuOPsCDuFfotzEE/VwsMK2rI/Q1VORdYoWoDmNVE3CcFAPHSTFwnBQHx0oxVNVxKms9cgv6iYmJyM/Ph6mpaZF2U1NThIeHl3hMbGxsif0Ll9wX/v62PiKRCCdOnIC3tze0tbUhFothYmKCwMBA6Ovrl1rv4sWLMW/evGLtx44dg4aGxjverfwdP35c3iVQGXCcFEN1GCcNANOcgANRYoTEi7HnajQO33iOXtZStDQWIBLJu8KKUR3GqibgOCkGjpNi4DgpDo6VYqhq45SZmVmmfnIL+vIiCALGjx8PExMTBAcHQ11dHZs3b8ann36Ky5cvo1atWiUeN2PGjCKrCdLS0mBlZYWuXbtCR0fnY5Vfbrm5uTh+/Di6dOkCZWVleZdDpeA4KYbqOE79AFx9+hKz/72HB/Gv4P9Igoh8fcz/tD4cTLTkXd57q45jVR1xnBQDx0kxcJwUB8dKMVTVcSpcWf4ucgv6RkZGkEgkiIuLK9IeFxcHMzOzEo8xMzN7a//C3+Pi4ooE9ri4ODRp0gQAcPLkSRw8eBAvX76UBfQNGzbg+PHj2LFjB7799tsSX1tVVRWqqqrF2pWVlavUwJdGUeqs6ThOiqG6jVNrBxMc8jXClnORWHXiAS4/eYmeG0Iwup0dfDo6Ql1FIu8S31t1G6vqiuOkGDhOioHjpDg4Voqhqo1TWWuR22Z8KioqcHFxQVBQkKxNKpUiKCgIbdq0KfGYNm3aFOkPFCylKOxva2sLMzOzIn3S0tIQGhoq61O41EEsLvrWxWIxpFLuPk1ENZOyRIwx7e1xfHJ7dK5ngtx8AetPPULXVWdw6n7Jd0IhIiIioqpJrrvu+/n54ddff8WOHTtw7949jB07FhkZGRg2bBgAYPDgwUU26/P19UVgYCCWL1+O8PBwzJ07F1euXIGPjw+AguvvJ02ahIULF+Lff//FrVu3MHjwYJibm8Pb2xtAwZcF+vr6GDJkCG7cuIEHDx5g2rRpiIyMRPfu3T/6Z0BEVJVYGWhg85Dm+OUrF9TSVcOz5NcYtu0yxv1xFbGpWe8+ARERERHJnVyv0R8wYAASEhIwe/ZsxMbGokmTJggMDJRtphcVFVVk5t3V1RX+/v6YNWsWZs6cCUdHRwQEBMDZ2VnWZ/r06cjIyMDo0aORkpICNzc3BAYGQk1NDUDBJQOBgYH47rvv0KlTJ+Tm5qJBgwbYv38/Gjdu/HE/ACKiKkgkEsGzgRncHIyw6sQDbD3/BIdvxeLsg0RM6VoHg9vYQCKuJrv1EREREVVDct+Mz8fHRzYj/6bTp08Xa+vXrx/69etX6vlEIhHmz5+P+fPnl9qnefPmOHr0aLlrJSKqSTRVlfBddyf0bmqJ7wJuISwqBfMO3EVAWDQW92kEJ/OquxEpERERUU0m16X7RERU9TmZ62DvGFcs9HaGtpoSbjxPxafrzuGnwHBk5ebLuzwiIiIiegODPhERvZNYLMKXra1xwq89ujmbIV8q4OfTj+C56izOP0yUd3lERERE9B8M+kREVGamOmr4+UsXbPrKBWY6anialIkvNodi6p4beJmRI+/yiIiIiAgM+kRE9B66NjDDcb92GNzGGiIR8PfV5/BYcQb7r0dDEAR5l0dERERUozHoExHRe9FWU8b8Xs74e0wb1DHVQlJGDnz/uo5h2y/j+ctMeZdHREREVGMx6BMR0QdxsTbAwQnu8OtSByoSMU7fT0CXFWexOfgx8qWc3SciIiL62Bj0iYjog6koiTGxsyMO+7qjpY0BXufmY+Ghe+i94TzuxKTKuzwiIiKiGoVBn4iIKoyDiRb+Gt0ai/s0hLaaEm4+T0Wvdeex7Oh9ZOfxVnxEREREHwODPhERVSixWIRBLWsj6H+34suTClh36iG6rzmHa1Ev5V0eERERUbXHoE9ERJXC5H+34tv4ZTMYaaniYfwr9P35AuYfuIvMnDx5l0dERERUbTHoExFRpfJyroUTfu3Qp5kFBAHYej4SXquCceFhorxLIyIiIqqWGPSJiKjS6WmoYEX/Jtg2rAXMddUQlZyJzzeHYsa+m0jLypV3eURERETVCoM+ERF9NB3rmuDo5Hb4snVtAMCfl56h64qzCLoXJ+fKiIiIiKoPBn0iIvqotNWUsdC7If4a3Ro2hhqITcvCiB1XMOmvMCRn5Mi7PCIiIiKFx6BPRERy0drOEEd822F0OzuIRUDA9Rh0WXEGB2/GQBAEeZdHREREpLAY9ImISG7UVSSY+Ul97BvXFnVMtZCUkQMf/zCM+f0qEtKz5V0eERERkUJi0CciIrlrYqWHgxPc4dvZEUpiEY7eiUPXlQWz+0RERERUPgz6RERUJagoiTG5Sx3s92mL+rV08DIzFz7+YRj3x1UkveLsPhEREVFZMegTEVGV0sBcF/vHt5XN7h++FYuuK8/i8K0X8i6NiIiISCEw6BMRUZVTOLsfML4t6plpIykjB+P+uAYf/2vcmZ+IiIjoHRj0iYioynK20MW/Pm6Y0MkBErEIB2++QNeVZxB4O1bepRERERFVWQz6RERUpakoiTGla138M84VdUy1kPgqB2N+v4qJf4bhJWf3iYiIiIph0CciIoXQyFIPBya4YVwHe4hFwL83YtBl5Vkcu8PZfSIiIqL/YtAnIiKFoaokwXSvetg3ri3sjTWR+Cobo3+7Cr9d15GamSvv8oiIiIiqBAZ9IiJSOE2s9HBooju+bm8HsQjYFxaNLivPIOhenLxLIyIiIpI7Bn0iIlJIasoSzOhWH3+PdYWdsSbi07MxYscVTNl9A2mvObtPRERENReDPhERKbRmtfVxeKI7RrnbQiQC9l57jk/WXcC9lyJ5l0ZEREQkFwz6RESk8NSUJfiuuxP2fN0GtkaaiEvLxsZwCWb/excZ2XnyLo+IiIjoo2LQJyKiaqO5jQEOT3TH4Na1AQB/Xn6OT9YE4+rTZDlXRkRERPTxMOgTEVG1oq4iwffd62G8Uz5q6arhaVIm+m0MwU+B4cjOy5d3eURERESVjkGfiIiqpTq6Ag75tEGfZhaQCsDPpx+h17rzuPciTd6lEREREVUqBn0iIqq2tNWUsaJ/E2z8shkMNFUQHpuOXuvOY+OZR8iXCvIuj4iIiKhSMOgTEVG15+VcC0cntYNHfRPk5Evx45FwDPglBE+TMuRdGhEREVGFY9AnIqIawVhbFb8Obo4lnzWClqoSrjx9iW6rg+EfGgVB4Ow+ERERVR8M+kREVGOIRCL0b26FI77uaGVrgMycfMz85xaGb7+M+LQseZdHREREVCEY9ImIqMaxMtDAn6NaY1b3+lBREuPU/QR0XXUWB2/GyLs0IiIiog/GoE9ERDWSWCzCSHc7HJrgBmcLHaRk5sLHPwwT/wxDSmaOvMsjIiIiem8M+kREVKM5mmrjn3FtMbGTAyRiEf69EQPPVWdx9kGCvEsjIiIiei8M+kREVOMpS8Tw61oXf49pAzsjTcSlZWPw1kuYvf82Xufky7s8IiIionJh0CciIvqfprX1cWiiO4a62gAAdoY8RY+1wbgdnSrfwoiIiIjKgUGfiIjoP9RVJJjbswF2Dm8JE21VPErIgPf689hw+iHypbwNHxEREVV9DPpEREQlaFfHGEcntYNXAzPkSQUsCbyPQZsu4llyprxLIyIiInorBn0iIqJS6Guq4Ocvm2HpZ42gqSLBpSfJ+GR1MPZdew5B4Ow+ERERVU0M+kRERG8hEonQr7kVjvi2g4u1PtKz8+C3+wZ8eBs+IiIiqqIY9ImIiMqgtqEGdo1ujSld6kBJLMKhmy/gtSoY5x8myrs0IiIioiIY9ImIiMpISSLGhM6O2DvWFXZGmohNy8IXm0Ox6NBdZOfxNnxERERUNTDoExERlVNjKz0cnOiGL1rVBgD8GhyJXuvOIzw2Tc6VERERETHoExERvRcNFSUs6t0Qmwc3h6GmCsJj09Fz3XlsORcJKW/DR0RERHLEoE9ERPQBPJxMETipHTrVM0FOnhQLDt7FV1tD8SL1tbxLIyIiohqKQZ+IiOgDGWurYsuQ5ljo7Qw1ZTHOP0yC16pgHLr5Qt6lERERUQ3EoE9ERFQBRCIRvmxtjUMT3dHQQhepr3Mx3v8a/HZfx6vsPHmXR0RERDUIgz4REVEFsjfWwr5xrvDp6ACxCNh3LRrd1wTj+rMUeZdGRERENQSDPhERUQVTlogx1bMu/hrdBhZ66nialInPfr6A9aceIp8b9REREVElY9AnIiKqJC1tDXDY1x09GtVCnlTA0qP38fmvFxGTwo36iIiIqPIw6BMREVUiXXVlrB3UFMv6NYaGigShkcnwWnUWh29xoz4iIiKqHAz6RERElUwkEuEzF0scnuiOxpa6SMvKw7g/ruGbv28igxv1ERERUQVj0CciIvpIbIw08fdYV4zrYA+RCNh15Rl6rD2Hm89T5F0aERERVSMM+kRERB+RskSM6V714D+yNWrpqiEyMQN9NlzAxjOPIOVGfURERFQBGPSJiIjkoI29IY74uqObsxnypAJ+PBKOL7eEIjY1S96lERERkYJj0CciIpITPQ0VbPiiGX7q2xDqyhJceJQEr9VnEXg7Vt6lERERkQJj0CciIpIjkUiEAS1q4+BENzhb6CAlMxdjfr+KGftuITOHG/URERFR+THoExERVQH2xlrYN7Ytvm5vB5EI+PNSFHqsPYfb0anyLo2IiIgUDIM+ERFRFaGiJMaMbvXx+4hWMNVRxeOEDPTecB6/nn3MjfqIiIiozBj0iYiIqpi2DkYI9G2Hrk6myM0XsOjwPQzZdgnxadyoj4iIiN6NQZ+IiKgK0tdUwS9fuWBRb2eoKYsRHJEIr9XBOHE3Tt6lERERURXHoE9ERFRFiUQifNHKGgcnuMGplg6SM3IwcucVfB9wG1m5+fIuj4iIiKooBn0iIqIqzsFEG/+Md8VIN1sAwG8Xn6LXuvN4EJcu58qIiIioKmLQJyIiUgCqShLM6uGEHcNbwkhLBffj0tFz3Tn4h0ZBELhRHxEREf0/Bn0iIiIF0r6OMY74toO7oxGycqWY+c8tjPe/htTMXHmXRkRERFXEBwX9rCzu/ktERPSxGWurYsewlpj5ST0oiUU4fCsWn6wJxpUnyfIujYiIiKqAcgd9qVSKBQsWwMLCAlpaWnj8+DEA4Pvvv8eWLVsqvEAiIiIqTiwWYXQ7e+wd6wprQw1Ep7zGgE0XsTYoAvlSLuUnIiKqycod9BcuXIjt27djyZIlUFFRkbU7Oztj8+bNFVocERERvV1jKz0cnOAG7ybmyJcKWH78AT7/9SJepL6Wd2lEREQkJ+UO+jt37sSmTZvwxRdfQCKRyNobN26M8PDwCi2OiIiI3k1bTRmrBjbFiv6NoaEiQWhkMrqtDsbxu3HyLo2IiIjkoNxBPzo6Gg4ODsXapVIpcnO5ERAREZG89GlmiUMT3eFsoYOUzFyM2nkFc/bfRlZuvrxLIyIioo+o3EHfyckJwcHBxdr//vtvNG3atEKKIiIiovdja6SJfWPbYqSbLQBgR8hTeK8/j4fx6XKujIiIiD4WpfIeMHv2bAwZMgTR0dGQSqXYt28f7t+/j507d+LgwYOVUSMRERGVg4qSGLN6OKGtoxGm7r6B8Nh09Fh7DnM/bYABLawgEonkXSIRERFVonLP6Pfq1QsHDhzAiRMnoKmpidmzZ+PevXs4cOAAunTpUhk1EhER0XvoWNcERya5w93RCFm5Uny77xZ8/gxD6mteakdERFSdlXtGHwDc3d1x/Pjxiq6FiIiIKpiJthp2DGuJTcGPsezofRy6+QLXo1KwZlATuFgbyLs8IiIiqgTlntG3s7NDUlJSsfaUlBTY2dmVu4D169fDxsYGampqaNWqFS5duvTW/nv27EG9evWgpqaGhg0b4vDhw0WeFwQBs2fPRq1ataCurg4PDw9EREQUO8+hQ4fQqlUrqKurQ19fH97e3uWunYiISBGIxSKMaW+Pv8e6oraBBqJTXqP/Lxex7mQE8qWCvMsjIiKiClbuoP/kyRPk5xffvTc7OxvR0dHlOteuXbvg5+eHOXPm4Nq1a2jcuDE8PT0RHx9fYv8LFy5g0KBBGDFiBMLCwuDt7Q1vb2/cvn1b1mfJkiVYs2YNNm7ciNDQUGhqasLT0xNZWVmyPnv37sVXX32FYcOG4caNGzh//jw+//zzctVORESkaJpY6eHQRDf0bGyOfKmAZcce4MvNoYhNzXr3wURERKQwyrx0/99//5X999GjR6Grqyt7nJ+fj6CgINjY2JTrxVesWIFRo0Zh2LBhAICNGzfi0KFD2Lp1K7799tti/VevXg0vLy9MmzYNALBgwQIcP34c69atw8aNGyEIAlatWoVZs2ahV69eAICdO3fC1NQUAQEBGDhwIPLy8uDr64ulS5dixIgRsnM7OTm9tdbs7GxkZ2fLHqelpQEAcnNzq/RtBQtrq8o1EsdJUXCcFAfHqnRqEmBZ3wZoa6+PeQfDEfI4Cd1Wn8WPfZzRqa7xR62F46QYOE6KgeOkODhWiqGqjlNZ6xEJglCmNXticcHkv0gkwpuHKCsrw8bGBsuXL0ePHj3K9MI5OTnQ0NDA33//XWTZ/JAhQ5CSkoL9+/cXO6Z27drw8/PDpEmTZG1z5sxBQEAAbty4gcePH8Pe3h5hYWFo0qSJrE/79u3RpEkTrF69GpcuXUKrVq2wdetWrFmzBrGxsWjSpAmWLl0KZ2fnUuudO3cu5s2bV6zd398fGhoaZXrPREREVUnca2BnhATPMwp24W9nJkVPaymUy73ej4iIiD6GzMxMfP7550hNTYWOjk6p/co8oy+VSgEAtra2uHz5MoyMjD6owMTEROTn58PU1LRIu6mpKcLDw0s8JjY2tsT+sbGxsucL20rr8/jxYwAFwX3FihWyLyg6dOiABw8ewMCg5I2JZsyYAT8/P9njtLQ0WFlZoWvXrm/9gOUtNzcXx48fR5cuXaCsrCzvcqgUHCfFwHFSHByrsvs8T4rlxyOw7cJTnI0VIwG6WNm/EeyNNSv9tTlOioHjpBg4ToqDY6UYquo4Fa4sf5dy77ofGRlZ7mKqksIvLL777jv07dsXALBt2zZYWlpiz549+Prrr0s8TlVVFaqqqsXalZWVq9TAl0ZR6qzpOE6KgeOkODhW76asDMzp6Yx2dUwwZc8N3ItNR++fL2Jezwbo19wSIpHoI9TAcVIEHCfFwHFSHBwrxVDVxqmstbzX7fUyMjJw5swZREVFIScnp8hzEydOLNM5jIyMIJFIEBcXV6Q9Li4OZmZmJR5jZmb21v6Fv8fFxaFWrVpF+hQu5S9s/+81+aqqqrCzs0NUVFSZaiciIqpuOtYzQaCvOybvvo7zD5Mwfe9NBD9MxKLeztBRqzr/wCEiIqJ3K/dVeGFhYXBwcMCgQYPg4+ODhQsXYtKkSZg5cyZWrVpV5vOoqKjAxcUFQUFBsjapVIqgoCC0adOmxGPatGlTpD8AHD9+XNbf1tYWZmZmRfqkpaUhNDRU1sfFxQWqqqq4f/++rE9ubi6ePHkCa2vrMtdPRERU3ZjoqOG34a0w3asuJGIRDtyIQfc1wbj+LEXepREREVE5lDvoT548GZ9++ilevnwJdXV1XLx4EU+fPoWLiwuWLVtWrnP5+fnh119/xY4dO3Dv3j2MHTsWGRkZsl34Bw8ejBkzZsj6+/r6IjAwEMuXL0d4eDjmzp2LK1euwMfHB0DBRoGTJk3CwoUL8e+//+LWrVsYPHgwzM3NZRv+6ejoYMyYMZgzZw6OHTuG+/fvY+zYsQCAfv36lffjICIiqlbEYhHGdXDAnjFtYKmvjmfJr/HZzxfwy5lHkErLtH8vERERyVm5l+5fv34dv/zyC8RiMSQSCbKzs2FnZ4clS5ZgyJAh6NOnT5nPNWDAACQkJGD27Nmy3e8DAwNlm+lFRUXJdvsHAFdXV/j7+2PWrFmYOXMmHB0dERAQUGS3/OnTpyMjIwOjR49GSkoK3NzcEBgYCDU1NVmfpUuXQklJCV999RVev36NVq1a4eTJk9DX1y/vx0FERFQtNautj0MT3TFz3y0cuvUCi4+E4/yjJCzv1xjG2sX3rCEiIqKqo9xBX1lZWRa+TUxMEBUVhfr160NXVxfPnj0rdwE+Pj6yGfk3nT59ulhbv3793jrzLhKJMH/+fMyfP7/UPsrKyli2bFm5VyAQERHVJLrqylj3eVO4XTbCvAN3cPZBArqtDsbKAY3h7mgs7/KIiIioFOVeut+0aVNcvnwZQMH96WfPno0//vgDkyZNeut96ImIiEjxiEQiDGpZGwd83FDXVBuJr7Lx1ZZL+PFIOHLzpfIuj4iIiEpQ7qD/ww8/yHauX7RoEfT19TF27FgkJCTgl19+qfACiYiISP4cTbWx36ctvmhVGwCw8cwj9NsYgmfJmXKujIiIiN5U7qX7zZs3l/23iYkJAgMDK7QgIiIiqprUlCVY1Lsh3ByM8M3em7j+LAWfrA7G4r4N0aORubzLIyIiov8p94x+aa5du4YePXpU1OmIiIioiurWsBYO+7rDxVof6dl58PEPw4x9N/E6J1/epRERERHKGfSPHj2KqVOnYubMmXj8+DEAIDw8HN7e3mjRogWkUl6rR0REVBNY6mtg1+jW8OnoAJEI+PPSM/Rcdw7hsWnyLo2IiKjGK3PQ37JlC7p164bt27fjp59+QuvWrfH777+jTZs2MDMzw+3bt3H48OHKrJWIiIiqECWJGFM96+KPEa1goq2KiPhX6LXuPH67+BSCIMi7PCIiohqrzEF/9erV+Omnn5CYmIjdu3cjMTERGzZswK1bt7Bx40bUr1+/MuskIiKiKsrVwQhHfN3Rsa4xsvOk+D7gNsb+fg2pmbnyLo2IiKhGKnPQf/Tokez+9X369IGSkhKWLl0KS0vLSiuOiIiIFIOhliq2DGmBWd3rQ1kiQuCdWHyyJhhXniTLuzQiIqIap8xB//Xr19DQ0ABQcE9dVVVV2W32iIiIiMRiEUa622Hf2LawNtRAdMprDNh0EWuDIpAv5VJ+IiKij6Vct9fbvHkztLS0AAB5eXnYvn07jIyMivSZOHFixVVHRERECqehpS4OTnDD9wG3EXA9BsuPP8CFR0lYNbAJTHXU5F0eERFRtVfmoF+7dm38+uuvssdmZmb47bffivQRiUQM+kRERARtNWWsHNAEbo7GmL3/NkIeJ6Hb6mAs69cIneqZyrs8IiKiaq3MQf/JkyeVWAYRERFVNyKRCJ+5WKJpbT1M8A/D3RdpGL79Cka42WK6V93y3eOXiIiIyox/xxIREVGlsjfWwj/jXTHU1QYAsOVcJPr+fAFPkjLkWxgREVE1xaBPRERElU5VSYK5PRtg8+Dm0NdQxu3oNHhvuIjLCSJ5l0ZERFTtMOgTERHRR+PhZIojvu3QytYAGTn5+P2hBNP33kJGdp68SyMiIqo2GPSJiIjoozLTVYP/qNaY2MkeIgj45/oL9Fh7DrejU+VdGhERUbXAoE9EREQfnUQswoSO9vBpkA8zHVVEJmagz4YL2HouEoIgyLs8IiIihVbuoJ+Wllbir/T0dOTk5FRGjURERFRNOegA/45vgy5OpsjJl2L+wbsYueMKkjP4bwoiIqL3Ve6gr6enB319/WK/9PT0oK6uDmtra8yZMwdSqbQy6iUiIqJqRl9DBZu+csH8Xg2goiRGUHg8uq0+i5BHSfIujYiISCGVO+hv374d5ubmmDlzJgICAhAQEICZM2fCwsICP//8M0aPHo01a9bgxx9/rIx6iYiIqBoSiUQY3MYGAePaws5YE3Fp2fh880WsOHYfefmcPCAiIioPpfIesGPHDixfvhz9+/eXtX366ado2LAhfvnlFwQFBaF27dpYtGgRZs6cWaHFEhERUfXmZK6DgxPcMPffO9h95TnWnHyIkMdJWD2wKcz11OVdHhERkUIo94z+hQsX0LRp02LtTZs2RUhICADAzc0NUVFRH14dERER1TgaKkpY8lljrB7YBFqqSrj85CW6rQ7G0Tux8i6NiIhIIZQ76FtZWWHLli3F2rds2QIrKysAQFJSEvT19T+8OiIiIqqxejWxwKGJbmhsqYvU17n4+rer+D7gNrJy8+VdGhERUZVW7qX7y5YtQ79+/XDkyBG0aNECAHDlyhWEh4fj77//BgBcvnwZAwYMqNhKiYiIqMaxNtTEnjGuWHbsPjadfYzfLj7F5SfJWPd5UziYaMu7PCIioiqp3DP6PXv2RHh4OLp164bk5GQkJyejW7duCA8PR48ePQAAY8eOxYoVKyq8WCIiIqp5VJTEmPlJfWwf1gKGmioIj03Hp2vPY9flKAiCIO/yiIiIqpxyz+gDgK2tLXfVJyIioo+qQ10THPF1h9/uGzj3MBHf7L2Fcw+TsKi3M3TUlOVdHhERUZXxXkE/JSUFly5dQnx8PKTSore8GTx4cIUURkRERPQmEx017BzeEhvPPsLyYw9w4EYMrj97ibWDmqGJlZ68yyMiIqoSyh30Dxw4gC+++AKvXr2Cjo4ORCKR7DmRSMSgT0RERJVKLBZhXAcHtLYzxMQ/w/As+TU++/kCpnnWxSh3O4jFonefhIiIqBor9zX6U6ZMwfDhw/Hq1SukpKTg5cuXsl/JycmVUSMRERFRMc1q6+PQRHd0b1gLeVIBi4+EY+j2y0hIz5Z3aURERHJV7qAfHR2NiRMnQkNDozLqISIiIiozXXVlrPu8KRb3aQhVJTHOPkhAt9XBCI5IkHdpREREclPuoO/p6YkrV65URi1ERERE5SYSiTCoZW0cmOCGOqZaSHyVja+2XMKPR8KRmy999wmIiIiqmXJfo9+9e3dMmzYNd+/eRcOGDaGsXHSX2549e1ZYcURERERlVcdUG//6uGHBwbv4IzQKG888wsXHSVg7qCmsDLgSkYiIao5yB/1Ro0YBAObPn1/sOZFIhPz8/A+vioiIiOg9qClLsKh3Q7g5GOGbvTdx/VkKPlkdjMV9G6JHI3N5l0dERPRRlHvpvlQqLfUXQz4RERFVBd0a1sJhX3e4WOsjPTsPPv5hmLHvJl7n8N8qRERU/ZU76BMREREpAkt9Dewa3Ro+HR0gEgF/XnqGnuvOITw2Td6lERERVaoyLd1fs2YNRo8eDTU1NaxZs+atfSdOnFghhRERERF9KCWJGFM968LV3hCTdl1HRPwr9Fp3HrN6OOHLVrUhEonkXSIREVGFK1PQX7lyJb744guoqalh5cqVpfYTiUQM+kRERFTluDoY4YivO6bsuYHT9xPwfcBtnI9IxE99G0FXQ/ndJyAiIlIgZQr6kZGRJf43ERERkaIw1FLF1iEtsPV8JH4KDEfgnVjcik7F6oFN0NzGQN7lERERVRheo09EREQ1hlgswkh3O+wd6wprQw1Ep7zGgE0XsTYoAvlSQd7lERERVYhy314vPz8f27dvR1BQEOLj4yGVSos8f/LkyQorjoiIiKgyNLLUw8EJbvg+4DYCrsdg+fEHuPAoCasGNoGpjpq8yyMiIvog5Q76vr6+2L59O7p37w5nZ2duYkNEREQKSVtNGSsHNIGbozFm77+NkMdJ6LY6GMv6NUKneqbyLo+IiOi9lTvo//XXX9i9ezc++eSTyqiHiIiI6KMRiUT4zMUSTWvrYYJ/GO6+SMPw7Vcwws0W073qQlVJIu8SiYiIyq3c1+irqKjAwcGhMmohIiIikgt7Yy38M94VQ11tAABbzkWi788XEJmYId/CiIiI3kO5g/6UKVOwevVqCAI3rCEiIqLqQ1VJgrk9G+DXwc2hp6GM29Fp6LEmGP+EPZd3aUREROVS7qX7586dw6lTp3DkyBE0aNAAyspF7z27b9++CiuOiIiI6GPr4mSKI77u8P3rOi5FJmPyrhsIjkjEgl7O0FQt9z+diIiIPrpy/22lp6eH3r17V0YtRERERFVCLV11/DmqNdadfIjVQQ+w71o0wqJSsHZQUzhb6Mq7PCIiorcqV9DPy8tDx44d0bVrV5iZmVVWTURERERyJxGL4OvhiNZ2Bpi06zoiEzPQZ8MFfNutHoa1teGdh4iIqMoq1zX6SkpKGDNmDLKzsyurHiIiIqIqpZWdIQ5PdEcXJ1Pk5Esx/+BdjNxxBckZOfIujYiIqETl3oyvZcuWCAsLq4xaiIiIiKokfU0VbPrKBfN7NYCKkhhB4fHotvosQh4lybs0IiKiYsp9jf64ceMwZcoUPH/+HC4uLtDU1CzyfKNGjSqsOCIiIqKqQiQSYXAbGzS3NoDPn9fwOCEDn2++iAkdHTCxsyOUJOWePyEiIqoU5Q76AwcOBABMnDhR1iYSiSAIAkQiEfLz8yuuOiIiIqIqxslcBwcnuGHO/jvYc/U51px8iJDHSVg9sCnM9dTlXR4REVH5g35kZGRl1EFERESkMDRUlLC0X2O4ORrhu39u4/KTl+i2OhhLPmsEzwbcsJiIiOSr3EHf2tq6MuogIiIiUji9mligiZUeJvwZhpvPU/H1b1fxVWtrfNe9PtSUJfIuj4iIaqhyB/1Cd+/eRVRUFHJyiu4427Nnzw8uioiIiEhRWBtq4u8xrlh27D42nX2M3y4+xeUnyVj3eVM4mGjLuzwiIqqByh30Hz9+jN69e+PWrVuya/MByO4ly2v0iYiIqKZRURJj5if14WpviCm7byA8Nh091p7D7B4NMKillezfSURERB9DubeH9fX1ha2tLeLj46GhoYE7d+7g7NmzaN68OU6fPl0JJRIREREphg51TXDE1x1uDkbIypVi5j+38PVvV/EyI+fdBxMREVWQcgf9kJAQzJ8/H0ZGRhCLxRCLxXBzc8PixYuL7MRPREREVBOZ6Khh5/CW+O6T+lCWiHDsbhy8Vp/FuYhEeZdGREQ1RLmDfn5+PrS1C643MzIyQkxMDICCTfru379fsdURERERKSCxWIRR7ezwz7i2sDfWRFxaNr7cEoofDt9Ddh4vcyQiospV7qDv7OyMGzduAABatWqFJUuW4Pz585g/fz7s7OwqvEAiIiIiReVsoYuDE9zxeavaAIBNZx+jz4YLeBj/Ss6VERFRdVbuoD9r1ixIpVIAwPz58xEZGQl3d3ccPnwYa9asqfACiYiIiBSZuooEP/RuiE1fuUBfQxl3YtLQY20w/gh9KtvUmIiIqCKVe9d9T09P2X87ODggPDwcycnJ0NfX546yRERERKXo2sAMja30MGX3DZx7mIjv/rmN0/cT8FPfRjDQVJF3eUREVI2Ue0a/0MOHD3H06FG8fv0aBgYGFVkTERERUbVk+sZGfcfvxsFrFTfqIyKiilXuoJ+UlITOnTujTp06+OSTT/DixQsAwIgRIzBlypQKL5CIiIioOincqC9gfMFGffHpBRv1LTp0lxv1ERFRhSh30J88eTKUlZURFRUFDQ0NWfuAAQMQGBhYocURERERVVcNzAs26vuydcFGfb8GR6L3+gt4GJ8u58qIiEjRlTvoHzt2DD/99BMsLS2LtDs6OuLp06cVVhgRERFRdaeuIsFC74b4dXBz6Gso4+6LNPRYew6/X+RGfURE9P7KHfQzMjKKzOQXSk5OhqqqaoUURURERFSTdHEyxdFJ7eDuaISsXClmBdzG6N+uIjkjR96lERGRAip30Hd3d8fOnTtlj0UiEaRSKZYsWYKOHTtWaHFERERENYWJjhp2DGuJWd3rQ0UixvG7cfBcdRbBEQnyLo2IiBRMuW+vt2TJEnTu3BlXrlxBTk4Opk+fjjt37iA5ORnnz5+vjBqJiIiIagSxWISR7nZoY28I37+u42H8K3y15RJGutlimlddqCpJ5F0iEREpgHLP6Ds7O+PBgwdwc3NDr169kJGRgT59+iAsLAz29vaVUSMRERFRjdLAXBcHfNzwVWtrAMDmc9yoj4iIyq7cM/oAoKuri++++65I2/PnzzF69Ghs2rSpQgojIiIiqsnUVSRY4O2M9nWMMX3vTdlGfTM/qY+vWltDJBLJu0QiIqqiyj2jX5qkpCRs2bKlok5HRERERAA8nEwR6OuOdnWMkZUrxez9dzB022XEp2XJuzQiIqqiKizoExEREVHlMNFRw/ahLTD3UyeoKolx5kECPFedReDtF/IujYiIqiAGfSIiIiIFIBaLMLStLQ5OcINTLR28zMzFmN+vYeqeG0jPypV3eUREVIUw6BMREREpEEdTbQSMb4uxHewhEgF/X32ObquDcflJsrxLIyKiKqLMm/H16dPnrc+npKR8aC1EREREVAYqSmJ841UPHeuaYPKu63j+8jUG/BKCMe3tMcmjDlSUOJdDRFSTlflvAV1d3bf+sra2xuDBgyuzViIiIiL6j5a2Bgic5I6+zSwhFYANpx+hz8/neRs+IqIarswz+tu2bavMOoiIiIjoPWirKWN5/8bwqG+CGf/cwu3oNHRfcw4zutXDEFcb3oaPiKgGqhLrutavXw8bGxuoqamhVatWuHTp0lv779mzB/Xq1YOamhoaNmyIw4cPF3leEATMnj0btWrVgrq6Ojw8PBAREVHiubKzs9GkSROIRCJcv369ot4SERER0UfVrWEtHJ3UDu3qGCM7T4q5B+5i8NZLiONt+IiIahy5B/1du3bBz88Pc+bMwbVr19C4cWN4enoiPj6+xP4XLlzAoEGDMGLECISFhcHb2xve3t64ffu2rM+SJUuwZs0abNy4EaGhodDU1ISnpyeysor/RTd9+nSYm5tX2vsjIiIi+lhMddSwY1gLzOvZAKpKYgRHJMJz1VkcvsXb8BER1SRyD/orVqzAqFGjMGzYMDg5OWHjxo3Q0NDA1q1bS+y/evVqeHl5Ydq0aahfvz4WLFiAZs2aYd26dQAKZvNXrVqFWbNmoVevXmjUqBF27tyJmJgYBAQEFDnXkSNHcOzYMSxbtqyy3yYRERHRRyESiTDE1QaHJrqhgbkOUjJzMe6Pa5iym7fhIyKqKcp8jX5lyMnJwdWrVzFjxgxZm1gshoeHB0JCQko8JiQkBH5+fkXaPD09ZSE+MjISsbGx8PDwkD2vq6uLVq1aISQkBAMHDgQAxMXFYdSoUQgICICGhsY7a83OzkZ2drbscVpaGgAgNzcXublV9y/Nwtqqco3EcVIUHCfFwbFSDBynymWtr4bdo1pi7alH2BQcib3XniP0cSKW9G2IFjb6ZT4Px0kxcJwUB8dKMVTVcSprPXIN+omJicjPz4epqWmRdlNTU4SHh5d4TGxsbIn9Y2NjZc8XtpXWRxAEDB06FGPGjEHz5s3x5MmTd9a6ePFizJs3r1j7sWPHyvRFgbwdP35c3iVQGXCcFAPHSXFwrBQDx6ly1Qfg4wT8/lCC5ylZ+GLLJXQyF/CJlRTluQsfx0kxcJwUB8dKMVS1ccrMzCxTP7kGfXlZu3Yt0tPTi6wkeJcZM2YUWUmQlpYGKysrdO3aFTo6OpVRZoXIzc3F8ePH0aVLFygrK8u7HCoFx0kxcJwUB8dKMXCcPq6hWXlYeDgc+8JiEBQjwrM8HSzp64wG5m//dwzHSTFwnBQHx0oxVNVxKlxZ/i5yDfpGRkaQSCSIi4sr0h4XFwczM7MSjzEzM3tr/8Lf4+LiUKtWrSJ9mjRpAgA4efIkQkJCoKqqWuQ8zZs3xxdffIEdO3YUe11VVdVi/QFAWVm5Sg18aRSlzpqO46QYOE6Kg2OlGDhOH4eBsjJWDGgKL+damPnPLTyIf4XPfgmFb2dHjO1gDyXJ26f3OU6KgeOkODhWiqGqjVNZa5HrZnwqKipwcXFBUFCQrE0qlSIoKAht2rQp8Zg2bdoU6Q8ULKco7G9rawszM7MifdLS0hAaGirrs2bNGty4cQPXr1/H9evXZbfn27VrFxYtWlSh75GIiIioKunawAxHJ7WDVwMz5EkFLD/+AH03huBh/Ct5l0ZERBVE7kv3/fz8MGTIEDRv3hwtW7bEqlWrkJGRgWHDhgEABg8eDAsLCyxevBgA4Ovri/bt22P58uXo3r07/vrrL1y5cgWbNm0CULDT7KRJk7Bw4UI4OjrC1tYW33//PczNzeHt7Q0AqF27dpEatLS0AAD29vawtLT8SO+ciIiISD4MtVTx85fNEHA9GrP338GNZynoviYY33jVw1BXG4jFInmXSEREH0DuQX/AgAFISEjA7NmzERsbiyZNmiAwMFC2mV5UVBTE4v9feODq6gp/f3/MmjULM2fOhKOjIwICAuDs7CzrM336dGRkZGD06NFISUmBm5sbAgMDoaam9tHfHxEREVFVJBKJ0LupJVrbGWL63zcRHJGI+Qfv4vjdOCzt1wiW+lV/s2EiIiqZ3IM+APj4+MDHx6fE506fPl2srV+/fujXr1+p5xOJRJg/fz7mz59fpte3sbGBIAhl6ktERERUndTSVcfO4S3xe2gUfjh0DyGPk+C1KhizezihX3OudCQiUkRyvUafiIiIiORPJBLhq9bWOOLrDhdrfbzKzsP0vTcxcscVJKRny7s8IiIqJwZ9IiIiIgIA2BhpYvfXbfBtt3pQkYgRFB6P7usuICyJ1+wTESkSBn0iIiIikpGIRRjT3h7/TmgLp1o6eJmZi+0PJJi8+yZSMnPkXR4REZUBgz4RERERFVPPTAcB49tiXHs7iCHg4K1YeK46i9P34+VdGhERvQODPhERERGVSEVJjMkeDpjknA87Iw3EpWVj6LbLmPnPLbzKzpN3eUREVAoGfSIiIiJ6K2ttIGBsGwxrawMA8A+NgufKs7jwMFG+hRERUYkY9ImIiIjondRVJJjzaQP4j2oFS311RKe8xuebQ/EdZ/eJiKocBn0iIiIiKjNXeyMcndQOX7W2BgD88b/Z/fOc3SciqjIY9ImIiIioXDRVlbDA27nI7P4Xm0Mx859bSM/KlXd5REQ1HoM+EREREb2Xwtn9wW0KZvf9Q6PgtSoY5yI4u09EJE8M+kRERET03jRVlTC/lzP+HNUaVgYFs/tfbgnFjH2c3ScikhcGfSIiIiL6YG3sDRHo2w5D/je7/+elgtn94IgEOVdGRFTzMOgTERERUYXQVFXCvP/N7tc20EB0ymt8teUSZuy7ydl9IqKPiEGfiIiIiCpUG3tDBE5yx1BXGwDAn5eewXPlWZx9wNl9IqKPgUGfiIiIiCqchooS5vZsgL9GF8zux6RmYfDWS/h2702kcXafiKhSMegTERERUaVpbVd0dv+vywWz+2c4u09EVGkY9ImIiIioUhXO7u8a3RrWhhp4kZqFIVsvYeqeG0jJzJF3eURE1Q6DPhERERF9FK3sDHHEt2B2XyQC/r76HB4rzuLIrRfyLo2IqFph0CciIiKij6Zwdv/vMW1gb6yJxFfZGPvHNXz92xXEp2XJuzwiomqBQZ+IiIiIPjoXawMcmuiOCZ0coCQW4eidOHisOIPdl59BEAR5l0dEpNAY9ImIiIhILtSUJZjStS4OTHBDQwtdpGXlYfrem/hqyyVEJWXKuzwiIoXFoE9EREREclW/lg7+GeeKmZ/Ug6qSGOceJsJz1VlsDn6MfCln94mIyotBn4iIiIjkTkkixuh29jg6qR1a2xngdW4+Fh66h74/X8D92HR5l0dEpFAY9ImIiIioyrAx0oT/yNZY3KchtFWVcP1ZCnqsDcaqEw+QkyeVd3lERAqBQZ+IiIiIqhSxWIRBLWvjuF97eNQ3RW6+gFUnItBjbTCuPk2Wd3lERFUegz4RERERVUlmumr4dbAL1n3eFIaaKngQ9wqfbQzBrIBbSMvKlXd5RERVFoM+EREREVVZIpEIPRqZ44Rfe/RvbglBAH6/GAWP5Wdw+NYL3oqPiKgEDPpEREREVOXpa6pgyWeN8eeo1rAz0kR8ejbG/XENI3dcQXTKa3mXR0RUpTDoExEREZHCaGNviMO+7pjYyQHKEhGCwuPRZcUZbDkXyVvxERH9D4M+ERERESkUNWUJ/LrWxeGJ7mhho4/MnHwsOHgX3uvP43Z0qrzLIyKSOwZ9IiIiIlJIjqba2DW6TcGt+NSUcCs6FT3XncOiQ3eRmZMn7/KIiOSGQZ+IiIiIFFbhrfiCprRHj0a1IBWAX4Mj0WXFWZwKj5d3eUREcsGgT0REREQKz0RbDes+b4ZtQ1vAQk8d0SmvMWz7ZYz3v4a4tCx5l0dE9FEx6BMRERFRtdGxngmO+7XDKHdbiEXAoZsv0Hn5GWw9F4m8fKm8yyMi+igY9ImIiIioWtFQUcJ33Z1wYIIbmtbWw6vsPMw/eBc9153HtaiX8i6PiKjSMegTERERUbXUwFwXe8e4YnGfhtBVV8bdF2nos+ECZuy7iZcZOfIuj4io0jDoExEREVG1VbhZ38kp7fGZiyUA4M9Lz9B5xRnsvvIMUqkg5wqJiCoegz4RERERVXuGWqpY1q8xdn/dBnVNtZGckYPpf9/EgE0hCI9Nk3d5REQVikGfiIiIiGqMlrYGODjRDTM/qQcNFQkuP3mJ7mvO4YfD95CRnSfv8oiIKgSDPhERERHVKMoSMUa3s8cJv/bwamCGfKmATWcfw2PFGRy59QKCwOX8RKTYGPSJiIiIqEYy11PHxq9csG1oC1gZqONFahbG/nENQ7ZdxqOEV/Iuj4jovTHoExEREVGN1rGeCY5Pbo+JnRygIhHj7IMEeK06i8VH7uEVl/MTkQJi0CciIiKiGk9NWQK/rnVxbHI7dKxrjNx8Ab+ceYzOy09j//VoLucnIoXCoE9ERERE9D82RprYNqwltgxpDmtDDcSlZcP3r+sY8MtF3I3h7vxEpBgY9ImIiIiI3tC5vimOTmqHqV3rQE1ZjEtPktFjbTBm77+N1MxceZdHRPRWDPpERERERCVQU5bAp5MjgqZ0QPeGtSAVgJ0hT9Fx+Wn8eSkK+VIu5yeiqolBn4iIiIjoLSz01LH+i2bwH9kKjiZaSM7IwYx9t9B7w3mERb2Ud3lERMUw6BMRERERlYGrgxEO+7pjVvf60FZVws3nqei94QKm7rmB+PQseZdHRCTDoE9EREREVEbKEjFGutshaGp79G1mCQD4++pzdFx6GhtOP0RWbr6cKyQiYtAnIiIiIio3E201LO/fGHvHuqKxpS4ycvKxJPA+PFacweFbL3g7PiKSKwZ9IiIiIqL35GKtj3/GtcXKAY1hpqOG5y9fY9wf1zDgl4u4HZ0q7/KIqIZi0CciIiIi+gBisQi9m1ri5NT28O3sKLsd36frzmHanhuIT+P1+0T0cTHoExERERFVAA0VJUzuUgcnp3SAdxNzCAKw5+pzdFh2GutP8fp9Ivp4GPSJiIiIiCqQuZ46Vg1sin3jXNHESg+ZOflYevQ+Oi8/g4M3Y3j9PhFVOgZ9IiIiIqJK0Ky2PvaNdcWqAU1gpqOG6JTX8PEPQ7+NIbj5PEXe5RFRNcagT0RERERUScRiEbybWuDk1PaY5FFw/f6Vpy/Rc915+P4VhmfJmfIukYiqIQZ9IiIiIqJKpqGihEkedXBqagf0aWoBANh/PQadl5/BokN3kZKZI+cKiag6YdAnIiIiIvpIaumqY8WAJjg4wQ1tHQyRky/Fr8GRaLfkFDadfcQN+4ioQjDoExERERF9ZM4Wuvh9RCtsH9YC9cy0kZaVhx8Oh6Pz8jP4J+w5pFJu2EdE749Bn4iIiIhIDkQiETrUNcGhie5Y+lkj2YZ9k3fdwKfrzuH8w0R5l0hECopBn4iIiIhIjiRiEfo1t8KpqR0wzbMutFSVcCcmDV9sDsWQrZcQHpsm7xKJSMEw6BMRERERVQHqKhKM7+iAM9M6YKirDZTEIpx5kIBuq4Mxbc8NvEh9Le8SiUhBMOgTEREREVUhhlqqmNuzAU74tUf3hrUgCMCeq8/RfulpLDx4F8kZ3KGfiN6OQZ+IiIiIqAqyMdLE+i+a4Z9xrmhpY4CcPCk2n4uE+08nsfL4A6Rn5cq7RCKqohj0iYiIiIiqsKa19bHr69bYPqwFGpjrICMnH6uDInhLPiIqlZK8CyAiIiIiorcr3KG/naMxAu/EYvmx+3iUkIEfDodjy7lIjO9gBy2pvKskoqqCQZ+IiIiISEGIxSJ80rAWujqZ4p+waKw6EYHolNeY/e89GKpKILV6gd7NrCARi+RdKhHJEZfuExEREREpGCWJGP2aW+Hk1PaY17MBjLRUkJQtwtS/b+GT1cE4dicWgiDIu0wikhMGfSIiIiIiBaWqJMEQVxsETXZDj9r50FFTwv24dIz+7Sp6b7iA4IgEBn6iGohBn4iIiIhIwWmoKKGLhYCTfu4Y39Ee6soSXH+Wgq+2XMJnG0MY+IlqGAZ9IiIiIqJqQlddGdM86+Hs9I4Y3tYWqkpiXH36El9tuYS+P1/A2QcM/EQ1AYM+EREREVEF69ChAyZNmiS31zfWVsXsT50QPL0jRrgVBP5rUSkYvJWBn6gmYNAnIiIiInqHoUOHQiQSYcyYMcWeGz9+PEQiEYYOHSpr27dvHxYsWPDBr+nt7V3q8zY2NhCJRBCJRNDV1cXEiROxdevWIn1MdNTwfQ8nBH9TPPD3+fkCzvwv8K9fvx42NjZQU1NDq1atcOnSpXfWt2fPHtSrVw9qampo2LAhDh8+XOR5QRAwe/Zs1KpVC+rq6vDw8EBERESRPosWLYKrqys0NDSgp6dX5s+GiN6OQZ+IiIiIqAysrKzw119/4fXr17K2rKws+Pv7o3bt2kX6GhgYQFtbu9Jrmj9/Pl68eIGwsDB06NABY8aMwZEjR4r1M9EuHvjDolIwZOsltBy5AJMn+2H27Nm4du0aGjduDE9PT8THx5f6uhcuXMCgQYMwYsQIhIWFwdvbG97e3rh9+7asz5IlS7BmzRps3LgRoaGh0NTUhKenJ7KysmR9cnJy0K9fP4wdO7ZiPxiiGo5Bn4iIiIioDJo1awYrKyvs27dP1rZv3z7Url0bTZs2LdL3zaX7NjY2+OGHHzB8+HBoa2ujdu3a2LRp0wfXpK2tDTMzM9jZ2aFPnz4wMDDA8ePHS+1fUuC/eeQPqDXsgn9f10W8xAg///wzNDQ0iq0O+K/Vq1fDy8sL06ZNQ/369bFgwQI0a9YM69atA1Awm79q1SrMmjULvXr1QqNGjbBz507ExMQgICBAdp558+Zh8uTJaNiw4Qd/FkT0/xj0iYiIiIjKaPjw4di2bZvs8datWzFs2LAyHbt8+XI0b94cYWFhGDduHMaOHYv79+9XSF1SqRQXLlzAy5cvoaKiImvfvn07RCJRsf6FgT9oclvkxT2Ctn1TXH+WgqHbLqPXhguo79IWFy6ElPp6ISEh8PDwKNLm6emJkJCCYyIjIxEbG1ukj66uLlq1aiXrQ0SVh0GfiIiIiKiMvvzyS5w7dw5Pnz7F06dPcf78eXz55ZdlOvaTTz7BuHHj4ODggG+++QZGRkY4derUB9XzzTffQEtLC1paWliyZAn09fUxcuRI2fO6urqoW7duqceLs19BKs3HptGdMdLNFurKEtyOTsPluHycvv4Au688Q06etNhxsbGxMDU1LdJmamqK2NhY2fOFbaX1IaLKUyWCfnk3//jQjT+ePHmCESNGwNbWFurq6rC3t8ecOXOQk5NTKe+PiIiIiKoHY2NjdO/eHdu3b8e2bdvQvXt3GBkZlenYRo0ayf5bJBLBzMzsrdfBl8W0adNw/fp1HDt2DHXq1MHSpUvh4OAge753794IDw9/53kMNFUxq4cTzn/bCRM7OUBFSYzsPCmm/30T7ZeewtZzkcjMyfugWono45F70N+1axf8/PwwZ86cMm3+UREbf4SHh0MqleKXX37BnTt3sHLlSmzcuBEzZ878KO+ZiIiIiBTX8OHDsX37duzYsQPDhw8v83HKyspFHotEIkilxWfLy8PIyAgODg5wc3PDtGnT4Ofnh7t375breIlEgri4OACAgaYK/LrWRRdbNdS3s4KJtipepGZh/sG7aPvjSawJikBqZi7MzMxkxxSKi4uDmZkZAMh+f1sfIqo8cg/6K1aswKhRozBs2DA4OTlh48aNb938oyI2/vDy8sK2bdvQtWtX2NnZoWfPnpg6dWqRjVWIiIiIiEri5eWFnJwc5ObmwtPTU97lyBgbG6Nfv36YMWNGmY9RUVGBi4sLgoKCZG1SqRRnT5/CwB4eODu9I37o3RDWhhp4mZmLFccfwPXHIOjZNMDho0U3/Tt+/DjatGkDALC1tYWZmVmR86alpSE0NFTWh4gqj5I8XzwnJwdXr14t8j8jsVgMDw+PUjfpCAkJgZ+fX5E2T09PWYh/18YfAwcOLPG8qampMDAwKLXW7OxsZGdnyx6npaUBAHJzc5Gbm/v2NypHhbVV5RqJ46QoOE6Kg2OlGDhOioHjVEAqlUIqlco+h5s3bxZpf/N5QRCKPAaA/Pz8Io8FQSjW9uZrpqSk4PLly0XaDQ0NYWVlVeSchecYM2YMWrRogYsXL8LFxQUBAQGYNWtWkdWvb5o4cSJGjBiBJk2aoEWLFli7di0yMjLw5ZdfQgIp+jWrhUNrZsBIRQ8ZjfojPO4Vsmp3xq0/v0WnIVPwzaiBOHf0X1y5cgXr16+X1TJhwgQsXLgQtra2sLGxwdy5c2Fubo7u3bvL+kRFRSE5ORmRkZHIz8+XvVcHBwdoaWmVcXQUC/9MKYaqOk5lrUeuQT8xMRH5+fklbtJR2rVElbHxx8OHD7F27VosW7as1FoXL16MefPmFWs/duwYNDQ0Sj2uqnjbbVao6uA4KQaOk+LgWCkGjpNiqOnj9Pz5c2RkZBTbG6pQXFwcXr16JXs+KSkJkZGRsseZmZm4e/dukePT0tIQERFR6jmfP3+OM2fOoGXLlkXaPTw84OPjU+I5nz9/jiZNmmD8+PGYPXs2goOD8eDBg1JfAwC0tLQwePBgzJgxAy9fvoStrS1mzpyJq1evyvrcuHEDJiYmmNgrBXf1RTiuXQ/5n05D8MHfcOqPNdA2MseQid/g6dMoREVFAQCcnJzQtWtXjBgxAhkZGahfvz6mTp2KkydPys67evXqIhsSFr7XBQsWVPtb7tX0P1OKoqqNU2ZmZpn6iQRBECq5llLFxMTAwsICFy5cKLKEZ/r06Thz5gxCQ0OLHaOiooIdO3Zg0KBBsrYNGzZg3rx5iIuLw4ULF9C2bVvExMSgVq1asj79+/eHSCTCrl27ipwvOjoa7du3R4cOHbB58+ZSay1pRt/KygqJiYnQ0dF5r/f/MeTm5uL48ePo0qVLsevCqOrgOCkGjpPi4FgpBo6TYuA4KQZ5jNPlJy/xy9lInIlIlLU1ttTFcFdrdHUygZJE7lcJV0n8M6UYquo4paWlwcjICKmpqW/NoXKd0X9z849Cb9ukozwbf/w36MfFxaFJkyZFjouJiUHHjh3h6uqKTZs2vbVWVVVVqKqqFmtXVlauUgNfGkWps6bjOCkGjpPi4FgpBo6TYuA4KYaPOU6ujiZwdTTBg7h0bD0XiX1h0bjxPBW+u2/CQk8dw9raYEALK2irVX49N2/ehKmpabFVvVUZ/0wphqo2TmWtRa5fs5W2+UdQUFCpm3S0adOmSH/g/Tb+iI6ORocOHeDi4oJt27ZBLOY3jkRERERE5VXHVBs/9m2E8990gm9nRxhoqiA65TUWHrqHNotPYuHBu3j+smzLjd9HTEwMmjZtCjMzM9SvXx+TJ0/GoUOHkJ6eXmmvSVTVyXVGHwD8/PwwZMgQNG/eHC1btsSqVauQkZGBYcOGAQAGDx4MCwsLLF68GADg6+uL9u3bY/ny5ejevTv++usvXLlyRTYjLxKJMGnSJCxcuBCOjo6wtbXF999/D3Nzc3h7ewP4/5BvbW2NZcuWISEhQVYPb/dBRERERFR+xtqqmNylDsZ2sEdAWDQ2n4vEw/hX2HwuEtsuPIGXsxlGutmiaW39Cn3doKAg2W0Kw8PD8fDhQ6xatQoSiQQtWrSAp6cnOnfujFatWkFFRaVCX5uoqpJ70B8wYAASEhIwe/ZsxMbGokmTJggMDJQtu4mKiioy2+7q6gp/f3/MmjULM2fOhKOjIwICAuDs7CzrM336dGRkZGD06NFISUmBm5sbAgMDoaamBqBgBcDDhw/x8OFDWFpaFqlHjlsWEBEREREpPDVlCQa2rI3+za1wJiIBW4Ijce5hIg7dfIFDN1+gubU+hrvZoquTaYVcx3/ixAkoKSkhLy8PAGS/5+fn4+LFi7h8+TLmzZsHNTU1tG/fHl27dkXnzp3RsGFDruqlakvuQR8AfHx84OPjU+Jzp0+fLtbWr18/9OvXr9TziUQizJ8/H/Pnzy/x+aFDh2Lo0KHvUyoREREREZWBWCxCx7om6FjXBHdj0rDlXCT+vRGNK09f4srTl6ilq4YvWtXGwJa1YaRVfC+sshAEAYGBgbJwX5L8/HwAQFZWFo4fP47jx49DKpVCX18fXbp0QZcuXeDh4QEbG5v3qoGoKuJXWEREREREVKmczHWwvH9jnP+mE3w6OsBQUwUvUrOw7NgDuC4+Cb9d13H9WUq5z3v//n3Ex8eXub9UKpUt83/58iX27t2LUaNGwdbWFrVr18bo0aOxe/duJCYmvuNMRFVblZjRJyIiIiKi6s9ERw1TPetiQmcHHL71AtsvPMWNZynYFxaNfWHRaGypiyGuNujeqBZUlSTvPN+5c+c+qJ7C2X4AePbsGbZt24Zff/0VAODs7AwvLy94eHjAzc0NmpqaH/RaRB8TZ/SJiIiIiOijUlWSoHdTS+wf3xYB49uiTzMLqEjEuPE8FX67b8B18UksPnIPT5My3nqebt26wcfHBw4ODrI2JaX3n8v87yUAt2/fxqr/a+/Oo6K4EjWAf9UNNIvsOwiCuKCCuEIwokFawPgSTTzjMh5NfC6TRGfMM1GPnmhMJvP06STmJXFMxnF7SYwxL8Y8GQWbBlEREUFMcCGKKIjsyC7Q0Pf9YeyxI+IC0tB8v3M4QtWt6nu5Xrq+rqpbH3+M6Oho2NnZISwsDH/+85+RkpLS5q0CRF0Bz+gTEREREZHBDPOywzCvYVj9/CB8m5aPr05dR2FVA75Iuoovkq4irL8Tfh/sDeVgV5j+ZvI+T09PfPrppwDuPFkrISEB8fHxiI2NRUlJCSRJgiRJusv1H9e9E/wlJycjJSUFa9euhaWlJcLDw3X39w8ePBiSJLXvF0HUgRj0iYiIiIjI4Jx6KbA4vB/+MK4v1JdKsCc1D8cul+L45TIcv1wGZ2sFZozywsxgL/S2t7xve09PT8yZMwdz5syBEALZ2dlQq9U4cuQIEhISUFtbC7lcDq1W+0RP2hJC6C71r6+vx+HDh3Ho0CEIIeDk5ITIyEhMnDgRERER8PLyavfvg6g9GPSJiIiIiKjLMJHLEDXEDVFD3JBfUY9vTudh35kbKK1pxGeJV7Dl6BWMH+CMWcHemODvct9ZfuDOU7j8/f3h7++PxYsXo7m5GRkZGYiPj8eRI0eQnJyM5uZmvcfyPa57rxIoKyvDvn37sGfPHgCAr6+v7v7+8PBw2NvbP9kvg+gJMegTEREREVGX5OVgiRXR/nhTOQCqC8XYc/o6kq+U42h2KY5ml8KplxleHtEb00f1Rj8X6wfux8TEBMHBwQgODsbq1atx+/ZtJCcnIz4+HnFxcTh37hyEEO0K/vdul5ubi23btmHr1q2QJAlBQUGIjo5GREQEgoODn2j/RI+DQZ+IiIiIiLo0MxMZJg91x+Sh7sgtq8Pe03n4PuMGymqb8PdjV/H3Y1cxwtsOM0Z7YfJQD/RStB1zLCwsoFQqoVQqsWHDBlRUVCAxMRFqtRqHDx/GtWvXAKBDgr8QApmZmcjKysKGDRtgamqKAQMG4Oeff0ZkZCRGjhwJufzhTxggehycdZ+IiIiIiLoNXycrrHp+EFJWReDvc0ZCOcgVcpmEjLxKrPz+Z4z+IB5vf3cOp3MrHvlefAcHB0ybNg1/+9vfkJubi+vXr2PHjh2YPn06HB0dAQAymQwy2ZPHp7vBX6PR4MKFC1i3bh1CQkJgb2+PKVOmYMuWLbh06dITzR9A9Fs8o09ERERERN2OqVyGyCFuiBzihpLqBuw/W4B9Z/JxtbQO/5t+A/+bfgPeDpaYOtwTLw/3hI+T1SPv29vbG/PmzcO8efMghMCFCxcQHx8PlUqFxMRE1NfXQy6X6ybne1z3TuxXU1ODmJgYHDx4EEIIuLi4YNKkSYiIiEBERAQ8PDye6DWoZ2PQJyIiIiKibs3FxhyvjffDH8b1RUbeLXyblo9//lSIvIp6fKK+jE/UlzHC2w4vjeiNF4a6w87S7JH3LUkShgwZgiFDhmDp0qXQaDRIS0uDWq1GXFwcUlNTO3Riv5KSEnz99dfYvXs3AKBfv3664P/cc8/B1tb2iV6DehYGfSIiIiIiMgqSJGFkHweM7OOA914MwJELRdifUYDjl0uRkVeJjLxKvH/wPMIHuuDlEb0R7u8Mhcnj3R9vamqKMWPGYMyYMVizZg3q6upw/PhxqNVqxMbGIisrC0DH3N8PAFeuXMHWrVvx6aefQiaTYfjw4boZ/UNDQ6FQKJ7oNci4MegTEREREZHRsTCTY8owT0wZ5omS6gb837mb2J9RgAuF1ThyoRhHLhTDxtwE0QFueCHIA6F9HWHSyqP6HsbKygrR0dGIjo7Gpk2bUFpaisTERKhUKsTFxSE/Px8A2nWp/93gr9VqkZ6ejnPnzuEvf/kLFAoFwsLCMHHiRCiVSgwbNqxd8wiQ8WDQJyIiIiIio+ZiY44FYX2xIKwvLhVV44eMAhzILEBxdSP2nbmBfWduwNHKDM8HuuOFIA+M6mMPmUx6otdydnbG9OnTMX36dAB3HrWnVquhUqmgUqlw69YtSJIESZL0Ltl/HHeDf2NjI9RqNRISErBy5UrY2Nhg4sSJmDhxIiIiIuDn5wdJerJ2UPfGoE9ERERERD2Gv5sNVj1vgxXR/ki7VoGD527i0M+FKK9rwpenruPLU9fhZmOOfxvqjn8L8kBQb9t2hWVfX18sWLAACxYsgFarRUZGBrZs2YKCggIcP34cDQ0N7Z7Y7+5M/dXV1Thw4AD2798PIQQ8PDwQFRWFiRMnYsKECXB1dX3idlD3wqBPREREREQ9jlwm4Zm+jnimryPWvTgEJ3PKcfDcTcRlFaGougH/OJGLf5zIhaedBaKGuGFSoBtGej/5mX7gziP6goKCMHXqVDz//PMQQiA1NRXx8fGIi4tDWloatFptu+7vv/cDg5s3b+LLL7/Ezp07AQD+/v66if3GjRsHa2vrJ24LdW0M+kRERERE1KOZymUYP8AZ4wc444OpATj2Syn+79xNJFwqQUHlbexIzsWO5Fw4WysQNcQV0UPc8Uxfhye6p/9eZmZmCAsLQ1hYGN577z3U1NTg2LFjiI+PR2xsLC5dugSg4yb2u3TpEq5cuYLNmzdDLpdj1KhRiI6ORkREBEJCQmBm9uhPI6CujUGfiIiIiIjoV+amckQOcUPkEDc0aFqQ9EspYrOKEH+xGKU1jfjqVB6+OpUHO0tTTBzkiqghbni2nxMszB5v9v7WWFtbY/LkyZg8eTI2b96M4uJiJCQkQKVSITY2FoWFhZAkCTKZrN0T+7W0tCA1NRVnzpzBe++9B3Nzc4wfPx6RkZGIiIhAYGAgJ/brxhj0iYiIiIiIWmFuKkfUEDdEDXFDU7MWJ3PKEJtVhCMXilFR14Tv0m/gu/QbMDeVYWw/J0QMckWEvwtcbMw75PVdXV0xa9YszJo1C0II5OTkID4+HvHx8VCpVKiuroZMJtO7T/9x3f3AoKGhQTdhoFarhb29vW5iP6VSCR8fnw5pE3UOBn0iIiIiIqKHMDOR4bmBLnhuoAs+mKpF2rVbiM0qRPzFO5f3x18sQfzFEgBAUG9bKAe5ImKQKwa5W3fIzPeSJKFfv37o168fXnvtNWi1WmRmZuru7z9x4gSampradZn/vU8BuHXrFr7//nvs27cPAODl5YXo6GgolUpMmDABTk5O7W4TPT0M+kRERERERI/BRC5DqJ8jQv0cse5FgUtFNYi/UIz4SyU4l1+JczeqcO5GFT5U/QJPOwuM+/X+/2f7OcK8/Vf4A7gzsd+IESMwYsQIrFixAg0NDUhJSYFarUZsbCzOnj3boRP75efnY+fOndi2bRsAICAgQBf8x44dCysrqw5pF3UMBn0iIiIiIqInJEkSBrnbYJC7Df4Y0R8l1Q1IuFSC+IvFOHGlDAWVt/HN6Tx8czoPJjIJI7zt4KKV4FNYjaFeDh32nHtzc3OEh4cjPDwcH3zwASorK5GUlAS1Wo3Dhw/jypUrADpuYr+srCxcunQJf/3rX2FiYoJnnnkGkZGRUCqVGD16NExMGDUNib99IiIiIiKiDuJiY46Zwd6YGeyN200tOHW1HEm/lCLpl1LkltXh9LVbAOSI+dspOFsrMK6/M8L6O2GMn2OH3dsPAHZ2dpgyZQqmTJkCACgoKEBCQoJuRv+SkhJIkgRJkvQu2X8cd4N/c3MzkpOTkZKSgrVr18LS0hLh4eG6+/sHDx7cYR9ofPnllwgJCcGAAQM6ZH/GikGfiIiIiIjoKbAwkyPc3wXh/i4AgOvldUi8WIT/Tb6AnFoTlNY04vuMG/g+4wYAoL9LL4zxc8SYfk54xtcRtpamHVYXT09PzJkzB3PmzIEQAtnZ2VCr1Thy5AgSEhJQW1sLuVwOrVb7RBP7CSF0l/rX19fj8OHDOHToEIQQcHJyQmRkJCZOnIiIiAh4eXk9URsKCgowd+5c2NjYICYmBmFhYU+0n56AQZ+IiIiIiKgT9HG0wuwQb9iXZyEicgJ+KqhB0i+lSM4pw/mb1bhcUovLJbXYnXIdMgkI8LRFqJ8jxvg5YWQfe/RSdEx8kyQJ/v7+8Pf3x+LFi9Hc3IyMjAzEx8fjyJEjSE5ORnNzc4dN7FdWVoZ9+/Zhz549AABfX1/d/f3h4eGwt7d/pH2q1WoAQG1tLSZMmICvv/4a06dPf6L6GTsGfSIiIiIiok6mMJFhTD8njOl3Z/b6W3VNOHW1HCdzypGcU4arpXX46UYVfrpRhS+SrkImAUM8bDHaxwHBvvYY5eMAp16KDqmLiYkJgoODERwcjNWrV+P27dtITk7Wzeh/7tw5CCE67P7+3NxcbNu2DVu3boUkSQgKCkJ0dDQiIiLw7LPPwsLCotV9qFQqXR20Wi1mzJiB/Px8LFu2rMNuDTAWDPpEREREREQGZm9lhkmB7pgU6A4AKKpqwMmcMpzMKcepq+W4ces2fi6ows8FVdiRnAsA6OtshWAfB4z2ccDIPvbo42jZIYHXwsICSqUSSqUSGzZsQEVFBRITE3UT+127dg0AIJfL9Wbmfxx3g78QApmZmcjKysKGDRtgamqKMWPGICoqChERERg5ciTkcjmEEIiLi7vvg4a3334b165dw8cffwy5vIMeaWAEGPSJiIiIiIi6GDdbc7w8ojdeHtEbAFBYdRuncyuQdq0Cabm3kF1cg6uldbhaWoe9afkAAHtLUwzzssMwL3sM97ZDkJcdbC3af5+/g4MDpk2bhmnTpgEA8vLyoFardWf8y8vLIZPJAKDdE/tpNBocO3YMJ06cwOrVq2FtbY3w8HAMHz4cpaWlrW67ZcsW5Ofn45tvvnng1QA9DYM+ERERERFRF+dua4EpwzwxZZgnAKCyvglnrt1C2rUKnL5WgfMF1bhVr0FidikSs/8ViPs6W2GYlx2Ge9khwNMWg9xtYG7avjPf3t7emDdvHubNmwchBM6fP6+b2O/o0aOor69v19n+eyf2q6mpQUxMDA4ePAiZTNbqBwlCCBw8eBDjx4/HoUOH4OTk1K72GQMGfSIiIiIiom7GztIMysGuUA52BQA0NrfgYmENMvNu4Wx+JTLzK3G9vF531n9/RgEAQC6T4OdshQAPWwzxtEWAhw0Ge9jA2vzJzvxLkoSAgAAEBARg6dKl0Gg0SEtLg1qtRlxcHFJTUztsYr+2ngag1WqRkZGB4OBgqFQq+Pn5PdFrGQsGfSIiIiIiom5OYSL/9bJ9O7z667Ly2kacu1GJzLxKZN6owoWbVSirbcIvxbX4pbgW+88W6Lb3cbTEIHcbDHC1xkA3awxwtYaPoyVM5LLHqsfde+zHjBmDNWvWoK6uDsePH9fd33/+/HkAaFfwf5CWlhbk5eVh9OjRiI2NRXBwcIfuvzth0CciIiIiIjJCjr0UmODvign+d876CyFQUtOIrIIqZBVU4/zNKpy/WY2Cytu4Vl6Pa+X1OJxVpNveTC6Dn0svDHDthQGud8J/X2creNlbwszk0T4AsLKyQnR0NKKjo7Fp0yaUlpYiMTERKpUKcXFxyM+/M79Aey71v1dLSwuqqqowbtw47Nu3Dy+++GK799kdMegTERERERH1AJIkwdXGHK425ogY5KpbfquuCedvVuNSUTV+Ka5BdnEtLhfXoL6pBRcLq3GxsFpvP3KZBC97C/R17gVfJyv4Olmhr5MV+jr3gou1AjLZg2f+d3Z2xvTp0zF9+nQAdx61p1aroVKpoFKpcOvWLchkMggh2rxUvy1arRZNTU2YOnUqPvvsM7zxxhtPtJ/ujEGfiIiIiIioB7O3MsPY/k4Y2/9fk9hptQIFlbeRXVSD7OIa/FJcg8vFtcgtq8NtTYvuCoDfMjORobe9BXrbW6K3vQW8fv23t70FvBws4WhlpvcIQF9fXyxYsAALFiyAVqvFzz//jPj4eKhUKiQlJaGhoeGJzvbf/ZBg8eLFuH79OtavX697MkBPwKBPREREREREemQyCV4OlvBysNRN+AfcCdDF1Y24WnYn9OeW1iG3rA5Xy+qQV1GPpmatbgLA1ihMZHCzNYertTlcbc3haq248/OvVxq49e6P15YMwbJly6DRaJCYmIjo6Oh2tWXjxo3Iy8vDrl27oFAo2rWv7oJBn4iIiIiIiB6JJElwszWHm605xvjpP8ZO06JFUVUD8m/V40bFbdy4VY/8W3f+vXHrNoqqG9DYrMX18npcb+VqgHspTGRwtDJDc35Wu+p7d9K/vXv34o033kBYWFi79tddMOgTERERERFRu5nKZbqrANDK0+0am1tQXNWIouoGFN/zVVTd+K/vq+58GNDYrMXNqgbcykgBZHJA+wiX7ksyAAL49bJ9c6fesPcJgKPvYLj2C8AX2WbYfTUNClM5FCYymMpkkMslmMokyGUyhPo5YuI9Vy90Zwz6RERERERE9NQpTOTwdrSEt6PlA8sIIVDf1IKKuiZU1DXh5R9WoLq1kC9JkCQZxK/r5L0cofD0h5n7QCjc+8PM1Q8yxZ3XqQFQowWuXClrs35yGRj0iYiIiIiIiDqSJEmwUpjASmECS3EbuZcvAvjXJfgAYG9vj5CQEDzzzDMYPXo0Ro8eDWdnZzRoWlDT0IyaBg1ua1rQoNGisbkFjRotGjQtaGj+dZmmBY3NWjRrBZpbBJq1d74P9nEwZNM7FIM+ERERERERdTkNDQ3w9vaGl5cXQkNDdaG+T58+ejP332VuKoe5qRzO1j1jwr22MOgTERERERFRl+Pp6Ylr164ZuhrdUs95kCARERERERFRD8CgT0RERERERGREGPSJiIiIiIiIjAiDPhEREREREZERYdAnIiIiIiIiMiIM+kRERERERERGhEGfiIiIiIiIyIgw6BMREREREREZEQZ9IiIiIiIiIiPCoE9ERERERERkRBj0iYiIiIiIiIwIgz4RERERERGREWHQJyIiIiIiIjIiDPpERERERERERoRBn4iIiIiIiMiIMOgTERERERERGREGfSIiIiIiIiIjwqBPREREREREZEQY9ImIiIiIiIiMCIM+ERERERERkRFh0CciIiIiIiIyIgz6REREREREREaEQZ+IiIiIiIjIiDDoExERERERERkRBn0iIiIiIiIiI8KgT0RERERERGREGPSJiIiIiIiIjAiDPhEREREREZERYdAnIiIiIiIiMiIM+kRERERERERGhEGfiIiIiIiIyIgw6BMREREREREZEQZ9IiIiIiIiIiPCoE9ERERERERkRBj0iYiIiIiIiIwIgz4RERERERGREWHQJyIiIiIiIjIiXSLob9myBT4+PjA3N0dISAhOnz7dZvnvvvsO/v7+MDc3R2BgIA4dOqS3XgiBtWvXwt3dHRYWFlAqlbh8+bJemYqKCsyePRs2Njaws7PD/PnzUVtb2+FtIyIiIiIiIupMBg/63377LZYtW4Z3330XGRkZCAoKQlRUFEpKSlotf/LkScyaNQvz58/H2bNnMXXqVEydOhVZWVm6Mhs3bsQnn3yCzz//HKmpqbCyskJUVBQaGhp0ZWbPno3z589DpVIhJiYGx44dw6JFi556e4mIiIiIiIieJoMH/Y8++ggLFy7EvHnzMHjwYHz++eewtLTEjh07Wi3/3//934iOjsby5csxaNAg/PnPf8aIESPw2WefAbhzNv/jjz/GO++8gylTpmDo0KH4n//5H9y8eRMHDhwAAFy8eBGxsbH4xz/+gZCQEIwdOxaffvop9u7di5s3b3ZW04mIiIiIiIg6nIkhX7ypqQnp6elYtWqVbplMJoNSqURKSkqr26SkpGDZsmV6y6KionQhPjc3F0VFRVAqlbr1tra2CAkJQUpKCmbOnImUlBTY2dlh1KhRujJKpRIymQypqal46aWX7nvdxsZGNDY26n6uqqoCcOcWAI1G8/iN7yQajQb19fUoLy+HqampoatDD8B+6h7YT90H+6p7YD91D+yn7oH91H2wr7qHrtpPNTU1AO6c4G6LQYN+WVkZWlpa4Orqqrfc1dUVly5danWboqKiVssXFRXp1t9d1lYZFxcXvfUmJiZwcHDQlfmt9evX47333rtvua+v74OaR0RERERERNThampqYGtr+8D1Bg363cmqVav0riTQarWoqKiAo6MjJEkyYM3aVl1dDS8vL+Tn58PGxsbQ1aEHYD91D+yn7oN91T2wn7oH9lP3wH7qPthX3UNX7SchBGpqauDh4dFmOYMGfScnJ8jlchQXF+stLy4uhpubW6vbuLm5tVn+7r/FxcVwd3fXKzNs2DBdmd9O9tfc3IyKiooHvq5CoYBCodBbZmdn13YDuxAbG5su9R+UWsd+6h7YT90H+6p7YD91D+yn7oH91H2wr7qHrthPbZ3Jv8ugk/GZmZlh5MiRUKvVumVarRZqtRqhoaGtbhMaGqpXHgBUKpWuvK+vL9zc3PTKVFdXIzU1VVcmNDQUlZWVSE9P15VJSEiAVqtFSEhIh7WPiIiIiIiIqLMZ/NL9ZcuW4ZVXXsGoUaMQHByMjz/+GHV1dZg3bx4AYO7cufD09MT69esBAEuXLsX48ePx4YcfYvLkydi7dy/OnDmDv//97wAASZLw5ptv4oMPPkD//v3h6+uLNWvWwMPDA1OnTgUADBo0CNHR0Vi4cCE+//xzaDQaLFmyBDNnznzoJRBEREREREREXZnBg/6MGTNQWlqKtWvXoqioCMOGDUNsbKxuMr28vDzIZP+68GDMmDHYs2cP3nnnHaxevRr9+/fHgQMHEBAQoCuzYsUK1NXVYdGiRaisrMTYsWMRGxsLc3NzXZmvv/4aS5YsQUREBGQyGaZNm4ZPPvmk8xreSRQKBd599937bjugroX91D2wn7oP9lX3wH7qHthP3QP7qftgX3UP3b2fJPGwefmJiIiIiIiIqNsw6D36RERERERERNSxGPSJiIiIiIiIjAiDPhEREREREZERYdAnIiIiIiIiMiIM+kZuy5Yt8PHxgbm5OUJCQnD69GlDV6lHW79+PUaPHg1ra2u4uLhg6tSpyM7O1ivz3HPPQZIkva/XXnvNQDXumdatW3dfH/j7++vWNzQ0YPHixXB0dESvXr0wbdo0FBcXG7DGPZOPj899/SRJEhYvXgyAY8lQjh07hhdeeAEeHh6QJAkHDhzQWy+EwNq1a+Hu7g4LCwsolUpcvnxZr0xFRQVmz54NGxsb2NnZYf78+aitre3EVhi/tvpJo9Fg5cqVCAwMhJWVFTw8PDB37lzcvHlTbx+tjcENGzZ0ckuM38PG1KuvvnpfP0RHR+uV4Zh6+h7WT629X0mShE2bNunKcEw9fY9yLP4ox3l5eXmYPHkyLC0t4eLiguXLl6O5ubkzm/JQDPpG7Ntvv8WyZcvw7rvvIiMjA0FBQYiKikJJSYmhq9ZjJSUlYfHixTh16hRUKhU0Gg0iIyNRV1enV27hwoUoLCzUfW3cuNFANe65hgwZotcHJ06c0K37j//4Dxw8eBDfffcdkpKScPPmTbz88ssGrG3PlJaWptdHKpUKAPC73/1OV4ZjqfPV1dUhKCgIW7ZsaXX9xo0b8cknn+Dzzz9HamoqrKysEBUVhYaGBl2Z2bNn4/z581CpVIiJicGxY8ewaNGizmpCj9BWP9XX1yMjIwNr1qxBRkYG9u/fj+zsbLz44ov3lX3//ff1xtgf//jHzqh+j/KwMQUA0dHRev3wzTff6K3nmHr6HtZP9/ZPYWEhduzYAUmSMG3aNL1yHFNP16Mciz/sOK+lpQWTJ09GU1MTTp48id27d2PXrl1Yu3atIZr0YIKMVnBwsFi8eLHu55aWFuHh4SHWr19vwFrRvUpKSgQAkZSUpFs2fvx4sXTpUsNVisS7774rgoKCWl1XWVkpTE1NxXfffadbdvHiRQFApKSkdFINqTVLly4Vfn5+QqvVCiE4lroCAOKHH37Q/azVaoWbm5vYtGmTblllZaVQKBTim2++EUIIceHCBQFApKWl6cocPnxYSJIkCgoKOq3uPclv+6k1p0+fFgDE9evXdcv69OkjNm/e/HQrR3pa66tXXnlFTJky5YHbcEx1vkcZU1OmTBETJkzQW8Yx1fl+eyz+KMd5hw4dEjKZTBQVFenKbN26VdjY2IjGxsbObUAbeEbfSDU1NSE9PR1KpVK3TCaTQalUIiUlxYA1o3tVVVUBABwcHPSWf/3113ByckJAQABWrVqF+vp6Q1SvR7t8+TI8PDzQt29fzJ49G3l5eQCA9PR0aDQavbHl7+8Pb29vji0DampqwldffYV///d/hyRJuuUcS11Lbm4uioqK9MaPra0tQkJCdOMnJSUFdnZ2GDVqlK6MUqmETCZDampqp9eZ7qiqqoIkSbCzs9NbvmHDBjg6OmL48OHYtGlTl7t0tac4evQoXFxcMHDgQLz++usoLy/XreOY6nqKi4vxz3/+E/Pnz79vHcdU5/rtsfijHOelpKQgMDAQrq6uujJRUVGorq7G+fPnO7H2bTMxdAXo6SgrK0NLS4vef0AAcHV1xaVLlwxUK7qXVqvFm2++iWeffRYBAQG65b///e/Rp08feHh44KeffsLKlSuRnZ2N/fv3G7C2PUtISAh27dqFgQMHorCwEO+99x7CwsKQlZWFoqIimJmZ3Xew6+rqiqKiIsNUmHDgwAFUVlbi1Vdf1S3jWOp67o6R1t6b7q4rKiqCi4uL3noTExM4ODhwjBlIQ0MDVq5ciVmzZsHGxka3/E9/+hNGjBgBBwcHnDx5EqtWrUJhYSE++ugjA9a254mOjsbLL78MX19f5OTkYPXq1Zg0aRJSUlIgl8s5prqg3bt3w9ra+r7b/jimOldrx+KPcpxXVFTU6vvY3XVdBYM+kYEsXrwYWVlZevd+A9C7Zy4wMBDu7u6IiIhATk4O/Pz8OruaPdKkSZN03w8dOhQhISHo06cP9u3bBwsLCwPWjB5k+/btmDRpEjw8PHTLOJaI2k+j0WD69OkQQmDr1q1665YtW6b7fujQoTAzM8Mf/vAHrF+/HgqForOr2mPNnDlT931gYCCGDh0KPz8/HD16FBEREQasGT3Ijh07MHv2bJibm+st55jqXA86FjcWvHTfSDk5OUEul983Q2RxcTHc3NwMVCu6a8mSJYiJiUFiYiJ69+7dZtmQkBAAwJUrVzqjatQKOzs7DBgwAFeuXIGbmxuamppQWVmpV4Zjy3CuX7+O+Ph4LFiwoM1yHEuGd3eMtPXe5Obmdt+ksc3NzaioqOAY62R3Q/7169ehUqn0zua3JiQkBM3Nzbh27VrnVJBa1bdvXzg5Oen+1nFMdS3Hjx9Hdnb2Q9+zAI6pp+lBx+KPcpzn5ubW6vvY3XVdBYO+kTIzM8PIkSOhVqt1y7RaLdRqNUJDQw1Ys55NCIElS5bghx9+QEJCAnx9fR+6TWZmJgDA3d39KdeOHqS2thY5OTlwd3fHyJEjYWpqqje2srOzkZeXx7FlIDt37oSLiwsmT57cZjmOJcPz9fWFm5ub3viprq5GamqqbvyEhoaisrIS6enpujIJCQnQarW6D2vo6bsb8i9fvoz4+Hg4Ojo+dJvMzEzIZLL7LhOnznXjxg2Ul5fr/tZxTHUt27dvx8iRIxEUFPTQshxTHe9hx+KPcpwXGhqKn3/+We8DtLsfhg4ePLhzGvIoDDwZID1Fe/fuFQqFQuzatUtcuHBBLFq0SNjZ2enNEEmd6/XXXxe2trbi6NGjorCwUPdVX18vhBDiypUr4v333xdnzpwRubm54scffxR9+/YV48aNM3DNe5a33npLHD16VOTm5ork5GShVCqFk5OTKCkpEUII8dprrwlvb2+RkJAgzpw5I0JDQ0VoaKiBa90ztbS0CG9vb7Fy5Uq95RxLhlNTUyPOnj0rzp49KwCIjz76SJw9e1Y3W/uGDRuEnZ2d+PHHH8VPP/0kpkyZInx9fcXt27d1+4iOjhbDhw8Xqamp4sSJE6J///5i1qxZhmqSUWqrn5qamsSLL74oevfuLTIzM/Xer+7OKH3y5EmxefNmkZmZKXJycsRXX30lnJ2dxdy5cw3cMuPTVl/V1NSIt99+W6SkpIjc3FwRHx8vRowYIfr37y8aGhp0++CYevoe9rdPCCGqqqqEpaWl2Lp1633bc0x1jocdiwvx8OO85uZmERAQICIjI0VmZqaIjY0Vzs7OYtWqVYZo0gMx6Bu5Tz/9VHh7ewszMzMRHBwsTp06Zegq9WgAWv3auXOnEEKIvLw8MW7cOOHg4CAUCoXo16+fWL58uaiqqjJsxXuYGTNmCHd3d2FmZiY8PT3FjBkzxJUrV3Trb9++Ld544w1hb28vLC0txUsvvSQKCwsNWOOeKy4uTgAQ2dnZess5lgwnMTGx1b9zr7zyihDiziP21qxZI1xdXYVCoRARERH39V95ebmYNWuW6NWrl7CxsRHz5s0TNTU1BmiN8Wqrn3Jzcx/4fpWYmCiEECI9PV2EhIQIW1tbYW5uLgYNGiT+8z//Uy9cUsdoq6/q6+tFZGSkcHZ2FqampqJPnz5i4cKF953U4Zh6+h72t08IIb744gthYWEhKisr79ueY6pzPOxYXIhHO867du2amDRpkrCwsBBOTk7irbfeEhqNppNb0zZJCCGe0sUCRERERERERNTJeI8+ERERERERkRFh0CciIiIiIiIyIgz6REREREREREaEQZ+IiIiIiIjIiDDoExERERERERkRBn0iIiIiIiIiI8KgT0RERERERGREGPSJiIiIiIiIjAiDPhEREXVbzz33HN58801DV4OIiKhLYdAnIiKiNr366quQJAmSJMHU1BS+vr5YsWIFGhoaDF01IiIiaoWJoStAREREXV90dDR27twJjUaD9PR0vPLKK5AkCf/1X/9l6KoRERHRb/CMPhERET2UQqGAm5sbvLy8MHXqVCiVSqhUKgBAY2Mj/vSnP8HFxQXm5uYYO3Ys0tLSdNvu2rULdnZ2evs7cOAAJEnS/bxu3ToMGzYMX375JXx8fGBra4uZM2eipqZGV6aurg5z585Fr1694O7ujg8//PDpNpqIiKibYtAnIiKix5KVlYWTJ0/CzMwMALBixQp8//332L17NzIyMtCvXz9ERUWhoqLisfabk5ODAwcOICYmBjExMUhKSsKGDRt065cvX46kpCT8+OOPOHLkCI4ePYqMjIwObRsREZExYNAnIiKih4qJiUGvXr1gbm6OwMBAlJSUYPny5airq8PWrVuxadMmTJo0CYMHD8a2bdtgYWGB7du3P9ZraLVa7Nq1CwEBAQgLC8OcOXOgVqsBALW1tdi+fTv++te/IiIiAoGBgdi9ezeam5ufRnOJiIi6Nd6jT0RERA8VHh6OrVu3oq6uDps3b4aJiQmmTZuGn376CRqNBs8++6yurKmpKYKDg3Hx4sXHeg0fHx9YW1vrfnZ3d0dJSQmAO2f7m5qaEBISolvv4OCAgQMHtrNlRERExodBn4iIiB7KysoK/fr1AwDs2LEDQUFB2L59O0aPHv3QbWUyGYQQess0Gs195UxNTfV+liQJWq22HbUmIiLqmXjpPhERET0WmUyG1atX45133oGfnx/MzMyQnJysW6/RaJCWlobBgwcDAJydnVFTU4O6ujpdmczMzMd6TT8/P5iamiI1NVW37NatW/jll1/a1xgiIiIjxKBPREREj+13v/sd5HI5tm7ditdffx3Lly9HbGwsLly4gIULF6K+vh7z588HAISEhMDS0hKrV69GTk4O9uzZg127dj3W6/Xq1Qvz58/H8uXLkZCQgKysLLz66quQyXgoQ0RE9Fu8dJ+IiIgem4mJCZYsWYKNGzciNzcXWq0Wc+bMQU1NDUaNGoW4uDjY29sDuHMv/VdffYXly5dj27ZtiIiIwLp167Bo0aLHes1NmzahtrYWL7zwAqytrfHWW2+hqqrqaTSPiIioW5PEb2+aIyIiIiIiIqJui9e7ERERERERERkRBn0iIiIiIiIiI8KgT0RERERERGREGPSJiIiIiIiIjAiDPhEREREREZERYdAnIiIiIiIiMiIM+kRERERERERGhEGfiIiIiIiIyIgw6BMREREREREZEQZ9IiIiIiIiIiPCoE9ERERERERkRP4fYgHHzen9ojEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def cosine_learning_rate(current_round, total_rounds, initial_lr=0.001, min_lr=0):\n",
    "    return min_lr + 0.5 * (initial_lr - min_lr) * (1 + math.cos(math.pi * current_round / total_rounds))\n",
    "\n",
    "# 设置参数\n",
    "total_rounds = 200\n",
    "initial_lr = 0.01\n",
    "min_lr = 0.001\n",
    "\n",
    "# 计算每个回合的学习率\n",
    "lr_schedule = [cosine_learning_rate(r, total_rounds, initial_lr, min_lr) for r in range(total_rounds)]\n",
    "\n",
    "# 创建图表\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(total_rounds), lr_schedule)\n",
    "plt.title('Cosine Learning Rate Schedule')\n",
    "plt.xlabel('Round')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.grid(True)\n",
    "\n",
    "# 设置y轴的范围，使其从0开始\n",
    "plt.ylim(bottom=0)\n",
    "\n",
    "# 添加一些关键点的标注\n",
    "plt.annotate(f'Initial LR: {initial_lr}', xy=(0, initial_lr), xytext=(10, initial_lr),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "plt.annotate(f'Min LR: {min_lr}', xy=(total_rounds-1, min_lr), xytext=(total_rounds-60, min_lr*2),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=kernel_size//2, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn = nn.MultiheadAttention(dim, num_heads)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, dim * mlp_ratio),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(dim * mlp_ratio, dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.norm1(x), self.norm1(x), self.norm1(x))[0]\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        return x\n",
    "\n",
    "class MobileViTBlock(nn.Module):\n",
    "    def __init__(self, in_channels, dim, patch_size, num_transformer_blocks):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.local_rep = nn.Sequential(\n",
    "            ConvBlock(in_channels, in_channels),\n",
    "            ConvBlock(in_channels, dim)\n",
    "        )\n",
    "        self.transformer = nn.Sequential(*[TransformerBlock(dim, num_heads=4) for _ in range(num_transformer_blocks)])\n",
    "        self.fusion = ConvBlock(dim, in_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.local_rep(x)\n",
    "        B, C, H, W = y.shape\n",
    "        y = y.reshape(B, C, H // self.patch_size, self.patch_size, W // self.patch_size, self.patch_size)\n",
    "        y = y.permute(0, 2, 4, 1, 3, 5).reshape(B * (H // self.patch_size) * (W // self.patch_size), C, -1)\n",
    "        y = self.transformer(y.transpose(1, 2)).transpose(1, 2)\n",
    "        y = y.reshape(B, H // self.patch_size, W // self.patch_size, C, self.patch_size, self.patch_size)\n",
    "        y = y.permute(0, 3, 1, 4, 2, 5).reshape(B, C, H, W)\n",
    "        y = self.fusion(y)\n",
    "        return x + y\n",
    "\n",
    "class MobileViT(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=1000, dims=[96, 120, 144], patch_sizes=[2, 2, 2], num_transformer_blocks=[2, 4, 3]):\n",
    "        super().__init__()\n",
    "        self.stem = ConvBlock(in_channels, 16, stride=2)\n",
    "        \n",
    "        self.stages = nn.ModuleList([\n",
    "            self._make_stage(16, 32, dims[0], patch_sizes[0], num_transformer_blocks[0]),\n",
    "            self._make_stage(32, 64, dims[1], patch_sizes[1], num_transformer_blocks[1]),\n",
    "            self._make_stage(64, 96, dims[2], patch_sizes[2], num_transformer_blocks[2])\n",
    "        ])\n",
    "        \n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(96, num_classes)\n",
    "\n",
    "    def _make_stage(self, in_channels, out_channels, dim, patch_size, num_transformer_blocks):\n",
    "        return nn.Sequential(\n",
    "            ConvBlock(in_channels, out_channels, stride=2),\n",
    "            MobileViTBlock(out_channels, dim, patch_size, num_transformer_blocks)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        for stage in self.stages:\n",
    "            x = stage(x)\n",
    "        x = self.pool(x).flatten(1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# 创建一个 MobileViT 模型示例\n",
    "model = MobileViT(num_classes=10)  # 适用于 Imagenette 的 10 个类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileViT(\n",
      "  (stem): ConvBlock(\n",
      "    (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (stages): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): ConvBlock(\n",
      "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (1): MobileViTBlock(\n",
      "        (local_rep): Sequential(\n",
      "          (0): ConvBlock(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (1): ConvBlock(\n",
      "            (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "        (transformer): Sequential(\n",
      "          (0): TransformerBlock(\n",
      "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=96, out_features=96, bias=True)\n",
      "            )\n",
      "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Sequential(\n",
      "              (0): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (1): TransformerBlock(\n",
      "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=96, out_features=96, bias=True)\n",
      "            )\n",
      "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Sequential(\n",
      "              (0): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (fusion): ConvBlock(\n",
      "          (conv): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): ConvBlock(\n",
      "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (1): MobileViTBlock(\n",
      "        (local_rep): Sequential(\n",
      "          (0): ConvBlock(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (1): ConvBlock(\n",
      "            (conv): Conv2d(64, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "        (transformer): Sequential(\n",
      "          (0): TransformerBlock(\n",
      "            (norm1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=120, out_features=120, bias=True)\n",
      "            )\n",
      "            (norm2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Sequential(\n",
      "              (0): Linear(in_features=120, out_features=480, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Linear(in_features=480, out_features=120, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (1): TransformerBlock(\n",
      "            (norm1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=120, out_features=120, bias=True)\n",
      "            )\n",
      "            (norm2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Sequential(\n",
      "              (0): Linear(in_features=120, out_features=480, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Linear(in_features=480, out_features=120, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (2): TransformerBlock(\n",
      "            (norm1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=120, out_features=120, bias=True)\n",
      "            )\n",
      "            (norm2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Sequential(\n",
      "              (0): Linear(in_features=120, out_features=480, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Linear(in_features=480, out_features=120, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (3): TransformerBlock(\n",
      "            (norm1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=120, out_features=120, bias=True)\n",
      "            )\n",
      "            (norm2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Sequential(\n",
      "              (0): Linear(in_features=120, out_features=480, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Linear(in_features=480, out_features=120, bias=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (fusion): ConvBlock(\n",
      "          (conv): Conv2d(120, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): ConvBlock(\n",
      "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (1): MobileViTBlock(\n",
      "        (local_rep): Sequential(\n",
      "          (0): ConvBlock(\n",
      "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (1): ConvBlock(\n",
      "            (conv): Conv2d(96, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "        (transformer): Sequential(\n",
      "          (0): TransformerBlock(\n",
      "            (norm1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=144, out_features=144, bias=True)\n",
      "            )\n",
      "            (norm2): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Sequential(\n",
      "              (0): Linear(in_features=144, out_features=576, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Linear(in_features=576, out_features=144, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (1): TransformerBlock(\n",
      "            (norm1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=144, out_features=144, bias=True)\n",
      "            )\n",
      "            (norm2): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Sequential(\n",
      "              (0): Linear(in_features=144, out_features=576, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Linear(in_features=576, out_features=144, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (2): TransformerBlock(\n",
      "            (norm1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=144, out_features=144, bias=True)\n",
      "            )\n",
      "            (norm2): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Sequential(\n",
      "              (0): Linear(in_features=144, out_features=576, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Linear(in_features=576, out_features=144, bias=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (fusion): ConvBlock(\n",
      "          (conv): Conv2d(144, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (fc): Linear(in_features=96, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 打印模型结构\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of parameters: 2326266\n"
     ]
    }
   ],
   "source": [
    "# 打印参数总量\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\nNumber of parameters: {num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于每一层，打印输出形状, 以及参数数量, 以及dtype\n",
    "for name, param in model.named_parameters():\n",
    "    # print(f\"{name}: {param.shape} - {param.numel()} parameters - {param.dtype}\")\n",
    "    # if name不包含weight或bias，那么这是一个非模型参数，打印\n",
    "    if 'weight' not in name and 'bias' not in name:\n",
    "        print(param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileViT(\n",
      "  (conv1): ConvBNAct(\n",
      "    (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (mv2): ModuleList(\n",
      "    (0): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNAct(\n",
      "          (conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (1): ConvBNAct(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (2): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNAct(\n",
      "          (conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (1): ConvBNAct(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (2): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNAct(\n",
      "          (conv): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (1): ConvBNAct(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNAct(\n",
      "          (conv): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (1): ConvBNAct(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNAct(\n",
      "          (conv): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (1): ConvBNAct(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (2): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNAct(\n",
      "          (conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (1): ConvBNAct(\n",
      "          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNAct(\n",
      "          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (1): ConvBNAct(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (2): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mvit): ModuleList(\n",
      "    (0): MobileViTBlock(\n",
      "      (conv1): ConvBNAct(\n",
      "        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNAct(\n",
      "        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (transformer): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (1): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (3): Linear(in_features=64, out_features=128, bias=True)\n",
      "          (4): SiLU()\n",
      "          (5): Linear(in_features=128, out_features=64, bias=True)\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (1): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (3): Linear(in_features=64, out_features=128, bias=True)\n",
      "          (4): SiLU()\n",
      "          (5): Linear(in_features=128, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (conv3): ConvBNAct(\n",
      "        (conv): Conv2d(64, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (1): MobileViTBlock(\n",
      "      (conv1): ConvBNAct(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNAct(\n",
      "        (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (transformer): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
      "          (1): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=80, out_features=80, bias=True)\n",
      "          )\n",
      "          (2): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
      "          (3): Linear(in_features=80, out_features=320, bias=True)\n",
      "          (4): SiLU()\n",
      "          (5): Linear(in_features=320, out_features=80, bias=True)\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
      "          (1): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=80, out_features=80, bias=True)\n",
      "          )\n",
      "          (2): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
      "          (3): Linear(in_features=80, out_features=320, bias=True)\n",
      "          (4): SiLU()\n",
      "          (5): Linear(in_features=320, out_features=80, bias=True)\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
      "          (1): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=80, out_features=80, bias=True)\n",
      "          )\n",
      "          (2): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
      "          (3): Linear(in_features=80, out_features=320, bias=True)\n",
      "          (4): SiLU()\n",
      "          (5): Linear(in_features=320, out_features=80, bias=True)\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
      "          (1): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=80, out_features=80, bias=True)\n",
      "          )\n",
      "          (2): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
      "          (3): Linear(in_features=80, out_features=320, bias=True)\n",
      "          (4): SiLU()\n",
      "          (5): Linear(in_features=320, out_features=80, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (conv3): ConvBNAct(\n",
      "        (conv): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (2): MobileViTBlock(\n",
      "      (conv1): ConvBNAct(\n",
      "        (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNAct(\n",
      "        (conv): Conv2d(80, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (transformer): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (1): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=96, out_features=96, bias=True)\n",
      "          )\n",
      "          (2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
      "          (4): SiLU()\n",
      "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (1): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=96, out_features=96, bias=True)\n",
      "          )\n",
      "          (2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
      "          (4): SiLU()\n",
      "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (1): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=96, out_features=96, bias=True)\n",
      "          )\n",
      "          (2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
      "          (4): SiLU()\n",
      "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (conv3): ConvBNAct(\n",
      "        (conv): Conv2d(96, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv2): ConvBNAct(\n",
      "    (conv): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=320, out_features=12, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConvBNAct(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, groups=1):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, groups=groups, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, expansion_factor=4):\n",
    "        super().__init__()\n",
    "        hidden_dim = in_channels * expansion_factor\n",
    "        self.use_res_connect = stride == 1 and in_channels == out_channels\n",
    "\n",
    "        layers = []\n",
    "        if expansion_factor != 1:\n",
    "            layers.append(ConvBNAct(in_channels, hidden_dim, kernel_size=1))\n",
    "        layers.extend([\n",
    "            ConvBNAct(hidden_dim, hidden_dim, stride=stride, groups=hidden_dim),\n",
    "            nn.Conv2d(hidden_dim, out_channels, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        ])\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "class MobileViTBlock(nn.Module):\n",
    "    def __init__(self, dim, depth, channel, kernel_size, patch_size, mlp_dim):\n",
    "        super().__init__()\n",
    "        self.ph, self.pw = patch_size\n",
    "\n",
    "        self.conv1 = ConvBNAct(channel, channel, kernel_size)\n",
    "        self.conv2 = ConvBNAct(channel, dim, kernel_size=1)\n",
    "\n",
    "        self.transformer = nn.Sequential(*[\n",
    "            nn.Sequential(\n",
    "                nn.LayerNorm(dim),\n",
    "                nn.MultiheadAttention(dim, 4, batch_first=True),\n",
    "                nn.LayerNorm(dim),\n",
    "                nn.Linear(dim, mlp_dim),\n",
    "                nn.SiLU(),\n",
    "                nn.Linear(mlp_dim, dim),\n",
    "            ) for _ in range(depth)\n",
    "        ])\n",
    "\n",
    "        self.conv3 = ConvBNAct(dim, channel, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x.clone()\n",
    "\n",
    "        # Local representation\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        # Global representations\n",
    "        _, _, h, w = x.shape\n",
    "        x = x.reshape(x.shape[0], x.shape[1], h // self.ph, self.ph, w // self.pw, self.pw)\n",
    "        x = x.permute(0, 2, 4, 1, 3, 5).contiguous()\n",
    "        x = x.reshape(x.shape[0], h // self.ph * w // self.pw, -1)\n",
    "\n",
    "        # Transformer blocks\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        # Fusion of Local and Global Representations\n",
    "        x = x.reshape(x.shape[0], h // self.ph, w // self.pw, -1, self.ph, self.pw)\n",
    "        x = x.permute(0, 3, 1, 4, 2, 5).contiguous()\n",
    "        x = x.reshape(x.shape[0], -1, h, w)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        return x + y\n",
    "\n",
    "class MobileViT(nn.Module):\n",
    "    def __init__(self, image_size, dims, channels, num_classes, depths=[2, 4, 3], expansion=4):\n",
    "        super().__init__()\n",
    "        ih, iw = image_size\n",
    "        ph, pw = ih // 32, iw // 32\n",
    "\n",
    "        self.conv1 = ConvBNAct(3, channels[0], stride=2)\n",
    "\n",
    "        self.mv2 = nn.ModuleList([])\n",
    "        self.mv2.append(InvertedResidual(channels[0], channels[1], 1, expansion))\n",
    "        self.mv2.append(InvertedResidual(channels[1], channels[2], 2, expansion))\n",
    "        self.mv2.append(InvertedResidual(channels[2], channels[3], 1, expansion))\n",
    "        self.mv2.append(InvertedResidual(channels[2], channels[3], 1, expansion))   # Repeat\n",
    "        self.mv2.append(InvertedResidual(channels[3], channels[4], 2, expansion))\n",
    "        self.mv2.append(InvertedResidual(channels[5], channels[6], 2, expansion))\n",
    "        self.mv2.append(InvertedResidual(channels[7], channels[8], 2, expansion))\n",
    "\n",
    "        self.mvit = nn.ModuleList([])\n",
    "        self.mvit.append(MobileViTBlock(dims[0], depths[0], channels[5], 3, (2, 2), dims[0]*2))\n",
    "        self.mvit.append(MobileViTBlock(dims[1], depths[1], channels[7], 3, (2, 2), dims[1]*4))\n",
    "        self.mvit.append(MobileViTBlock(dims[2], depths[2], channels[9], 3, (2, 2), dims[2]*4))\n",
    "\n",
    "        self.conv2 = ConvBNAct(channels[-2], channels[-1], 1)\n",
    "\n",
    "        self.pool = nn.AvgPool2d(ih//32, 1)\n",
    "        self.fc = nn.Linear(channels[-1], num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.mv2[0](x)\n",
    "        x = self.mv2[1](x)\n",
    "        x = self.mv2[2](x)\n",
    "        x = self.mv2[3](x)      # Repeat\n",
    "\n",
    "        y = self.mv2[4](x)\n",
    "        x = self.mvit[0](y)\n",
    "        x = x + y\n",
    "\n",
    "        y = self.mv2[5](x)\n",
    "        x = self.mvit[1](y)\n",
    "        x = x + y\n",
    "\n",
    "        y = self.mv2[6](x)\n",
    "        x = self.mvit[2](y)\n",
    "        x = x + y\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(x).view(-1, x.shape[1])\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 创建适用于 224x224 输入和 12 类别的 MobileViT 模型\n",
    "def mobilevit_xxs(num_classes=12):\n",
    "    dims = [64, 80, 96]\n",
    "    channels = [16, 16, 24, 24, 48, 48, 64, 64, 80, 80, 320]\n",
    "    return MobileViT((224, 224), dims, channels, num_classes)\n",
    "\n",
    "# 实例化模型\n",
    "model = mobilevit_xxs()\n",
    "\n",
    "# 打印模型结构\n",
    "print(model)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.conv.weight: torch.Size([16, 3, 3, 3]) - 432 parameters - torch.float32\n",
      "conv1.bn.weight: torch.Size([16]) - 16 parameters - torch.float32\n",
      "conv1.bn.bias: torch.Size([16]) - 16 parameters - torch.float32\n",
      "mv2.0.conv.0.conv.weight: torch.Size([64, 16, 1, 1]) - 1024 parameters - torch.float32\n",
      "mv2.0.conv.0.bn.weight: torch.Size([64]) - 64 parameters - torch.float32\n",
      "mv2.0.conv.0.bn.bias: torch.Size([64]) - 64 parameters - torch.float32\n",
      "mv2.0.conv.1.conv.weight: torch.Size([64, 1, 3, 3]) - 576 parameters - torch.float32\n",
      "mv2.0.conv.1.bn.weight: torch.Size([64]) - 64 parameters - torch.float32\n",
      "mv2.0.conv.1.bn.bias: torch.Size([64]) - 64 parameters - torch.float32\n",
      "mv2.0.conv.2.weight: torch.Size([16, 64, 1, 1]) - 1024 parameters - torch.float32\n",
      "mv2.0.conv.3.weight: torch.Size([16]) - 16 parameters - torch.float32\n",
      "mv2.0.conv.3.bias: torch.Size([16]) - 16 parameters - torch.float32\n",
      "mv2.1.conv.0.conv.weight: torch.Size([64, 16, 1, 1]) - 1024 parameters - torch.float32\n",
      "mv2.1.conv.0.bn.weight: torch.Size([64]) - 64 parameters - torch.float32\n",
      "mv2.1.conv.0.bn.bias: torch.Size([64]) - 64 parameters - torch.float32\n",
      "mv2.1.conv.1.conv.weight: torch.Size([64, 1, 3, 3]) - 576 parameters - torch.float32\n",
      "mv2.1.conv.1.bn.weight: torch.Size([64]) - 64 parameters - torch.float32\n",
      "mv2.1.conv.1.bn.bias: torch.Size([64]) - 64 parameters - torch.float32\n",
      "mv2.1.conv.2.weight: torch.Size([24, 64, 1, 1]) - 1536 parameters - torch.float32\n",
      "mv2.1.conv.3.weight: torch.Size([24]) - 24 parameters - torch.float32\n",
      "mv2.1.conv.3.bias: torch.Size([24]) - 24 parameters - torch.float32\n",
      "mv2.2.conv.0.conv.weight: torch.Size([96, 24, 1, 1]) - 2304 parameters - torch.float32\n",
      "mv2.2.conv.0.bn.weight: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mv2.2.conv.0.bn.bias: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mv2.2.conv.1.conv.weight: torch.Size([96, 1, 3, 3]) - 864 parameters - torch.float32\n",
      "mv2.2.conv.1.bn.weight: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mv2.2.conv.1.bn.bias: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mv2.2.conv.2.weight: torch.Size([24, 96, 1, 1]) - 2304 parameters - torch.float32\n",
      "mv2.2.conv.3.weight: torch.Size([24]) - 24 parameters - torch.float32\n",
      "mv2.2.conv.3.bias: torch.Size([24]) - 24 parameters - torch.float32\n",
      "mv2.3.conv.0.conv.weight: torch.Size([96, 24, 1, 1]) - 2304 parameters - torch.float32\n",
      "mv2.3.conv.0.bn.weight: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mv2.3.conv.0.bn.bias: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mv2.3.conv.1.conv.weight: torch.Size([96, 1, 3, 3]) - 864 parameters - torch.float32\n",
      "mv2.3.conv.1.bn.weight: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mv2.3.conv.1.bn.bias: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mv2.3.conv.2.weight: torch.Size([24, 96, 1, 1]) - 2304 parameters - torch.float32\n",
      "mv2.3.conv.3.weight: torch.Size([24]) - 24 parameters - torch.float32\n",
      "mv2.3.conv.3.bias: torch.Size([24]) - 24 parameters - torch.float32\n",
      "mv2.4.conv.0.conv.weight: torch.Size([96, 24, 1, 1]) - 2304 parameters - torch.float32\n",
      "mv2.4.conv.0.bn.weight: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mv2.4.conv.0.bn.bias: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mv2.4.conv.1.conv.weight: torch.Size([96, 1, 3, 3]) - 864 parameters - torch.float32\n",
      "mv2.4.conv.1.bn.weight: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mv2.4.conv.1.bn.bias: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mv2.4.conv.2.weight: torch.Size([48, 96, 1, 1]) - 4608 parameters - torch.float32\n",
      "mv2.4.conv.3.weight: torch.Size([48]) - 48 parameters - torch.float32\n",
      "mv2.4.conv.3.bias: torch.Size([48]) - 48 parameters - torch.float32\n",
      "mv2.5.conv.0.conv.weight: torch.Size([192, 48, 1, 1]) - 9216 parameters - torch.float32\n",
      "mv2.5.conv.0.bn.weight: torch.Size([192]) - 192 parameters - torch.float32\n",
      "mv2.5.conv.0.bn.bias: torch.Size([192]) - 192 parameters - torch.float32\n",
      "mv2.5.conv.1.conv.weight: torch.Size([192, 1, 3, 3]) - 1728 parameters - torch.float32\n",
      "mv2.5.conv.1.bn.weight: torch.Size([192]) - 192 parameters - torch.float32\n",
      "mv2.5.conv.1.bn.bias: torch.Size([192]) - 192 parameters - torch.float32\n",
      "mv2.5.conv.2.weight: torch.Size([64, 192, 1, 1]) - 12288 parameters - torch.float32\n",
      "mv2.5.conv.3.weight: torch.Size([64]) - 64 parameters - torch.float32\n",
      "mv2.5.conv.3.bias: torch.Size([64]) - 64 parameters - torch.float32\n",
      "mv2.6.conv.0.conv.weight: torch.Size([256, 64, 1, 1]) - 16384 parameters - torch.float32\n",
      "mv2.6.conv.0.bn.weight: torch.Size([256]) - 256 parameters - torch.float32\n",
      "mv2.6.conv.0.bn.bias: torch.Size([256]) - 256 parameters - torch.float32\n",
      "mv2.6.conv.1.conv.weight: torch.Size([256, 1, 3, 3]) - 2304 parameters - torch.float32\n",
      "mv2.6.conv.1.bn.weight: torch.Size([256]) - 256 parameters - torch.float32\n",
      "mv2.6.conv.1.bn.bias: torch.Size([256]) - 256 parameters - torch.float32\n",
      "mv2.6.conv.2.weight: torch.Size([80, 256, 1, 1]) - 20480 parameters - torch.float32\n",
      "mv2.6.conv.3.weight: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mv2.6.conv.3.bias: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.0.conv1.conv.weight: torch.Size([48, 48, 3, 3]) - 20736 parameters - torch.float32\n",
      "mvit.0.conv1.bn.weight: torch.Size([48]) - 48 parameters - torch.float32\n",
      "mvit.0.conv1.bn.bias: torch.Size([48]) - 48 parameters - torch.float32\n",
      "mvit.0.conv2.conv.weight: torch.Size([64, 48, 1, 1]) - 3072 parameters - torch.float32\n",
      "mvit.0.conv2.bn.weight: torch.Size([64]) - 64 parameters - torch.float32\n",
      "mvit.0.conv2.bn.bias: torch.Size([64]) - 64 parameters - torch.float32\n",
      "mvit.0.transformer.0.0.weight: torch.Size([64]) - 64 parameters - torch.float32\n",
      "mvit.0.transformer.0.0.bias: torch.Size([64]) - 64 parameters - torch.float32\n",
      "mvit.0.transformer.0.1.in_proj_weight: torch.Size([192, 64]) - 12288 parameters - torch.float32\n",
      "mvit.0.transformer.0.1.in_proj_bias: torch.Size([192]) - 192 parameters - torch.float32\n",
      "mvit.0.transformer.0.1.out_proj.weight: torch.Size([64, 64]) - 4096 parameters - torch.float32\n",
      "mvit.0.transformer.0.1.out_proj.bias: torch.Size([64]) - 64 parameters - torch.float32\n",
      "mvit.0.transformer.0.2.weight: torch.Size([64]) - 64 parameters - torch.float32\n",
      "mvit.0.transformer.0.2.bias: torch.Size([64]) - 64 parameters - torch.float32\n",
      "mvit.0.transformer.0.3.weight: torch.Size([128, 64]) - 8192 parameters - torch.float32\n",
      "mvit.0.transformer.0.3.bias: torch.Size([128]) - 128 parameters - torch.float32\n",
      "mvit.0.transformer.0.5.weight: torch.Size([64, 128]) - 8192 parameters - torch.float32\n",
      "mvit.0.transformer.0.5.bias: torch.Size([64]) - 64 parameters - torch.float32\n",
      "mvit.0.transformer.1.0.weight: torch.Size([64]) - 64 parameters - torch.float32\n",
      "mvit.0.transformer.1.0.bias: torch.Size([64]) - 64 parameters - torch.float32\n",
      "mvit.0.transformer.1.1.in_proj_weight: torch.Size([192, 64]) - 12288 parameters - torch.float32\n",
      "mvit.0.transformer.1.1.in_proj_bias: torch.Size([192]) - 192 parameters - torch.float32\n",
      "mvit.0.transformer.1.1.out_proj.weight: torch.Size([64, 64]) - 4096 parameters - torch.float32\n",
      "mvit.0.transformer.1.1.out_proj.bias: torch.Size([64]) - 64 parameters - torch.float32\n",
      "mvit.0.transformer.1.2.weight: torch.Size([64]) - 64 parameters - torch.float32\n",
      "mvit.0.transformer.1.2.bias: torch.Size([64]) - 64 parameters - torch.float32\n",
      "mvit.0.transformer.1.3.weight: torch.Size([128, 64]) - 8192 parameters - torch.float32\n",
      "mvit.0.transformer.1.3.bias: torch.Size([128]) - 128 parameters - torch.float32\n",
      "mvit.0.transformer.1.5.weight: torch.Size([64, 128]) - 8192 parameters - torch.float32\n",
      "mvit.0.transformer.1.5.bias: torch.Size([64]) - 64 parameters - torch.float32\n",
      "mvit.0.conv3.conv.weight: torch.Size([48, 64, 1, 1]) - 3072 parameters - torch.float32\n",
      "mvit.0.conv3.bn.weight: torch.Size([48]) - 48 parameters - torch.float32\n",
      "mvit.0.conv3.bn.bias: torch.Size([48]) - 48 parameters - torch.float32\n",
      "mvit.1.conv1.conv.weight: torch.Size([64, 64, 3, 3]) - 36864 parameters - torch.float32\n",
      "mvit.1.conv1.bn.weight: torch.Size([64]) - 64 parameters - torch.float32\n",
      "mvit.1.conv1.bn.bias: torch.Size([64]) - 64 parameters - torch.float32\n",
      "mvit.1.conv2.conv.weight: torch.Size([80, 64, 1, 1]) - 5120 parameters - torch.float32\n",
      "mvit.1.conv2.bn.weight: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.1.conv2.bn.bias: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.1.transformer.0.0.weight: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.1.transformer.0.0.bias: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.1.transformer.0.1.in_proj_weight: torch.Size([240, 80]) - 19200 parameters - torch.float32\n",
      "mvit.1.transformer.0.1.in_proj_bias: torch.Size([240]) - 240 parameters - torch.float32\n",
      "mvit.1.transformer.0.1.out_proj.weight: torch.Size([80, 80]) - 6400 parameters - torch.float32\n",
      "mvit.1.transformer.0.1.out_proj.bias: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.1.transformer.0.2.weight: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.1.transformer.0.2.bias: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.1.transformer.0.3.weight: torch.Size([320, 80]) - 25600 parameters - torch.float32\n",
      "mvit.1.transformer.0.3.bias: torch.Size([320]) - 320 parameters - torch.float32\n",
      "mvit.1.transformer.0.5.weight: torch.Size([80, 320]) - 25600 parameters - torch.float32\n",
      "mvit.1.transformer.0.5.bias: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.1.transformer.1.0.weight: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.1.transformer.1.0.bias: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.1.transformer.1.1.in_proj_weight: torch.Size([240, 80]) - 19200 parameters - torch.float32\n",
      "mvit.1.transformer.1.1.in_proj_bias: torch.Size([240]) - 240 parameters - torch.float32\n",
      "mvit.1.transformer.1.1.out_proj.weight: torch.Size([80, 80]) - 6400 parameters - torch.float32\n",
      "mvit.1.transformer.1.1.out_proj.bias: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.1.transformer.1.2.weight: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.1.transformer.1.2.bias: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.1.transformer.1.3.weight: torch.Size([320, 80]) - 25600 parameters - torch.float32\n",
      "mvit.1.transformer.1.3.bias: torch.Size([320]) - 320 parameters - torch.float32\n",
      "mvit.1.transformer.1.5.weight: torch.Size([80, 320]) - 25600 parameters - torch.float32\n",
      "mvit.1.transformer.1.5.bias: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.1.transformer.2.0.weight: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.1.transformer.2.0.bias: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.1.transformer.2.1.in_proj_weight: torch.Size([240, 80]) - 19200 parameters - torch.float32\n",
      "mvit.1.transformer.2.1.in_proj_bias: torch.Size([240]) - 240 parameters - torch.float32\n",
      "mvit.1.transformer.2.1.out_proj.weight: torch.Size([80, 80]) - 6400 parameters - torch.float32\n",
      "mvit.1.transformer.2.1.out_proj.bias: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.1.transformer.2.2.weight: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.1.transformer.2.2.bias: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.1.transformer.2.3.weight: torch.Size([320, 80]) - 25600 parameters - torch.float32\n",
      "mvit.1.transformer.2.3.bias: torch.Size([320]) - 320 parameters - torch.float32\n",
      "mvit.1.transformer.2.5.weight: torch.Size([80, 320]) - 25600 parameters - torch.float32\n",
      "mvit.1.transformer.2.5.bias: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.1.transformer.3.0.weight: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.1.transformer.3.0.bias: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.1.transformer.3.1.in_proj_weight: torch.Size([240, 80]) - 19200 parameters - torch.float32\n",
      "mvit.1.transformer.3.1.in_proj_bias: torch.Size([240]) - 240 parameters - torch.float32\n",
      "mvit.1.transformer.3.1.out_proj.weight: torch.Size([80, 80]) - 6400 parameters - torch.float32\n",
      "mvit.1.transformer.3.1.out_proj.bias: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.1.transformer.3.2.weight: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.1.transformer.3.2.bias: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.1.transformer.3.3.weight: torch.Size([320, 80]) - 25600 parameters - torch.float32\n",
      "mvit.1.transformer.3.3.bias: torch.Size([320]) - 320 parameters - torch.float32\n",
      "mvit.1.transformer.3.5.weight: torch.Size([80, 320]) - 25600 parameters - torch.float32\n",
      "mvit.1.transformer.3.5.bias: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.1.conv3.conv.weight: torch.Size([64, 80, 1, 1]) - 5120 parameters - torch.float32\n",
      "mvit.1.conv3.bn.weight: torch.Size([64]) - 64 parameters - torch.float32\n",
      "mvit.1.conv3.bn.bias: torch.Size([64]) - 64 parameters - torch.float32\n",
      "mvit.2.conv1.conv.weight: torch.Size([80, 80, 3, 3]) - 57600 parameters - torch.float32\n",
      "mvit.2.conv1.bn.weight: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.2.conv1.bn.bias: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.2.conv2.conv.weight: torch.Size([96, 80, 1, 1]) - 7680 parameters - torch.float32\n",
      "mvit.2.conv2.bn.weight: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mvit.2.conv2.bn.bias: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mvit.2.transformer.0.0.weight: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mvit.2.transformer.0.0.bias: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mvit.2.transformer.0.1.in_proj_weight: torch.Size([288, 96]) - 27648 parameters - torch.float32\n",
      "mvit.2.transformer.0.1.in_proj_bias: torch.Size([288]) - 288 parameters - torch.float32\n",
      "mvit.2.transformer.0.1.out_proj.weight: torch.Size([96, 96]) - 9216 parameters - torch.float32\n",
      "mvit.2.transformer.0.1.out_proj.bias: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mvit.2.transformer.0.2.weight: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mvit.2.transformer.0.2.bias: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mvit.2.transformer.0.3.weight: torch.Size([384, 96]) - 36864 parameters - torch.float32\n",
      "mvit.2.transformer.0.3.bias: torch.Size([384]) - 384 parameters - torch.float32\n",
      "mvit.2.transformer.0.5.weight: torch.Size([96, 384]) - 36864 parameters - torch.float32\n",
      "mvit.2.transformer.0.5.bias: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mvit.2.transformer.1.0.weight: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mvit.2.transformer.1.0.bias: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mvit.2.transformer.1.1.in_proj_weight: torch.Size([288, 96]) - 27648 parameters - torch.float32\n",
      "mvit.2.transformer.1.1.in_proj_bias: torch.Size([288]) - 288 parameters - torch.float32\n",
      "mvit.2.transformer.1.1.out_proj.weight: torch.Size([96, 96]) - 9216 parameters - torch.float32\n",
      "mvit.2.transformer.1.1.out_proj.bias: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mvit.2.transformer.1.2.weight: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mvit.2.transformer.1.2.bias: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mvit.2.transformer.1.3.weight: torch.Size([384, 96]) - 36864 parameters - torch.float32\n",
      "mvit.2.transformer.1.3.bias: torch.Size([384]) - 384 parameters - torch.float32\n",
      "mvit.2.transformer.1.5.weight: torch.Size([96, 384]) - 36864 parameters - torch.float32\n",
      "mvit.2.transformer.1.5.bias: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mvit.2.transformer.2.0.weight: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mvit.2.transformer.2.0.bias: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mvit.2.transformer.2.1.in_proj_weight: torch.Size([288, 96]) - 27648 parameters - torch.float32\n",
      "mvit.2.transformer.2.1.in_proj_bias: torch.Size([288]) - 288 parameters - torch.float32\n",
      "mvit.2.transformer.2.1.out_proj.weight: torch.Size([96, 96]) - 9216 parameters - torch.float32\n",
      "mvit.2.transformer.2.1.out_proj.bias: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mvit.2.transformer.2.2.weight: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mvit.2.transformer.2.2.bias: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mvit.2.transformer.2.3.weight: torch.Size([384, 96]) - 36864 parameters - torch.float32\n",
      "mvit.2.transformer.2.3.bias: torch.Size([384]) - 384 parameters - torch.float32\n",
      "mvit.2.transformer.2.5.weight: torch.Size([96, 384]) - 36864 parameters - torch.float32\n",
      "mvit.2.transformer.2.5.bias: torch.Size([96]) - 96 parameters - torch.float32\n",
      "mvit.2.conv3.conv.weight: torch.Size([80, 96, 1, 1]) - 7680 parameters - torch.float32\n",
      "mvit.2.conv3.bn.weight: torch.Size([80]) - 80 parameters - torch.float32\n",
      "mvit.2.conv3.bn.bias: torch.Size([80]) - 80 parameters - torch.float32\n",
      "conv2.conv.weight: torch.Size([320, 80, 1, 1]) - 25600 parameters - torch.float32\n",
      "conv2.bn.weight: torch.Size([320]) - 320 parameters - torch.float32\n",
      "conv2.bn.bias: torch.Size([320]) - 320 parameters - torch.float32\n",
      "fc.weight: torch.Size([12, 320]) - 3840 parameters - torch.float32\n",
      "fc.bias: torch.Size([12]) - 12 parameters - torch.float32\n"
     ]
    }
   ],
   "source": [
    "# 对于每一层，打印输出形状, 以及参数数量, 以及dtype\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.shape} - {param.numel()} parameters - {param.dtype}\")\n",
    "    # # if name不包含weight或bias，那么这是一个非模型参数，打印\n",
    "    # if 'weight' not in name and 'bias' not in name:\n",
    "    #     print(param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileViT(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (mn): ModuleList(\n",
      "    (0): MobileViTBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (transformer): Sequential(\n",
      "        (0): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=96, out_features=96, bias=True)\n",
      "        )\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "        (3): Linear(in_features=96, out_features=192, bias=True)\n",
      "        (4): GELU(approximate='none')\n",
      "        (5): Dropout(p=0.0, inplace=False)\n",
      "        (6): Linear(in_features=192, out_features=96, bias=True)\n",
      "        (7): Dropout(p=0.0, inplace=False)\n",
      "        (8): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "        (9): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=96, out_features=96, bias=True)\n",
      "        )\n",
      "        (10): Dropout(p=0.0, inplace=False)\n",
      "        (11): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "        (12): Linear(in_features=96, out_features=192, bias=True)\n",
      "        (13): GELU(approximate='none')\n",
      "        (14): Dropout(p=0.0, inplace=False)\n",
      "        (15): Linear(in_features=192, out_features=96, bias=True)\n",
      "        (16): Dropout(p=0.0, inplace=False)\n",
      "        (17): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (conv3): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (2): MobileViTBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (transformer): Sequential(\n",
      "        (0): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=120, out_features=120, bias=True)\n",
      "        )\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "        (3): Linear(in_features=120, out_features=240, bias=True)\n",
      "        (4): GELU(approximate='none')\n",
      "        (5): Dropout(p=0.0, inplace=False)\n",
      "        (6): Linear(in_features=240, out_features=120, bias=True)\n",
      "        (7): Dropout(p=0.0, inplace=False)\n",
      "        (8): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "        (9): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=120, out_features=120, bias=True)\n",
      "        )\n",
      "        (10): Dropout(p=0.0, inplace=False)\n",
      "        (11): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "        (12): Linear(in_features=120, out_features=240, bias=True)\n",
      "        (13): GELU(approximate='none')\n",
      "        (14): Dropout(p=0.0, inplace=False)\n",
      "        (15): Linear(in_features=240, out_features=120, bias=True)\n",
      "        (16): Dropout(p=0.0, inplace=False)\n",
      "        (17): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "        (18): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=120, out_features=120, bias=True)\n",
      "        )\n",
      "        (19): Dropout(p=0.0, inplace=False)\n",
      "        (20): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "        (21): Linear(in_features=120, out_features=240, bias=True)\n",
      "        (22): GELU(approximate='none')\n",
      "        (23): Dropout(p=0.0, inplace=False)\n",
      "        (24): Linear(in_features=240, out_features=120, bias=True)\n",
      "        (25): Dropout(p=0.0, inplace=False)\n",
      "        (26): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "        (27): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=120, out_features=120, bias=True)\n",
      "        )\n",
      "        (28): Dropout(p=0.0, inplace=False)\n",
      "        (29): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "        (30): Linear(in_features=120, out_features=240, bias=True)\n",
      "        (31): GELU(approximate='none')\n",
      "        (32): Dropout(p=0.0, inplace=False)\n",
      "        (33): Linear(in_features=240, out_features=120, bias=True)\n",
      "        (34): Dropout(p=0.0, inplace=False)\n",
      "        (35): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (conv3): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (3): Conv2d(32, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (4): MobileViTBlock(\n",
      "      (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (transformer): Sequential(\n",
      "        (0): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=144, out_features=144, bias=True)\n",
      "        )\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "        (3): Linear(in_features=144, out_features=288, bias=True)\n",
      "        (4): GELU(approximate='none')\n",
      "        (5): Dropout(p=0.0, inplace=False)\n",
      "        (6): Linear(in_features=288, out_features=144, bias=True)\n",
      "        (7): Dropout(p=0.0, inplace=False)\n",
      "        (8): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "        (9): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=144, out_features=144, bias=True)\n",
      "        )\n",
      "        (10): Dropout(p=0.0, inplace=False)\n",
      "        (11): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "        (12): Linear(in_features=144, out_features=288, bias=True)\n",
      "        (13): GELU(approximate='none')\n",
      "        (14): Dropout(p=0.0, inplace=False)\n",
      "        (15): Linear(in_features=288, out_features=144, bias=True)\n",
      "        (16): Dropout(p=0.0, inplace=False)\n",
      "        (17): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "        (18): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=144, out_features=144, bias=True)\n",
      "        )\n",
      "        (19): Dropout(p=0.0, inplace=False)\n",
      "        (20): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "        (21): Linear(in_features=144, out_features=288, bias=True)\n",
      "        (22): GELU(approximate='none')\n",
      "        (23): Dropout(p=0.0, inplace=False)\n",
      "        (24): Linear(in_features=288, out_features=144, bias=True)\n",
      "        (25): Dropout(p=0.0, inplace=False)\n",
      "        (26): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (conv3): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (conv2): Conv2d(48, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=12, bias=True)\n",
      ")\n",
      "Total parameters: 466,364\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange\n",
    "\n",
    "class MobileViTBlock(nn.Module):\n",
    "    def __init__(self, dim, depth, channel, kernel_size, patch_size, mlp_dim, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.ph, self.pw = patch_size\n",
    "\n",
    "        self.conv1 = nn.Conv2d(channel, channel, kernel_size=kernel_size, padding=kernel_size//2)\n",
    "        self.conv2 = nn.Conv2d(channel, dim, kernel_size=1)\n",
    "\n",
    "        self.transformer = nn.Sequential(*[\n",
    "            nn.MultiheadAttention(dim, 4, dropout=dropout),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, mlp_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mlp_dim, dim),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.LayerNorm(dim)\n",
    "        ] * depth)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(dim, channel, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x.clone()\n",
    "\n",
    "        # Local representations\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        # Global representations\n",
    "        _, _, h, w = x.shape\n",
    "        x = rearrange(x, 'b d (h ph) (w pw) -> b (h w) (ph pw d)', ph=self.ph, pw=self.pw)\n",
    "        x = self.transformer(x, x, x)[0]\n",
    "        x = rearrange(x, 'b (h w) (ph pw d) -> b d (h ph) (w pw)', h=h//self.ph, w=w//self.pw, ph=self.ph, pw=self.pw)\n",
    "\n",
    "        # Fusion\n",
    "        x = self.conv3(x)\n",
    "        x = x + y\n",
    "\n",
    "        return x\n",
    "\n",
    "class MobileViT(nn.Module):\n",
    "    def __init__(self, image_size, dims, channels, num_classes, depths, kernel_size, patch_size):\n",
    "        super().__init__()\n",
    "        ih, iw = image_size\n",
    "        ph, pw = patch_size\n",
    "        assert ih % ph == 0 and iw % pw == 0\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, channels[0], kernel_size=3, padding=1)\n",
    "        self.mn = nn.ModuleList([])\n",
    "\n",
    "        for i in range(len(depths)):\n",
    "            self.mn.append(MobileViTBlock(dims[i], depths[i], channels[i], kernel_size, patch_size, dims[i]*2))\n",
    "            if i < len(depths)-1:\n",
    "                self.mn.append(nn.Conv2d(channels[i], channels[i+1], kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "        self.conv2 = nn.Conv2d(channels[-1], 512, kernel_size=1)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        for layer in self.mn:\n",
    "            x = layer(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 模型配置\n",
    "image_size = (224, 224)\n",
    "dims = [96, 120, 144]\n",
    "channels = [16, 32, 48, 48]\n",
    "num_classes = 12\n",
    "depths = [2, 4, 3]\n",
    "kernel_size = 3\n",
    "patch_size = (2, 2)\n",
    "\n",
    "# 创建模型\n",
    "model = MobileViT(image_size, dims, channels, num_classes, depths, kernel_size, patch_size)\n",
    "\n",
    "# 打印模型结构\n",
    "print(model)\n",
    "\n",
    "# 计算模型参数量\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of parameters: 466364\n"
     ]
    }
   ],
   "source": [
    "# 模型总数\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\nNumber of parameters: {num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2(\n",
      "  (features): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): Sequential(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=1280, out_features=12, bias=True)\n",
      "  )\n",
      ")\n",
      "Total parameters: 2,239,244\n",
      "Output shape: torch.Size([1, 12])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def conv_bn(inp, oup, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "\n",
    "def conv_1x1_bn(inp, oup):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expand_ratio):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        hidden_dim = round(inp * expand_ratio)\n",
    "        self.use_res_connect = self.stride == 1 and inp == oup\n",
    "\n",
    "        if expand_ratio == 1:\n",
    "            self.conv = nn.Sequential(\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                # pw\n",
    "                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, num_classes=12, input_size=224, width_mult=1.):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        block = InvertedResidual\n",
    "        input_channel = 32\n",
    "        last_channel = 1280\n",
    "        interverted_residual_setting = [\n",
    "            # t, c, n, s\n",
    "            [1, 16, 1, 1],\n",
    "            [6, 24, 2, 2],\n",
    "            [6, 32, 3, 2],\n",
    "            [6, 64, 4, 2],\n",
    "            [6, 96, 3, 1],\n",
    "            [6, 160, 3, 2],\n",
    "            [6, 320, 1, 1],\n",
    "        ]\n",
    "\n",
    "        # building first layer\n",
    "        assert input_size % 32 == 0\n",
    "        input_channel = int(input_channel * width_mult)\n",
    "        self.last_channel = int(last_channel * width_mult) if width_mult > 1.0 else last_channel\n",
    "        self.features = [conv_bn(3, input_channel, 2)]\n",
    "        # building inverted residual blocks\n",
    "        for t, c, n, s in interverted_residual_setting:\n",
    "            output_channel = int(c * width_mult)\n",
    "            for i in range(n):\n",
    "                if i == 0:\n",
    "                    self.features.append(block(input_channel, output_channel, s, expand_ratio=t))\n",
    "                else:\n",
    "                    self.features.append(block(input_channel, output_channel, 1, expand_ratio=t))\n",
    "                input_channel = output_channel\n",
    "        # building last several layers\n",
    "        self.features.append(conv_1x1_bn(input_channel, self.last_channel))\n",
    "        # make it nn.Sequential\n",
    "        self.features = nn.Sequential(*self.features)\n",
    "\n",
    "        # building classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(self.last_channel, num_classes),\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.mean(3).mean(2)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "# 创建模型\n",
    "model = MobileNetV2(num_classes=12, input_size=224)\n",
    "\n",
    "# 打印模型结构\n",
    "print(model)\n",
    "\n",
    "# 计算模型参数量\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "\n",
    "# 测试模型\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "output = model(x)\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "revision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
