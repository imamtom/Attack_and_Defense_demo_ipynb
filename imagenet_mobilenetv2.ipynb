{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([32, 3, 224, 224])\n",
      "Value range: [-2.12, 2.64]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class ImagenetteDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(os.listdir(root_dir))\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "        self.images = self._load_images()\n",
    "\n",
    "    def _load_images(self):\n",
    "        images = []\n",
    "        for cls_name in self.classes:\n",
    "            cls_dir = os.path.join(self.root_dir, cls_name)\n",
    "            for img_name in os.listdir(cls_dir):\n",
    "                images.append((os.path.join(cls_dir, img_name), self.class_to_idx[cls_name]))\n",
    "        return images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.images[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# 定义预处理步骤\n",
    "def get_transform(is_train=True):\n",
    "    # ImageNet数据集的均值和标准差\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    \n",
    "    if is_train:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "    else:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "    \n",
    "    return transform\n",
    "\n",
    "# 使用示例\n",
    "train_transform = get_transform(is_train=True)\n",
    "val_transform = get_transform(is_train=False)\n",
    "\n",
    "# 假设您的Imagenette数据集路径\n",
    "train_dataset = ImagenetteDataset(root_dir='/scratch/wenjie/imagenette2-320/train', transform=train_transform)\n",
    "val_dataset = ImagenetteDataset(root_dir='/scratch/wenjie/imagenette2-320/val', transform=val_transform)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# 打印一个批次的形状和值范围\n",
    "for images, labels in train_loader:\n",
    "    print(f\"Batch shape: {images.shape}\")\n",
    "    print(f\"Value range: [{images.min():.2f}, {images.max():.2f}]\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/wenjie/anaconda3/envs/revision/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/scratch/wenjie/anaconda3/envs/revision/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# MobileNetV2, 用来训练ImageNet12数据集\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 加载预训练的 MobileNetV2 模型\n",
    "model = models.mobilenet_v2(pretrained=False)\n",
    "# 修改最后的全连接层以输出 12 个类别\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_ftrs, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在gpu上训练\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 2.1903\n",
      "Epoch 1, Test Accuracy: 36.968152866242036%\n",
      "Epoch: 1, Loss: 1.8983\n",
      "Epoch 2, Test Accuracy: 47.77070063694268%\n",
      "Epoch: 2, Loss: 1.6967\n",
      "Epoch 3, Test Accuracy: 54.72611464968153%\n",
      "Epoch: 3, Loss: 1.5630\n",
      "Epoch 4, Test Accuracy: 57.197452229299365%\n",
      "Epoch: 4, Loss: 1.4634\n",
      "Epoch 5, Test Accuracy: 54.955414012738856%\n",
      "Epoch: 5, Loss: 1.3681\n",
      "Epoch 6, Test Accuracy: 67.03184713375796%\n",
      "Epoch: 6, Loss: 1.2756\n",
      "Epoch 7, Test Accuracy: 68.94267515923566%\n",
      "Epoch: 7, Loss: 1.2061\n",
      "Epoch 8, Test Accuracy: 68.73885350318471%\n",
      "Epoch: 8, Loss: 1.1612\n",
      "Epoch 9, Test Accuracy: 71.43949044585987%\n",
      "Epoch: 9, Loss: 1.1113\n",
      "Epoch 10, Test Accuracy: 73.09554140127389%\n",
      "Epoch: 10, Loss: 1.0719\n",
      "Epoch 11, Test Accuracy: 76.28025477707007%\n",
      "Epoch: 11, Loss: 0.9991\n",
      "Epoch 12, Test Accuracy: 76.28025477707007%\n",
      "Epoch: 12, Loss: 0.9972\n",
      "Epoch 13, Test Accuracy: 77.07006369426752%\n",
      "Epoch: 13, Loss: 0.9809\n",
      "Epoch 14, Test Accuracy: 75.94904458598727%\n",
      "Epoch: 14, Loss: 0.9200\n",
      "Epoch 15, Test Accuracy: 77.91082802547771%\n",
      "Epoch: 15, Loss: 0.9171\n",
      "Epoch 16, Test Accuracy: 79.23566878980891%\n",
      "Epoch: 16, Loss: 0.8751\n",
      "Epoch 17, Test Accuracy: 80.12738853503184%\n",
      "Epoch: 17, Loss: 0.8754\n",
      "Epoch 18, Test Accuracy: 79.97452229299363%\n",
      "Epoch: 18, Loss: 0.8465\n",
      "Epoch 19, Test Accuracy: 80.9171974522293%\n",
      "Epoch: 19, Loss: 0.8316\n",
      "Epoch 20, Test Accuracy: 82.01273885350318%\n",
      "Epoch: 20, Loss: 0.8112\n",
      "Epoch 21, Test Accuracy: 83.18471337579618%\n",
      "Epoch: 21, Loss: 0.7684\n",
      "Epoch 22, Test Accuracy: 82.11464968152866%\n",
      "Epoch: 22, Loss: 0.7614\n",
      "Epoch 23, Test Accuracy: 81.27388535031847%\n",
      "Epoch: 23, Loss: 0.7565\n",
      "Epoch 24, Test Accuracy: 82.03821656050955%\n",
      "Epoch: 24, Loss: 0.7596\n",
      "Epoch 25, Test Accuracy: 82.5732484076433%\n",
      "Epoch: 25, Loss: 0.7475\n",
      "Epoch 26, Test Accuracy: 81.93630573248407%\n",
      "Epoch: 26, Loss: 0.7269\n",
      "Epoch 27, Test Accuracy: 84.5859872611465%\n",
      "Epoch: 27, Loss: 0.7147\n",
      "Epoch 28, Test Accuracy: 84.89171974522293%\n",
      "Epoch: 28, Loss: 0.6982\n",
      "Epoch 29, Test Accuracy: 83.1592356687898%\n",
      "Epoch: 29, Loss: 0.6831\n",
      "Epoch 30, Test Accuracy: 84.68789808917198%\n",
      "Epoch: 30, Loss: 0.6561\n",
      "Epoch 31, Test Accuracy: 85.45222929936305%\n",
      "Epoch: 31, Loss: 0.6683\n",
      "Epoch 32, Test Accuracy: 85.45222929936305%\n",
      "Epoch: 32, Loss: 0.6701\n",
      "Epoch 33, Test Accuracy: 84.89171974522293%\n",
      "Epoch: 33, Loss: 0.6414\n",
      "Epoch 34, Test Accuracy: 85.2484076433121%\n",
      "Epoch: 34, Loss: 0.6359\n",
      "Epoch 35, Test Accuracy: 83.59235668789809%\n",
      "Epoch: 35, Loss: 0.6416\n",
      "Epoch 36, Test Accuracy: 86.1656050955414%\n",
      "Epoch: 36, Loss: 0.6301\n",
      "Epoch 37, Test Accuracy: 85.63057324840764%\n",
      "Epoch: 37, Loss: 0.6104\n",
      "Epoch 38, Test Accuracy: 86.26751592356688%\n",
      "Epoch: 38, Loss: 0.6151\n",
      "Epoch 39, Test Accuracy: 86.85350318471338%\n",
      "Epoch: 39, Loss: 0.6019\n",
      "Epoch 40, Test Accuracy: 87.49044585987261%\n",
      "Epoch: 40, Loss: 0.5869\n",
      "Epoch 41, Test Accuracy: 86.80254777070064%\n",
      "Epoch: 41, Loss: 0.5780\n",
      "Epoch 42, Test Accuracy: 86.44585987261146%\n",
      "Epoch: 42, Loss: 0.5786\n",
      "Epoch 43, Test Accuracy: 86.52229299363057%\n",
      "Epoch: 43, Loss: 0.5712\n",
      "Epoch 44, Test Accuracy: 85.14649681528662%\n",
      "Epoch: 44, Loss: 0.5667\n",
      "Epoch 45, Test Accuracy: 87.0828025477707%\n",
      "Epoch: 45, Loss: 0.5558\n",
      "Epoch 46, Test Accuracy: 86.92993630573248%\n",
      "Epoch: 46, Loss: 0.5448\n",
      "Epoch 47, Test Accuracy: 87.10828025477707%\n",
      "Epoch: 47, Loss: 0.5386\n",
      "Epoch 48, Test Accuracy: 87.49044585987261%\n",
      "Epoch: 48, Loss: 0.5370\n",
      "Epoch 49, Test Accuracy: 87.82165605095541%\n",
      "Epoch: 49, Loss: 0.5301\n",
      "Epoch 50, Test Accuracy: 88.2547770700637%\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "# 训练模型\n",
    "num_epochs = 50\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "momentum = 0.9\n",
    "weight_decay = 0\n",
    "# weight_decay = 1e-4 # L2正则化系数\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay, momentum=momentum)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    train_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    print('Epoch: {}, Loss: {:.4f}'.format(epoch, train_loss))\n",
    "\n",
    "    # 在测试集上评估模型\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f\"Epoch {epoch+1}, Test Accuracy: {100 * correct / total}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "revision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
